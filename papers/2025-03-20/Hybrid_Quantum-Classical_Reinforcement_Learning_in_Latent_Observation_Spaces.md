# Hybrid Quantum-Classical Reinforcement Learning in Latent Observation Spaces

**URL**: http://arxiv.org/abs/2410.18284v3

## 原始摘要

Recent progress in quantum machine learning has sparked interest in using
quantum methods to tackle classical control problems via quantum reinforcement
learning. However, the classical reinforcement learning environments often
scale to high dimensional problem spaces, which represents a challenge for the
limited and costly resources available for quantum agent implementations. We
propose to solve this dimensionality challenge by a classical autoencoder and a
quantum agent together, where a compressed representation of observations is
jointly learned in a hybrid training loop. The latent representation of such an
autoencoder will serve as a tailored observation space best suited for both the
control problem and the QPU architecture, aligning with the agent's
requirements. A series of numerical experiments are designed for a performance
analysis of the latent-space learning method. Results are presented for
different control problems and for both photonic (continuous-variable) and
qubit-based agents, to show how the QNN learning process is improved by the
joint training.


## AI 摘要

量子机器学习的最新进展激发了利用量子强化学习方法解决经典控制问题的兴趣。然而，经典强化学习环境通常涉及高维问题空间，这对量子代理实现的有限且昂贵的资源构成了挑战。为解决这一维度挑战，本文提出了一种结合经典自编码器和量子代理的混合训练方法，通过联合学习压缩的观测表示来优化控制问题和量子处理单元架构的需求。通过一系列数值实验，展示了该方法在不同控制问题和光子（连续变量）及基于量子比特的代理中的性能，证明了联合训练对量子神经网络学习过程的改进效果。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-03-20T13:02:55+08:00
- **目录日期**: 2025-03-20
