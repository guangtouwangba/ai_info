# A Self-Improving Coding Agent

**URL**: http://arxiv.org/abs/2504.15228v1

## 原始摘要

We demonstrate that an LLM coding agent, equipped with basic coding tools,
can autonomously edit itself, and thereby improve its performance on benchmark
tasks. We find performance gains from 17% to 53% on a random subset of SWE
Bench Verified, with additional performance gains on LiveCodeBench, as well as
synthetically generated agent benchmarks. Our work represents an advancement in
the automated and open-ended design of agentic systems, and provides a
reference agent framework for those seeking to post-train LLMs on tool use and
other agentic tasks.


## AI 摘要

研究表明，配备基础编程工具的大语言模型（LLM）编码代理能够自主修改自身代码，从而显著提升基准任务性能。在SWE Bench Verified随机子集上，性能提升达17%至53%，在LiveCodeBench和合成代理基准测试中也表现更优。该工作推动了自动化、开放式智能代理系统的设计，为后续工具使用和代理任务的大模型微调提供了参考框架。这一突破展示了LLM代理通过自我迭代实现持续优化的潜力，为智能系统开发提供了新思路。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-23T03:16:05Z
- **目录日期**: 2025-04-23
