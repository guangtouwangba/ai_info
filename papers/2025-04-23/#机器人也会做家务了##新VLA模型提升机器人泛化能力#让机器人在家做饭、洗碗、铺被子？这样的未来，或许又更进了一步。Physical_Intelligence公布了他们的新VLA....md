# #机器人也会做家务了##新VLA模型提升机器人泛化能力#让机器人在家做饭、洗碗、铺被子？这样的未来，或许又更进了一步。Physical Intelligence公布了他们的新VLA...

**URL**: https://weibo.com/6105753431/PoBg4qYkp

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B9%9F%E4%BC%9A%E5%81%9A%E5%AE%B6%E5%8A%A1%E4%BA%86%23&amp;extparam=%23%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B9%9F%E4%BC%9A%E5%81%9A%E5%AE%B6%E5%8A%A1%E4%BA%86%23" data-hide=""><span class="surl-text">#机器人也会做家务了#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%96%B0VLA%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8D%87%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%23&amp;extparam=%23%E6%96%B0VLA%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8D%87%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%23" data-hide=""><span class="surl-text">#新VLA模型提升机器人泛化能力#</span></a><br><br>让机器人在家做饭、洗碗、铺被子？这样的未来，或许又更进了一步。<br><br>Physical Intelligence公布了他们的新VLA（Vision Language Action）模型π-0.5，新模型在适应复杂场景的前提之下，大幅提升了对全新环境的泛化能力。<br><br>一直以来，机器人面临着泛化能力的挑战，这关系着机器人是否能在面临新环境、新物体时正确执行任务。<br><br>在Physical Intelligence公布的实验视频当中可以看到，尽管π-0.5并不能每次都顺利完成任务，但已经能够在新环境当中展现出近似人类的“随机应变”。【视频1、视频2】<br><br>他们是如何做到这一点的呢？<br><br>核心是异构数据的协同训练。通过让模型学习多种不同数据源，从而将高级推理与运动控制相结合，实现如下能力：<br><br>- 实际执行各种技能的技巧<br>- 理解每项技能的语义上下文<br>- 推断任务的高层结构<br>- 迁移其他机器人的物理行为<br><br>为了实现机器人的有效泛化，团队训练了多个π-0.5模型的变体版本，分别删减了完整训练数据集中的不同组成部分，评估不同类型训练数据对模型泛化能力的影响。【图3】<br><br>他们发现网络数据（WD）对模型处理分布外物体的泛化能力提升最为显著，而来自其他机器人的数据（ME和CE）则在所有测试场景中都展现出重要性。<br><br>除外，团队还发现，仅需约100个训练环境，π-0.5的表现就能逼近直接在测试环境数据上训练的基线模型水平。【图4】<br><br>由于π-0.5通过协同训练学习输出多种标签类型（包括动作指令和文本），因此，可以使用同一个模型同时控制机器人的高层决策和底层执行。<br><br>为了实现这一点，该模型本身包含离散的自回归token解码和通过流匹配实现的连续解码。离散解码路径用于推断高层动作，而连续流匹配路径则用于生成底层运动指令。【图5】<br><br>Physical Intelligence团队坦率承认，目前的π0.5模型仍然不够完美，无论是在高层语义推理还是底层运动控制都仍会出错。接下来，他们还将努力提升自主进化能力和知识迁移能力。<br><br>想了解更多，欢迎阅读技术报告：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fwww.physicalintelligence.company%2Fblog%2Fpi05" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3ly1i0qtox0js4j30kg0dcgme.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1i0qtoyoz2xj30nq0dc3zo.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0qtnplhu4j31q810inhx.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0qtnt6p3oj31oe1387nc.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0qtny7eimj31re0yqb1h.jpg" referrerpolicy="no-referrer"><br><br><br clear="both"><div style="clear: both"></div><video controls="controls" poster="https://tvax4.sinaimg.cn/orj480/006Fd7o3ly1i0qtoxfh2cj30kg0dcgme.jpg" style="width: 100%"><source src="https://f.video.weibocdn.com/o0/pg0bVaz2lx08nHmQU8CY010412008hqc0E010.mp4?label=mp4_hd&amp;template=736x480.25.0&amp;ori=0&amp;ps=1Cx9YB1mmR49jS&amp;Expires=1745424163&amp;ssig=Xj3eOErGck&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/Bfm8lIS2lx08nHmQN6Qo010412004GiG0E010.mp4?label=mp4_ld&amp;template=552x360.25.0&amp;ori=0&amp;ps=1Cx9YB1mmR49jS&amp;Expires=1745424163&amp;ssig=xh6Urgl4Cj&amp;KID=unistore,video"><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5158630295797780" target="_blank" rel="noopener noreferrer">微博视频</a>观看。</p></video>

## AI 摘要

Physical Intelligence公司发布了新型VLA模型π-0.5，显著提升了机器人在新环境中的泛化能力。该模型通过异构数据协同训练，结合高级推理与运动控制，使机器人能理解语义上下文、推断任务结构并迁移物理行为。实验显示，网络数据和其他机器人数据对泛化能力提升至关重要，仅需约100个训练环境即可接近基线模型表现。模型采用离散和连续双解码路径，同时控制高层决策与底层执行。尽管在语义推理和运动控制上仍有不足，该技术为家用机器人实现复杂家务任务迈出重要一步。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-23T15:04:24Z
- **目录日期**: 2025-04-23
