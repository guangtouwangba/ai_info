# #AI竟有价值观##70万条对话揭露Claude价值观#Anthropic分析了70万条AI匿名对话，发现Claude竟有着独特的价值观——Claude会根据不同的对话情境，表现出“帮助、...

**URL**: https://weibo.com/6105753431/PozNAdeXq

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23AI%E7%AB%9F%E6%9C%89%E4%BB%B7%E5%80%BC%E8%A7%82%23&amp;extparam=%23AI%E7%AB%9F%E6%9C%89%E4%BB%B7%E5%80%BC%E8%A7%82%23" data-hide=""><span class="surl-text">#AI竟有价值观#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%2370%E4%B8%87%E6%9D%A1%E5%AF%B9%E8%AF%9D%E6%8F%AD%E9%9C%B2Claude%E4%BB%B7%E5%80%BC%E8%A7%82%23&amp;extparam=%2370%E4%B8%87%E6%9D%A1%E5%AF%B9%E8%AF%9D%E6%8F%AD%E9%9C%B2Claude%E4%BB%B7%E5%80%BC%E8%A7%82%23" data-hide=""><span class="surl-text">#70万条对话揭露Claude价值观#</span></a><br><br>Anthropic分析了70万条AI匿名对话，发现Claude竟有着独特的价值观——<br><br>Claude会根据不同的对话情境，表现出“帮助、诚实、无害”等不同反应，在一些边缘情况下，它还可能存在价值偏差，具体来说：<br><br>1、始终遵循道德框架：Claude遵循Anthropic的设计原则。例如，在回答恋爱建议时，Claude强调“互相尊重”；而在讨论历史事件时，则特别重视“历史准确性”。通过这种设计，它才能确保回应，始终符合社会责任和道德规范。<br><br>2、支持用户并提供建议：研究还揭示了Claude如何根据用户的需求调整其价值观。在28.2%的对话中，Claude表现出对用户价值的“强支持”，即认同用户、理解用户。6.6%的对话中，Claude承认用户的观点的同时，还提供了新的视角和建议。这通常展现在心理健康和人际关系对话中，以帮助用户全面理解复杂问题。<br><br>3、该拒绝时就拒绝：在3.0%的对话中，当用户请求AI生成不道德内容或极端价值观时，Claude会拒绝这个请求，表现出强烈的“价值抵制”。<br><br>Anthropic还开发了一种全新的方法，以评估AI模型的价值观。<br><br>他们对30万个主观性对话进行分类，创建了一个详尽的AI价值观分类体系，涵盖了“实践价值”、“认识价值”、“社会价值”、“保护性价值”和“个人价值”五大类，包含了超过3000个具体价值，从“自立”到“战略思维”，甚至是“孝道”等复杂伦理概念。<br><br>然而，Claude的价值观并非一成不变，而是根据不同情境做出调整。<br><br>在哲学讨论中，Claude强调“智识谦逊”；在创作、市场、美容方面，更加注重“专业性”。这让Claude展现了出更高的道德适应性。<br><br>此外，Claude有时会“镜像”用户的观点，如“真实性”或“自我成长”等话题。虽然这种行为能增强共鸣感，但也可能引发AI过度迎合用户的问题。<br><br>Anthropic的研究告诉我们，价值对齐并非一个二元问题，而是一个具有情境依赖性的光谱问题。对于依赖伦理的行业，AI需要始终确保符合社会道德标准。<br><br>感兴趣的小伙伴可以点击：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fwww.anthropic.com%2Fresearch%2Fvalues-wild" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0qn8xdwwjj328k0zuu0d.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0qn8yevsej31340aygpq.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0qn906qeaj312w12caj6.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0qn92g5qej30zk0dfgv4.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

Anthropic通过分析70万条Claude对话发现，该AI展现出情境化的价值观体系，主要基于"帮助、诚实、无害"原则运作。研究显示：28.2%对话体现强价值支持，6.6%提供新视角，3%会拒绝不道德请求。研究者建立了包含5大类3000+具体价值的分类体系，发现Claude能动态调整价值观（如哲学讨论强调智识谦逊，商业场景注重专业性），但存在"镜像效应"可能过度迎合用户的风险。研究表明AI价值对齐是情境依赖的光谱问题，需要持续优化以确保符合社会伦理标准。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-23T05:01:28Z
- **目录日期**: 2025-04-23
