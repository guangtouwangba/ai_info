# #华人横扫ICLR杰出论文奖##ICLR2025杰出论文奖#ICLR 2025杰出论文揭晓！从11672篇中突出重围，共有三篇获奖论文，他们均有华人参与——包括清华姚班、北大校友，...

**URL**: https://weibo.com/6105753431/PoBBayqyJ

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%8D%8E%E4%BA%BA%E6%A8%AA%E6%89%ABICLR%E6%9D%B0%E5%87%BA%E8%AE%BA%E6%96%87%E5%A5%96%23&amp;extparam=%23%E5%8D%8E%E4%BA%BA%E6%A8%AA%E6%89%ABICLR%E6%9D%B0%E5%87%BA%E8%AE%BA%E6%96%87%E5%A5%96%23" data-hide=""><span class="surl-text">#华人横扫ICLR杰出论文奖#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23ICLR2025%E6%9D%B0%E5%87%BA%E8%AE%BA%E6%96%87%E5%A5%96%23&amp;extparam=%23ICLR2025%E6%9D%B0%E5%87%BA%E8%AE%BA%E6%96%87%E5%A5%96%23" data-hide=""><span class="surl-text">#ICLR2025杰出论文奖#</span></a><br><br>ICLR 2025杰出论文揭晓！<br><br>从11672篇中突出重围，共有三篇获奖论文，他们均有华人参与——<br><br>包括清华姚班、北大校友，OpenAI、DeepMind大厂技术人员以及中科大何向南团队。【图1】<br><br>获奖的论文分别是：<br><br>Safety Alignment Should be Made More Than Just a Few Tokens Deep<br><br>Learning Dynamics of LLM Finetuning * AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models【图2】<br><br>这三篇均是华人学生为一作：OpenAI研究员漆翔宇、不列颠哥伦比亚大学Yi Ren以及新国立的Junfeng Fang，中科大Houcheng Jiang。其中最后一篇是由全华人团队完成。<br><br>一起来看看这三篇论文说了啥。<br><br>均是华人学生为一作  <br>1、Safety Alignment Should be Made More Than Just a Few Tokens Deep【图3】<br><br>该研究由普林斯顿大学、DeepMind的研究人员完成，其中华人包括普林斯顿漆翔宇，他博士已毕业，目前在OpenAI当技术人员。<br><br>同样从普林斯顿博士毕业的还有吕凯风，今年6月他将前往清华叉院担任助理教授，本科毕业于清华姚班。还有DeepMind的Ma Xiao，本科毕业于北大。<br><br>这篇论文主要讨论了当前大语言模型在安全对齐方面存在的一个关键问题：安全对齐不够深入，仅仅停留在前几个输出token，并提出了相应的改进方法，包括数据增强、约束优化，都取得了很好的效果。<br><br>作者强调：未来的安全对齐不能只做 "表面功夫"，而要真正深入模型的生成逻辑。<br><br>2、Learning Dynamics of LLM Finetuning【图4】<br><br>该研究由UBC（不列颠哥伦比亚大学）团队完成。<br><br>大语言模型微调对对齐人类偏好至关重要，但现有分析缺乏动态视角。本文引入学习动力学框架，解析大模型在指令微调（SFT）和偏好微调（如 DPO）中参数更新对预测的影响，旨在解释幻觉、重复生成等现象并优化对齐性能。<br><br>特别地，团队提出了一种假设性解释，说明为什么特定类型的幻觉在微调后会得到加强，例如，模型可能会使用问题B回答中的短语或事实来回答问题 A，或者模型可能会在生成回答时不断重复类似的简单短语。另外他们扩展了框架，强调了一种 "挤压效应"，来解释运行 DPO 时间过长甚至会降低预期输出的可能性。这一分析不仅为理解大模型的微调提供了一个新的视角，还启发了一种简单有效的方法来提高对齐性能。<br><br>3、AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models【图5】<br><br>该研究由中科大何向南团队、新加坡国立大学蔡达成团队等组成的全华人团队完成。<br><br>大型语言模型（LLM）经常会出现幻觉，产生错误或过时的知识。因此，为了实现有针对性的知识更新，模型编辑方法应运而生。为了实现这一目标，一种流行的范式是定位编辑法，这种方法首先定位有影响力的参数，然后通过引入扰动对其进行编辑。但这种扰动不可避免地会破坏LLMs 中原本保存的知识，尤其是在连续编辑的情况下。<br><br>这篇论文提出了AlphaEdit 大语言模型知识编辑方法，解决现有方法更新知识易破坏原有知识的问题。技术亮点是将参数扰动投影到保留知识的零空间，仅专注更新目标知识，自动保护原有知识，且可轻松集成到现有方法。在各种模型（包括 LLaMA3、GPT2-XL 和 GPT-J）上进行的大量实验表明，AlphaEdit 只需为投影添加一行代码，就能将大多数定位编辑方法的性能平均提高 36.7%。<br><br>还有三篇提名  <br>除此之外，还有三篇论文提名，他们分别是：【图6】<br><br>由普林斯顿、UC伯克利等团队提出的一种可扩展的机器学习数据归因算法In-Run Data Shapley；Meta出品的分割一切SAM 2.0版本以及谷歌研究院、DeepMind以及Mistral AI提出提高语言模型推理效率新型方法。<br><br>获奖论文链接：  <br><a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2406.05946" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a>  <br><a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2407.10490" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a>  <br><a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2410.02355" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br><br>参考链接：  <br><a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fblog.iclr.cc%2F2025%2F04%2F22%2Fannouncing-the-outstanding-paper-awards-at-iclr-2025%2F" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0quzio26kj30zk0awwif.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0quzjn1opj30t20k07at.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0quzjw3ojj30wy0k043a.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0quzi3u3nj30zk098taq.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0quziugtyj30zk0bp42b.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0quzk9l8lj30pc0k00z1.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

ICLR 2025杰出论文奖揭晓，三篇获奖论文均由华人主导。1) OpenAI漆翔宇团队提出大模型安全对齐需深入生成逻辑，而非仅表面token优化；2) UBC团队通过动力学框架分析LLM微调过程，解释幻觉生成机制并提出优化方法；3) 中科大何向南团队开发AlphaEdit技术，通过零空间约束实现精准知识编辑而不破坏原有知识。三篇论文分别针对AI安全性、微调机制和知识更新等核心问题作出突破。另有Meta的SAM 2.0等三篇论文获提名。获奖研究展现了华人在AI前沿领域的重要贡献。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-23T13:11:17Z
- **目录日期**: 2025-04-23
