# Reimagining Dance: Real-time Music Co-creation between Dancers and AI

**URL**: http://arxiv.org/abs/2506.12008v1

## 原始摘要

Dance performance traditionally follows a unidirectional relationship where
movement responds to music. While AI has advanced in various creative domains,
its application in dance has primarily focused on generating choreography from
musical input. We present a system that enables dancers to dynamically shape
musical environments through their movements. Our multi-modal architecture
creates a coherent musical composition by intelligently combining pre-recorded
musical clips in response to dance movements, establishing a bidirectional
creative partnership where dancers function as both performers and composers.
Through correlation analysis of performance data, we demonstrate emergent
communication patterns between movement qualities and audio features. This
approach reconceptualizes the role of AI in performing arts as a responsive
collaborator that expands possibilities for both professional dance performance
and improvisational artistic expression across broader populations.


## AI 摘要

这篇摘要介绍了一个创新的双向舞蹈表演系统，通过AI技术让舞者能够通过动作动态塑造音乐环境。该系统采用多模态架构，根据舞蹈动作智能组合预录音乐片段，形成连贯的音乐作品，实现了舞者同时作为表演者和作曲家的双向创作关系。研究通过表演数据相关性分析，揭示了动作特性与音频特征之间自然形成的互动模式。这一方法重新定义了AI在表演艺术中的角色，将其视为响应式协作伙伴，不仅拓展了专业舞蹈表演的可能性，也为更广泛人群的即兴艺术表达开辟了新途径。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-16T03:25:50Z
- **目录日期**: 2025-06-16
