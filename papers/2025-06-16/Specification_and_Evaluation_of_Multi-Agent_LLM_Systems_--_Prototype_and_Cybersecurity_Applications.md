# Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications

**URL**: http://arxiv.org/abs/2506.10467v2

## 原始摘要

Recent advancements in LLMs indicate potential for novel applications, e.g.,
through reasoning capabilities in the latest OpenAI and DeepSeek models. For
applying these models in specific domains beyond text generation, LLM-based
multi-agent approaches can be utilized that solve complex tasks by combining
reasoning techniques, code generation, and software execution. Applications
might utilize these capabilities and the knowledge of specialized LLM agents.
However, while many evaluations are performed on LLMs, reasoning techniques,
and applications individually, their joint specification and combined
application is not explored well. Defined specifications for multi-agent LLM
systems are required to explore their potential and their suitability for
specific applications, allowing for systematic evaluations of LLMs, reasoning
techniques, and related aspects. This paper reports the results of exploratory
research to specify and evaluate these aspects through a multi-agent system.
The system architecture and prototype are extended from previous research and a
specification is introduced for multi-agent systems. Test cases involving
cybersecurity tasks indicate feasibility of the architecture and evaluation
approach. In particular, the results show the evaluation of question answering,
server security, and network security tasks that were completed correctly by
agents with LLMs from OpenAI and DeepSeek.


## AI 摘要

最新研究表明，基于大语言模型(LLM)的多智能体系统展现出解决复杂任务的潜力，特别是在结合推理、代码生成和软件执行能力时。OpenAI和DeepSeek等先进模型在专业领域的应用，如网络安全任务(服务器安全、网络防护等)中表现出色。然而，目前对LLM系统、推理技术和应用场景的综合规范研究仍不足。本文通过扩展多智能体系统架构，提出了相关规范框架，测试案例验证了该方法的可行性。研究强调了建立系统化评估标准的重要性，以充分发挥多智能体LLM系统在特定领域的应用潜力。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-16T03:26:23Z
- **目录日期**: 2025-06-16
