# Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications

**URL**: http://arxiv.org/abs/2506.10467v2

## 原始摘要

Recent advancements in LLMs indicate potential for novel applications, e.g.,
through reasoning capabilities in the latest OpenAI and DeepSeek models. For
applying these models in specific domains beyond text generation, LLM-based
multi-agent approaches can be utilized that solve complex tasks by combining
reasoning techniques, code generation, and software execution. Applications
might utilize these capabilities and the knowledge of specialized LLM agents.
However, while many evaluations are performed on LLMs, reasoning techniques,
and applications individually, their joint specification and combined
application is not explored well. Defined specifications for multi-agent LLM
systems are required to explore their potential and their suitability for
specific applications, allowing for systematic evaluations of LLMs, reasoning
techniques, and related aspects. This paper reports the results of exploratory
research to specify and evaluate these aspects through a multi-agent system.
The system architecture and prototype are extended from previous research and a
specification is introduced for multi-agent systems. Test cases involving
cybersecurity tasks indicate feasibility of the architecture and evaluation
approach. In particular, the results show the evaluation of question answering,
server security, and network security tasks that were completed correctly by
agents with LLMs from OpenAI and DeepSeek.


## AI 摘要

最新研究表明，基于大语言模型(LLM)的多智能体系统展现出解决复杂任务的潜力。通过结合推理能力、代码生成和软件执行，这类系统可应用于网络安全等专业领域。研究扩展了多智能体系统架构原型，提出了标准化规范，并测试了OpenAI和DeepSeek模型在问答、服务器安全和网络安全任务中的表现。结果显示，该架构能有效评估LLM与推理技术的协同应用。但当前研究对LLM、推理技术与实际应用的联合规范仍存在探索不足，需要建立更系统的评估体系以充分发挥多智能体LLM系统的潜力。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-16T02:34:14Z
- **目录日期**: 2025-06-16
