# A Survey on (M)LLM-Based GUI Agents

**URL**: http://arxiv.org/abs/2504.13865v2

## 原始摘要

Graphical User Interface (GUI) Agents have emerged as a transformative
paradigm in human-computer interaction, evolving from rule-based automation
scripts to sophisticated AI-driven systems capable of understanding and
executing complex interface operations. This survey provides a comprehensive
examination of the rapidly advancing field of LLM-based GUI Agents,
systematically analyzing their architectural foundations, technical components,
and evaluation methodologies. We identify and analyze four fundamental
components that constitute modern GUI Agents: (1) perception systems that
integrate text-based parsing with multimodal understanding for comprehensive
interface comprehension; (2) exploration mechanisms that construct and maintain
knowledge bases through internal modeling, historical experience, and external
information retrieval; (3) planning frameworks that leverage advanced reasoning
methodologies for task decomposition and execution; and (4) interaction systems
that manage action generation with robust safety controls. Through rigorous
analysis of these components, we reveal how recent advances in large language
models and multimodal learning have revolutionized GUI automation across
desktop, mobile, and web platforms. We critically examine current evaluation
frameworks, highlighting methodological limitations in existing benchmarks
while proposing directions for standardization. This survey also identifies key
technical challenges, including accurate element localization, effective
knowledge retrieval, long-horizon planning, and safety-aware execution control,
while outlining promising research directions for enhancing GUI Agents'
capabilities. Our systematic review provides researchers and practitioners with
a thorough understanding of the field's current state and offers insights into
future developments in intelligent interface automation.


## AI 摘要

GUI智能体正革新人机交互方式，从基于规则的脚本发展为能理解复杂界面操作的AI系统。该研究系统分析了基于大语言模型的GUI智能体四大核心组件：(1)结合文本解析与多模态理解的感知系统；(2)通过内部建模和历史经验构建的知识库；(3)运用高级推理的任务规划框架；(4)具备安全控制的交互系统。研究揭示了大模型和多模态学习如何推动跨平台GUI自动化，同时指出当前评估方法的局限性，并提出标准化方向。关键挑战包括元素精确定位、知识检索、长程规划和执行安全控制，为未来智能界面自动化发展指明方向。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-05T02:32:18Z
- **目录日期**: 2025-06-05
