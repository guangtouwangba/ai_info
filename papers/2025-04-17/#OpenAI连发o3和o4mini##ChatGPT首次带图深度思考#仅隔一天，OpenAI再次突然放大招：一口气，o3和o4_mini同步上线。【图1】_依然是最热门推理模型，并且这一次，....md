# #OpenAI连发o3和o4mini##ChatGPT首次带图深度思考#仅隔一天，OpenAI再次突然放大招：一口气，o3和o4 mini同步上线。【图1】 依然是最热门推理模型，并且这一次，...

**URL**: https://weibo.com/6105753431/PnERmibH7

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23OpenAI%E8%BF%9E%E5%8F%91o3%E5%92%8Co4mini%23&amp;extparam=%23OpenAI%E8%BF%9E%E5%8F%91o3%E5%92%8Co4mini%23" data-hide=""><span class="surl-text">#OpenAI连发o3和o4mini#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23ChatGPT%E9%A6%96%E6%AC%A1%E5%B8%A6%E5%9B%BE%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83%23&amp;extparam=%23ChatGPT%E9%A6%96%E6%AC%A1%E5%B8%A6%E5%9B%BE%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83%23" data-hide=""><span class="surl-text">#ChatGPT首次带图深度思考#</span></a><br><br>仅隔一天，OpenAI再次突然放大招：<br><br>一口气，o3和o4 mini同步上线。【图1】  <br><br>依然是最热门推理模型，并且这一次，它们终于能够调用ChatGPT里的各种工具了，包括网络搜索、Python、图像分析、文件解释和图像生成。<br><br>也就是说，你现在可以也用o3来生成吉卜力风格的奥特曼抱子图了（doge）。【图2】<br><br>还不只是能看懂、生成图像，官方提到，o3和o4-mini是OpenAI首次能将上传图像集成到思维链中的模型——  <br><br>这意味着，它们可以基于图像展开思考，be like：<br><br>OpenAI表示，o3是他们目前最强大的推理模型，在编程、数学、科学、视觉感知等多个维度的基准测试中都刷新了SOTA，在分析图像、图表和图形等视觉任务中表现尤为出色。【图3】<br><br>在外部专家评估中，o3在困难现实任务中，能比o1少犯20%的重大错误。<br><br>而o4-mini则是一款专为快速、经济高效的推理而优化的小模型。<br><br>在专家评估中，o4-mini在非STEM任务以及数据科学领域都超过了前代的o3-mini。<br><br>在AIME 2024和AIME 2025中，甚至有超过o3的表现。【图4】<br><br>即日起，ChatGPT的Plus、Pro会员以及Team用户，都能直接体验o3、o4-mini和o4-mini-high，而原本的o1、o3-mini和o3-mini-high则已悄然下架。【图5】<br><br>所以，在基准测试上表现如此强势的o3和o4-mini，具体能带来哪些体验上的改变？<br><br>Talk is cheap，来看实测案例。<br><br>在OpenAI的官方直播中，研究员们展示了这样一个用法：  <br><br>让o3直接读一份未完成的学术海报，让它根据其中的研究线索，帮忙估算质子的同位旋矢量标量电荷，并搜索相关最新研究成果，对比新成果跟估算值的不同。【图6】<br><br>思考了不到3分钟，o3完全没有被难住，吐出了这样的结果：【图7】<br><br>网友们也第一时间给o3和o4-mini上了小球测试：【图8】  <br><br>还有医学教授在抢先体验后表示：完全停不下来。<br><br>我觉得o3的智能程度已经达到或接近天才水平了！【图9】<br><br>这位医学专家表示，他在向o3提出一些颇具挑战的临床或医学问题时，o3能给出像直接来自顶级专科医生的回答。<br><br>我们也简单测试了一下，比如让o3和o4-mini分别解读一下“洛就完了”表情包。【图10】<br><br>o3：【图11】<br><br>o4-mini：【图12】<br><br>你pick哪个答案？<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23OpenAI%E5%8F%91%E5%B8%83o3%E5%92%8Co4mini%23&amp;extparam=%23OpenAI%E5%8F%91%E5%B8%83o3%E5%92%8Co4mini%23" data-hide=""><span class="surl-text">#OpenAI发布o3和o4mini#</span></a><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0jnsnpckej30tl0k0n5l.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0jnsnyh3jj30w90k049m.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0jnsnjo82j30zk0fi426.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0jnsns6ryj30zk0gu79f.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0jnsmvi5jj30k00momyw.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0jnso6vs7j30zk0k0dx5.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0jnsoo6jkg30k00b9u0x.gif" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0jnsrmfyqg30ks0bp4qr.gif" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0jnt7j6gbj30wo0k0wng.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0jnt805fdj30ud0k018a.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0jnt6uc5mj30lg0k0787.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0jnt7bef4j30zk0d7djb.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

OpenAI近日同步推出o3和o4-mini两款新模型，具备多模态能力，可调用网络搜索、Python、图像分析等工具。o3是其最强推理模型，在编程、数学、视觉任务中表现优异，比前代减少20%错误；o4-mini则针对快速经济推理优化，在非STEM任务中超越前代。新模型支持图像深度思考，如解读学术海报、生成创意图片等。目前已向Plus/Pro/Team用户开放，替代旧版o1和o3-mini系列。实测显示o3能高效处理复杂学术问题，医学专家评价其回答达专科医生水平。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-17T05:03:41Z
- **目录日期**: 2025-04-17
