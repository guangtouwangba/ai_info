# Advancing Arabic Speech Recognition Through Large-Scale Weakly Supervised Learning

**URL**: http://arxiv.org/abs/2504.12254v1

## 原始摘要

Automatic speech recognition (ASR) is crucial for human-machine interaction
in diverse applications like conversational agents, industrial robotics, call
center automation, and automated subtitling. However, developing
high-performance ASR models remains challenging, particularly for low-resource
languages like Arabic, due to the scarcity of large, labeled speech datasets,
which are costly and labor-intensive to produce. In this work, we employ weakly
supervised learning to train an Arabic ASR model using the Conformer
architecture. Our model is trained from scratch on 15,000 hours of weakly
annotated speech data covering both Modern Standard Arabic (MSA) and Dialectal
Arabic (DA), eliminating the need for costly manual transcriptions. Despite the
absence of human-verified labels, our approach attains state-of-the-art (SOTA)
performance, exceeding all previous efforts in the field of Arabic ASR on the
standard benchmarks. By demonstrating the effectiveness of weak supervision as
a scalable, cost-efficient alternative to traditional supervised approaches,
paving the way for improved ASR systems in low resource settings.


## AI 摘要

本研究采用弱监督学习方法训练了基于Conformer架构的阿拉伯语自动语音识别(ASR)模型。使用15,000小时未经人工标注的现代标准阿拉伯语(MSA)和方言阿拉伯语(DA)语音数据进行训练，完全避免了昂贵的人工转录成本。尽管缺乏人工验证标签，该模型在标准测试集上仍取得了当前最优(SOTA)性能，超越了所有先前阿拉伯语ASR研究成果。这项工作证明了弱监督学习可作为传统监督方法的可扩展、高性价比替代方案，为资源匮乏语言开发高性能ASR系统开辟了新途径。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-17T15:02:18Z
- **目录日期**: 2025-04-17
