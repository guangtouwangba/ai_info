# Advancing Arabic Speech Recognition Through Large-Scale Weakly Supervised Learning

**URL**: http://arxiv.org/abs/2504.12254v1

## 原始摘要

Automatic speech recognition (ASR) is crucial for human-machine interaction
in diverse applications like conversational agents, industrial robotics, call
center automation, and automated subtitling. However, developing
high-performance ASR models remains challenging, particularly for low-resource
languages like Arabic, due to the scarcity of large, labeled speech datasets,
which are costly and labor-intensive to produce. In this work, we employ weakly
supervised learning to train an Arabic ASR model using the Conformer
architecture. Our model is trained from scratch on 15,000 hours of weakly
annotated speech data covering both Modern Standard Arabic (MSA) and Dialectal
Arabic (DA), eliminating the need for costly manual transcriptions. Despite the
absence of human-verified labels, our approach attains state-of-the-art (SOTA)
performance, exceeding all previous efforts in the field of Arabic ASR on the
standard benchmarks. By demonstrating the effectiveness of weak supervision as
a scalable, cost-efficient alternative to traditional supervised approaches,
paving the way for improved ASR systems in low resource settings.


## AI 摘要

本研究利用弱监督学习方法，基于Conformer架构训练阿拉伯语自动语音识别(ASR)模型。该模型完全使用15,000小时的弱标注语音数据(包含现代标准阿拉伯语和方言阿拉伯语)进行训练，无需昂贵的人工转录。尽管缺乏人工验证标签，该方法在标准测试集上取得了当前最优(SOTA)性能，超越了以往所有阿拉伯语ASR研究。这项成果证明了弱监督学习可作为传统监督方法的可扩展、高性价比替代方案，为低资源语言的ASR系统开发提供了新思路。研究特别解决了阿拉伯语这类低资源语言面临的大规模标注数据稀缺问题。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-17T22:01:21Z
- **目录日期**: 2025-04-17
