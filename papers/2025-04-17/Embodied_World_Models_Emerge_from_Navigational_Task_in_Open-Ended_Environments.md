# Embodied World Models Emerge from Navigational Task in Open-Ended Environments

**URL**: http://arxiv.org/abs/2504.11419v1

## 原始摘要

Understanding how artificial systems can develop spatial awareness and
reasoning has long been a challenge in AI research. Traditional models often
rely on passive observation, but embodied cognition theory suggests that deeper
understanding emerges from active interaction with the environment. This study
investigates whether neural networks can autonomously internalize spatial
concepts through interaction, focusing on planar navigation tasks. Using Gated
Recurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we
show that agents can learn to encode spatial properties like direction,
distance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS)
to model the agent-environment interaction as a closed dynamical system,
revealing stable limit cycles that correspond to optimal navigation strategies.
Ridge Representation allows us to map navigation paths into a fixed-dimensional
behavioral space, enabling comparison with neural states. Canonical Correlation
Analysis (CCA) confirms strong alignment between these representations,
suggesting that the agent's neural states actively encode spatial knowledge.
Intervention experiments further show that specific neural dimensions are
causally linked to navigation performance. This work provides an approach to
bridging the gap between action and perception in AI, offering new insights
into building adaptive, interpretable models that can generalize across complex
environments. The causal validation of neural representations also opens new
avenues for understanding and controlling the internal mechanisms of AI
systems, pushing the boundaries of how machines learn and reason in dynamic,
real-world scenarios.


## AI 摘要

这项研究探讨了神经网络如何通过主动交互自主内化空间概念。研究者结合门控循环单元(GRU)和元强化学习(Meta-RL)，发现智能体能够学习编码方向、距离和避障等空间属性。采用混合动力系统(HDS)建模交互过程，揭示了对应最优导航策略的稳定极限环。通过岭表示将导航路径映射到固定维度行为空间，并与神经状态对比。典型相关分析(CCA)证实了二者的强相关性，干预实验进一步验证了特定神经维度与导航性能的因果联系。该研究为构建可解释的自适应模型提供了新思路，推动了AI在动态场景中的学习推理能力。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-17T01:30:06Z
- **目录日期**: 2025-04-17
