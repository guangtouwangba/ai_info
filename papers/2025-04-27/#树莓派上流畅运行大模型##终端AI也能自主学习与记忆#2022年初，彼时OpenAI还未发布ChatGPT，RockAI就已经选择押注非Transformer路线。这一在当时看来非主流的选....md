# #树莓派上流畅运行大模型##终端AI也能自主学习与记忆#2022年初，彼时OpenAI还未发布ChatGPT，RockAI就已经选择押注非Transformer路线。这一在当时看来非主流的选...

**URL**: https://weibo.com/6105753431/PpaxKDj8M

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%A0%91%E8%8E%93%E6%B4%BE%E4%B8%8A%E6%B5%81%E7%95%85%E8%BF%90%E8%A1%8C%E5%A4%A7%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E6%A0%91%E8%8E%93%E6%B4%BE%E4%B8%8A%E6%B5%81%E7%95%85%E8%BF%90%E8%A1%8C%E5%A4%A7%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#树莓派上流畅运行大模型#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%BB%88%E7%AB%AFAI%E4%B9%9F%E8%83%BD%E8%87%AA%E4%B8%BB%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BF%86%23&amp;extparam=%23%E7%BB%88%E7%AB%AFAI%E4%B9%9F%E8%83%BD%E8%87%AA%E4%B8%BB%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%B0%E5%BF%86%23" data-hide=""><span class="surl-text">#终端AI也能自主学习与记忆#</span></a><br><br>2022年初，彼时OpenAI还未发布ChatGPT，RockAI就已经选择押注非Transformer路线。<br><br>这一在当时看来非主流的选择，如今正逐渐显现出前瞻性。<br><br>他们打造的端侧大模型已经可以在树莓派这样的微型设备上流畅运行，首批搭载Yan架构大模型的具身智能机器人也已经面世。<br><br>当下AI算力竞赛愈演愈烈之际，他们的“低算力”“群体智能”之路正在获得更多关注。<br><br>本期「大模型创新架构」主题访谈，量子位邀请到RockAI CEO刘凡平，聊聊他们选择非Transformer架构路线背后的故事，以及通过架构及算法创新实现AGI的技术愿景。【图1】△RockAI CEO刘凡平  <br><br>以下为量子位与RockAI CEO刘凡平的对话实录整理：<br><br>非Transformer逆势选择  <br>量子位：介绍一下RockAI的创立背景吧，当时为什么选择做非Transformer架构？<br><br>刘凡平：RockAI成立的工商登记的时间是2023年6月，但其实我们很多年前就在做这些事情了，当时ChatGPT还没有火。<br><br>我最早在2016、2017年研究Attention机制时就认识到Transformer存在很多问题。2022年初创业时，我们就坚定走非Transformer路线，主要是因为意识到Transformer又耗算力又耗数据。<br><br>在此之前，我们其实也探索过Transformer架构的优化方向，做了线性Attention等改进，但发现这些都没有解决根本问题，所以索性放弃，直接走非Transformer这条路。<br><br>量子位：当时设想的应用场景是什么？<br><br>刘凡平：最初做的其实是搜索引擎，当时我们的搜索引擎是“所搜即所得”，能够直接给出答案，而不是给一堆网页链接。这有点像现在的Kimi或Perplexity那种模式，但我们当时做得很早。<br><br>那时候就发现Transformer满足不了我们的需求，首先是幻觉问题非常严重，另外我们希望AI能实现个性化的自主学习和记忆，这两点都是当时Transformer基本上做不到的，甚至到现在都无法做到。<br><br>量子位：为什么从做搜索引擎转变成现在做端侧AI和群体智能？<br><br>刘凡平：其实是很自然的选择和转变。搜索引擎帮助用户获得信息，但它对用户的了解比较浅，只能通过用户的query、点击链接和我们给的结果来了解用户。<br><br>这种方式对记忆和自主学习的影响偏小，仅停留在传统机器学习的用户画像这个很浅的层面。我们想走得更远，让AI与用户之间产生更多粘性，所以想到让设备走进来。<br><br>我们当时判断AGI（通用人工智能）会和设备有强关联，而不仅仅是互联网的模式。搜索引擎只是通往AGI的一个工具，并没有成为基建，而人工智能要成为基建，就一定要和设备关联起来。<br><br>其实2022年底GPT火了之后，很多人不理解我们为什么要做非Transformer架构大模型。甚至到2023年，很多人都不太理解，现在随着越来越多人看到了Transformer之外的可能性，大家开始慢慢理解了。<br><br>量子位：能不能介绍一下什么是群体智能？<br><br>刘凡平：我们对群体智能有一个定义，具备自主学习的若干智能单元，通过环境感知、自我组织、互动协作共同解决复杂问题，并在不断变化的环境中实现整体智能提升。我们还定义了群体智能的四个阶段：<br><br>第一阶段是创新性基础架构，摒弃传统架构、研发低算力需求的创新架构和算法。<br><br>第二阶段是多元化硬件生态，构建跨平台、低功耗、多模态兼容的模型，实现在各类终端设备的灵活部署。<br><br>第三阶段是自适应智能进化，赋予智能单元自主学习能力，建立持续进化体系，实现自我优化和迭代。<br><br>第四阶段是协同化群体智能，构建智能单元间的高效信息交换与协作机制，形成既独立又整体的智能生态系统。<br><br>整个过程我们希望是从互联网模式走向物理世界的，让物理世界的每一种交互都成为数据，而这种数据能更了解用户，同时AI对数据的学习也能反馈到用户身上，我们认为这才是最有价值的。【图2<br>△RockAI群体智能发展理念  <br><br>MCSD与类脑激活  <br>量子位：能不能介绍一下Yan架构大模型的核心技术MCSD？<br><br>刘凡平：其实MCSD只是我们模型的一个模块，这个模块降低了时间复杂度和空间复杂度。<br><br>举个例子，Transformer中的Attention机制就像燃油汽车的发动机，是最核心的部分。现在很多人在优化它，相当于把发动机从自然吸气变成涡轮增压，但无论怎么改，它就是一个燃油发动机。<br><br>我们的MCSD相当于把它变成了新能源汽车的电机。Attention机制建立了一个大矩阵去计算token与token之间的关联关系，时间复杂度是O(n²)，性能损耗非常大。<br><br>而我们的MCSD可以通俗理解为，对输入内容中的token进行动态的增强和衰减。<br><br>比如我想预测“今天北京的温度是多少”这个句子的下一个token是什么，是问号还是句号。其中的“今天”两个字对后面用问号还是句号影响很小，所以对它进行衰减；而“多少”对下一个token影响比较大，所以进行增强。<br><br>这个过程只需要算一次，就把计算复杂度从O(n²)降为了O(n)，推理就更快，基本上做到一个稳定常量级的推理。【图3】△《MCSD: An Efficient Language Model with Diverse Fusion》论文  <br><br>量子位：除了MCSD，Yan架构大模型还有什么核心技术？<br><br>刘凡平：我们还提出了类脑激活机制，它是在MCSD基础上扩展的横向内容。这个类脑激活机制我们内部称为“动态神经元选择驱动算法”。<br><br>人的大脑是动态激活的。开车时，视觉皮层被大量激活；休息时，视觉皮层被抑制；考试时，逻辑区被激活；回忆问题时，记忆区被激活。而传统Transformer架构，哪怕算1+1，所有神经元都会参与运算，这是非常不合理的。<br><br>MoE（混合专家模型）虽然减少了参与计算的参数，但它在模型初始化前就定义好了分支数量，并不是真正动态激活的。我们的做法是，当用户输入query时，会动态组建一个神经网络，这个网络是根据需要临时建立的，不是预设好的。<br><br>形象地说，MoE相当于在河上提前修好五座桥，用户来了后选择一座过河；而我们是没有现成的桥，只提供一堆工具（神经元），用户需要过河时，这些工具动态地创建出一座桥，问题解决后这个桥就消失了。【图4】△MCSD与类脑激活机制示意  <br><br>量子位：这种计算复杂度为O(n)的模型能在现实中提供什么新的可能性？<br><br>刘凡平：最典型的是设备端应用。很多设备厂商找我们，是因为我们的模型能在他们设备上跑起来。Transformer架构如果要在骁龙6的手机上运行，参数量需要降得很低，而我们可以直接运行。<br><br>像树莓派这样的低端设备，我们也能运行起来，这对物联网设备很重要。还有无人机、具身智能机器人等，如果它们需要联网才能对话，那用户体验是很糟糕的。我们能让模型部署在设备上，实现离线智能，这是非常大的优势。<br><br>量子位：计算复杂度的下降和模型性能的提升可以兼得吗？<br><br>刘凡平：我认为是可以的。这不是拍脑袋的感觉，而是基于两方面原因：<br><br>一是我们做了很多实验，发现标准Attention机制的O(n²)计算复杂度有部分是浪费算力的；二是从脑科学角度看，即使是神经元很少的简单生物，也能拥有一定的智能。<br><br>我们认为关键是底层算法的问题。我们不仅在做架构创新，还有基础算法的创新。如辛顿所说，反向传播算法本身也存在问题。要进一步发展人工智能，底层算法必须要做大量创新。<br><br>底层算法决定了上层架构，底层算法如果不行，架构层的创新就会越来越有限。<br><br>训推同步与端侧革命  <br>量子位：能不能描绘一下群体智能最终的场景是什么样子？<br><br>刘凡平：人类社会的发展一定会伴随着新设备的产生，未来可能每个人都会有一个新的设备，这个设备可能不再是手机，因为手机的场景有限。<br><br>这个设备会是什么样现在不清楚，但我认为它更多会在物理世界帮助你，且不一定是机器人形式。会帮你解决日常生活中的绝大部分问题，具有高度隐私性，完全忠于你且不会泄露隐私。<br><br>更重要的是，这些设备具备自主学习能力。比如你告诉它做个蛋炒饭，它暂时还不会做，但它会在物理世界中自己学习怎么做。设备之间也会相互关联，在人类社会之外，还有人与机器的社会、机器与机器的社会。<br><br>不过这不是说硅基生命会产生，而是服务人类社会的过程。我是个务实主义者，不会幻想非常科幻的场景。未来社会只要人存在，就是为人服务的社会，没那么科幻，但一定会让人更简单、更高效地思考和行动。<br><br>量子位：目前我们是在群体智能四个阶段里的哪个阶段？<br><br>刘凡平：第一个阶段“创新性基础架构”已经完全实现。第二个阶段“多元化硬件生态”要兼容非常广泛的设备，我们也已经做到了。<br><br>现在正迈向第三个阶段“自适应智能进化”。因为自主学习和记忆技术还没有正式对外发布，一旦具备后，我们就完全进入第三阶段。第四阶段是“协同化群体智能”阶段，所以目前我们处于第二阶段向第三阶段过渡的阶段。<br><br>量子位：第三阶段自适应智能进化的门槛是什么，最大挑战是什么？<br><br>刘凡平：“自适应智能进化”的两个关键门槛是自主学习和记忆能力。最大挑战是“训推同步”，即训练和推理同步进行。<br><br>这个挑战非常高，不是说DeepSeek或是OpenAI就可以轻易做到的。他们做的其实更多还是对Transformer的优化，而训推同步在行业内都没有人做过。<br><br>Google最近发表了一篇《Titans: Learning to Memorize at Test Time》的论文，也算是记忆能力的一种探索，但还不够，而我们已经在实施自主学习与记忆能力的路上。【图5】△《Titans: Learning to Memorize at Test Time》论文  <br><br>我们的技术规划有两个方面：一是从架构层面，通过类脑激活机制改进在记忆过程中让每个神经元能记的东西更多；二是基础算法创新，特别是优化反向传播算法。<br><br>推理现在看起来容易，一台GPU设备就能完成，但训练却很难，主要是因为反向传播算法。如果训练和推理算法要求都很低，那么就可以在终端设备上直接做训练推理同步，直接从物理世界交互获得数据进行训练，这是理想状态。<br><br>量子位：预计第三阶段自适应智能进化和第四阶段协同化群体智能会在多久后实现？<br><br>刘凡平：第三阶段我们预计在未来一到两年内实现，不会特别久。<br><br>我们内部已经看到了一些效果，去年6月份世界人工智能大会上我们对外演示过这个能力，但那还属于实验室版本，没有商用。<br><br>第四阶段“协同化群体智能”需要的时间更长，因为它涉及设备与设备之间的通信，这方面虽然我们有很多研究，但确实还有障碍，预计2到3年后可能会看到明显进展。【图6】△群体智能示意  <br><br>量子位：要实现群体智能，不同设备上的多个模型相互协作的挑战大吗？<br><br>刘凡平：很大，这正是我们实验室团队正在研究的问题。<br><br>协同学习是很难的，它首先需要协同的机制和语言。人与人交流可以通过语言，但机器之间的交流大概率不是语言形式，因为语言交流有时间成本，且语言是具象表达，而非抽象的。<br><br>机器之间的协作一定是以更精准的方式进行，而目前我们还没找到很好的方式。我们在研究机器与机器之间的交流模式，包括神经元交换的方式。<br><br>举个例子，比如我的模型在开车时知道哪些神经元被激活，那能否把这部分神经元移植到另一个不会开车的模型上？移植后，那个模型无需训练就可以直接开车，实现能力迁移。<br><br>同样，当两个模型需要一起完成任务时，如何让它们默契配合？这需要实时同步的文本、视觉、语音的交互。<br><br>目前大模型的交互，输入和输出不是实时同步的，用户输入文本后，模型要等待完整输入完成才开始思考再输出。但人与人交流时，对方开始说话之后你同步就在思考了。<br><br>量子位：这与传统人与智能音箱的那种交互有何本质区别？<br><br>刘凡平：传统智能音箱是单向指令型交互，比如让小度播放音乐，它就播放。我们的模式是，当你刚说“帮我播一首”，还没说到后文时，模型已经开始推理你想听谁的歌，开始理解你的意图并准备结果，这能让设备更像人而非工具。<br><br>这需要完全不同的技术实现。传统多模态模型常常是分开训练的，先训练自然语言模型，再训练音频、视频模型，然后做对齐。<br><br>而我们的方法更像教婴儿，不是先学文本再学音频再学视觉，而是同时学习，这产生的对世界的认识是完全不同的，改变了大模型的学习模式。<br><br>比如教孩子认字，当你指着字母说“这是A”时，声音和视觉是同步输入给他的。重复几次孩子很快就能认出字母。实时学习不需要海量数据，只需要few-shot，而传统大模型需要大量样本输入去学习。<br><br>当前的大模型由于架构问题和反向传播的限制，导致强依赖数据和算力。而实时模型对数据的要求会大大降低。<br><br>一个人从婴儿到大学毕业，并没有看过一万亿token的数据，而现在大模型训练动辄需要十几T的token来训，这显现了现有方法的缺陷。<br><br>论文：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2406.12230" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>完整内容：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FAWtwk01ldqo97tKjANs4JA" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0v4uq56i9j30k30k0whw.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0v4ur7h0wj30zi0k0dqv.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0v4uqvcz3j30zk088780.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0v4uqr0w3j30zk0h349a.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0v4uqu2efj30zk0cc76v.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0v4uqr9uej30zk0gx7cm.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0v4ur4826j30wd0k0dto.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0v4ur0l0kj30zk0em7ae.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

RockAI开发了创新的非Transformer架构大模型Yan，采用MCSD技术将计算复杂度从O(n²)降至O(n)，结合类脑激活机制实现动态神经元选择。该模型可在树莓派等低端设备流畅运行，支持端侧离线智能。公司提出群体智能四阶段发展路径，目前已实现基础架构创新和硬件生态兼容，正推进自主学习和记忆能力研发，预计1-2年内实现自适应智能进化。该技术路线突破Transformer的高算力依赖，为物联网、机器人等终端设备提供轻量化AI解决方案，探索物理世界与数字世界的智能协同。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-27T06:03:53Z
- **目录日期**: 2025-04-27
