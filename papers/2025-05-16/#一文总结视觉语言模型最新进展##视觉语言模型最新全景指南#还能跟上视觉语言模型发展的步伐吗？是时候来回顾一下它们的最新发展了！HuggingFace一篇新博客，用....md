# #一文总结视觉语言模型最新进展##视觉语言模型最新全景指南#还能跟上视觉语言模型发展的步伐吗？是时候来回顾一下它们的最新发展了！HuggingFace一篇新博客，用...

**URL**: https://weibo.com/6105753431/Ps6qL2lYG

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%B8%80%E6%96%87%E6%80%BB%E7%BB%93%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%23&amp;extparam=%23%E4%B8%80%E6%96%87%E6%80%BB%E7%BB%93%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%23" data-hide=""><span class="surl-text">#一文总结视觉语言模型最新进展#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9C%80%E6%96%B0%E5%85%A8%E6%99%AF%E6%8C%87%E5%8D%97%23&amp;extparam=%23%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9C%80%E6%96%B0%E5%85%A8%E6%99%AF%E6%8C%87%E5%8D%97%23" data-hide=""><span class="surl-text">#视觉语言模型最新全景指南#</span></a><br><br>还能跟上视觉语言模型发展的步伐吗？是时候来回顾一下它们的最新发展了！<br><br>HuggingFace一篇新博客，用八大章节总结了VLM领域的最新发展。【图1】<br><br>一起来看看文章的细节：<br><br>一、新的模型架构趋势<br>1. Any-to-any模型，支持多种输入和输出模态，代表模型有：<br><br>- Chameleon：可输入并输出图像和文本，未开放图像生成能力<br>- Lumina-mGPT：在Chameleon基础上开发的模型，增加了图像生成能力<br>- Qwen 2.5 Omni：采用“Thinker-Talker”架构，“Thinker”负责文本生成，“Talker”以流式方式产生自然语音响应。【图2】<br><br>2. 推理模型，擅长复杂问题推理，代表模型有：<br><br>- QVQ-72B-preview：2025 年前唯一开源的多模态推理模型<br>- Kimi-VL-A3B-Thinking：基于Kimi-VL优化，强化长链推理能力【图3】<br><br>3. 小巧但功能强大的模型，参数量小（&lt;2B），可在消费级 GPU 运行，代表模型：<br><br>- SmolVLM：模型家族，尝试将模型参数压缩到极小规模<br>- gemma3-4b-it：支持128k上下文窗口的最小多模态模型之一<br>- Qwen2.5-VL-3B-Instruct：支持目标检测、文档理解等任务（32K 上下文）<br><br>4. 混合专家作为解码器的模型，在推理时更高效，代表模型：<br><br>- Kimi-VL：目前最先进的开源推理模型，采用混合专家解码器<br>- MoE-LLaVA：关注效率和减少幻觉<br>- DeepSeek-VL2：具有广泛的多模态能力<br><br>5. 视觉语言动作模型，将视觉语言模型应用于机器人领域，代表模型有：<br><br>- π0和π0-FAST：训练涵盖7个机器人平台和68个独特任务，展现出强大的零样本和微调性能<br>- GR00T N1：能够理解图像和语言，并将其转化为动作【图4】<br><br>二、新能力的涌现<br><br>1. 物体检测、分割与计数<br><br>- 视觉语言模型已能泛化传统CV任务。当前模型能够接收图像和各种提示，输出包含定位标记的结构化文本。<br>- 代表模型：PaliGemma、Molmo、Qwen2.5-VL【图5】<br><br>2. 多模态安全模型<br><br>- 在生产环境中部署视觉语言模型时，需过滤输入/输出内容以防止越狱攻击、有害生成，确保合规性。多模态安全模型在视觉语言模型之前和之后使用，以过滤其输入和输出。<br>- 代表模型：ShieldGemma 2、Llama Guard 4【图6】<br><br>3. 多模态RAG模型<br><br>- 在多模态领域对RAG进行了改进，用于处理复杂文档（通常为PDF格式），通过多模态检索器和重排序器，避免了传统PDF解析的脆弱性。【图7】<br>- 代表架构：DSE模型、ColBERT类似模型<br><br>三、多模态智能体与视频语言模型<br><br>- 近期涌现了许多能理解和操作用户界面的视觉语言模型，代表模型有：UI-TARS-1.5、MAGMA-8B、Qwen2.5-VL<br><br>- 当前大多数视觉语言模型已具备视频处理能力，但仍需要处理大量帧数据和它们之间的关系，研究者们用了各种方法来筛选关键帧，代表模型有LongVU、Qwen2.5VL【图8】<br><br>四、新的基准测试集【图9】<br><br>- MMT-Bench：评估视觉语言模型在需要专业知识、精确视觉识别、定位、推理和规划的多样化多模态任务中的表现。<br><br>- MMMU-Pro：评估先进AI模型在多模态领域的真实理解能力<br><br>更多详情内容，欢迎查看博客原文了解：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhuggingface.co%2Fblog%2Fvlms-2025" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1hgfp28hmj310218iwp2.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1hgfs3spyj31eu0rg1dp.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1hgfude0uj31em0zutvs.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i1hgfyzykfj31oa0vq7wh.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1hgg2125hj31l40vw4mi.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1hgg3zzs1j31l00vwwuu.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i1hgg5lfvbj31ks0jswiu.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1hgg9n8goj31tg0oi165.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i1hggchup5j31kq0x07wh.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

视觉语言模型(VLM)近期取得显著进展，主要呈现五大趋势：1)多模态Any-to-any架构(如Chameleon、Qwen2.5 Omni)；2)增强推理能力(QVQ-72B、Kimi-VL)；3)轻量化模型(SmolVLM、gemma3-4b)；4)混合专家解码器(Kimi-VL、MoE-LLaVA)；5)机器人应用(π0、GR00T)。新能力包括：物体检测/分割(PaliGemma)、多模态安全过滤(ShieldGemma2)、文档理解RAG系统。视频处理(LongVU)和UI交互(UI-TARS)成为新方向。MMT-Bench等新基准测试模型综合能力。整体发展呈现多模态融合、轻量化、专业化应用等特点。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-16T10:03:09Z
- **目录日期**: 2025-05-16
