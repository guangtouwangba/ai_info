# #机器人领域首个百万级动作数据集##人形机器人动作更精细了#人形机器人领域大利好——百万规模人体动作数据集MotionLib来了！北大卢宗青团队联合人大、智在无界...

**URL**: https://weibo.com/6105753431/PrNzspwUf

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9C%BA%E5%99%A8%E4%BA%BA%E9%A2%86%E5%9F%9F%E9%A6%96%E4%B8%AA%E7%99%BE%E4%B8%87%E7%BA%A7%E5%8A%A8%E4%BD%9C%E6%95%B0%E6%8D%AE%E9%9B%86%23&amp;extparam=%23%E6%9C%BA%E5%99%A8%E4%BA%BA%E9%A2%86%E5%9F%9F%E9%A6%96%E4%B8%AA%E7%99%BE%E4%B8%87%E7%BA%A7%E5%8A%A8%E4%BD%9C%E6%95%B0%E6%8D%AE%E9%9B%86%23" data-hide=""><span class="surl-text">#机器人领域首个百万级动作数据集#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%BA%E5%BD%A2%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8A%A8%E4%BD%9C%E6%9B%B4%E7%B2%BE%E7%BB%86%E4%BA%86%23&amp;extparam=%23%E4%BA%BA%E5%BD%A2%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8A%A8%E4%BD%9C%E6%9B%B4%E7%B2%BE%E7%BB%86%E4%BA%86%23" data-hide=""><span class="surl-text">#人形机器人动作更精细了#</span></a><br><br>人形机器人领域大利好——百万规模人体动作数据集MotionLib来了！<br><br>北大卢宗青团队联合人大、智在无界、智源研究院，发布了全新通用动作生成框架Being-M0，还放出一个百万级动作生成数据集MotionLib，首次实现了人体动作向多类型人形机器人的动作迁移。<br><br>具体来说，这项工作解决了三大关键问题：<br><br>- 百万高质量数据：团队从2000万段网络视频中，提取出100万条高质量动作数据，结合Gemini生成的细粒度动作描述，构成目前最大、最全的动作数据集MotionLib，包含RGB、深度等多模态信息，甚至还有多人交互场景。<br><br>- 动作生成框架：他们训练了一个能“看懂文字、做出动作”的动作生成框架Being-M0。通过该框架对动作的语义理解，人形机器人能“像人一样动”，做到动作识别、分类，甚至可以分析多人互动的行为。<br><br>- 跨平台通用：人体动作不只是“模仿”，而是“适配”。Being-M0创新使用“优化、学习”两阶段策略，把动作准确迁移到宇树H1、H1-2、G1等多个机器人上，实现不同机器人之间的动作统一。<br><br>在底层表示上，他们还提出了一种新方案 **MotionBook**，用二维“动作图像”保留空间与时序的完整信息，解决了传统向量量化的“信息损失”难题，让模型能学得更细，生成得更精。<br><br>这项研究将于ICML 2025亮相，团队表示后续还将持续推进通用具身智能发展，探索更强的全身运动控制与灵巧操作能力。<br><br>项目地址已开源：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fbeingbeyond.github.io%2FBeing-M0%2F" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>论文链接：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2410.03311" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1i1f56qiw0cj31uy0u0wh2.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3ly1i1f56v2nhdj31rs0u00vt.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3ly1i1f56qynsoj31rs0u041l.jpg" referrerpolicy="no-referrer"><br><br><br clear="both"><div style="clear: both"></div><video controls="controls" poster="https://tvax1.sinaimg.cn/orj480/006Fd7o3ly1i1f56r32x8j31uy0u0wh2.jpg" style="width: 100%"><source src="https://f.video.weibocdn.com/o0/Hvrb60Qqlx08oeV5UdmM010412007teI0E010.mp4?label=mp4_720p&amp;template=1604x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1747241920&amp;ssig=fHF7RzZOMi&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/XctioMa4lx08oeV57odW0104120043fC0E010.mp4?label=mp4_hd&amp;template=1068x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1747241920&amp;ssig=8yWyKIiEoC&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/ZNACqBo0lx08oeV5tdJm010412002Ba50E010.mp4?label=mp4_ld&amp;template=800x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1747241920&amp;ssig=1oAdIog2Aj&amp;KID=unistore,video"><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5166253254574088" target="_blank" rel="noopener noreferrer">微博视频</a>观看。</p></video>

## AI 摘要

北京大学卢宗青团队联合多家机构发布了机器人领域首个百万级动作数据集MotionLib和通用动作生成框架Being-M0。该研究从2000万网络视频中提取100万条高质量动作数据，结合Gemini生成的细粒度描述，构建了包含多模态信息的大规模数据集。创新提出的MotionBook二维表示法解决了传统向量量化的信息损失问题。Being-M0框架实现了人体动作向多类型人形机器人的精准迁移，使机器人动作更精细自然。该成果将亮相ICML 2025，并已开源相关数据和代码。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-14T16:03:30Z
- **目录日期**: 2025-05-14
