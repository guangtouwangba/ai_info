# Challenges and Future Directions of Data-Centric AI Alignment

**URL**: http://arxiv.org/abs/2410.01957v2

## 原始摘要

As AI systems become increasingly capable and influential, ensuring their
alignment with human values, preferences, and goals has become a critical
research focus. Current alignment methods primarily focus on designing
algorithms and loss functions but often underestimate the crucial role of data.
This paper advocates for a shift towards data-centric AI alignment, emphasizing
the need to enhance the quality and representativeness of data used in aligning
AI systems. In this position paper, we highlight key challenges associated with
both human-based and AI-based feedback within the data-centric alignment
framework. Through qualitative analysis, we identify multiple sources of
unreliability in human feedback, as well as problems related to temporal drift,
context dependence, and AI-based feedback failing to capture human values due
to inherent model limitations. We propose future research directions, including
improved feedback collection practices, robust data-cleaning methodologies, and
rigorous feedback verification processes. We call for future research into
these critical directions to ensure, addressing gaps that persist in
understanding and improving data-centric alignment practices.


## AI 摘要

本文主张以数据为中心的人工智能对齐方法，强调提高训练数据的质量和代表性。当前对齐研究过度依赖算法设计，而忽视了数据的关键作用。研究指出人类反馈存在可靠性问题，AI反馈则受限于时间漂移、上下文依赖和模型固有缺陷。作者提出未来研究方向包括优化反馈收集流程、开发鲁棒的数据清洗方法以及严格的反馈验证机制，以解决数据质量不足导致的AI价值观偏差问题。该论文呼吁学界重视数据层面的对齐研究，填补现有方法论空白，确保AI系统更好地符合人类价值观和偏好。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-03T00:02:16Z
- **目录日期**: 2025-05-03
