# Mind the GAP: Glimpse-based Active Perception improves generalization and sample efficiency of visual reasoning

**URL**: http://arxiv.org/abs/2409.20213v2

## 原始摘要

Human capabilities in understanding visual relations are far superior to
those of AI systems, especially for previously unseen objects. For example,
while AI systems struggle to determine whether two such objects are visually
the same or different, humans can do so with ease. Active vision theories
postulate that the learning of visual relations is grounded in actions that we
take to fixate objects and their parts by moving our eyes. In particular, the
low-dimensional spatial information about the corresponding eye movements is
hypothesized to facilitate the representation of relations between different
image parts. Inspired by these theories, we develop a system equipped with a
novel Glimpse-based Active Perception (GAP) that sequentially glimpses at the
most salient regions of the input image and processes them at high resolution.
Importantly, our system leverages the locations stemming from the glimpsing
actions, along with the visual content around them, to represent relations
between different parts of the image. The results suggest that the GAP is
essential for extracting visual relations that go beyond the immediate visual
content. Our approach reaches state-of-the-art performance on several visual
reasoning tasks being more sample-efficient, and generalizing better to
out-of-distribution visual inputs than prior models.


## AI 摘要

人类在理解视觉关系方面远优于AI系统，尤其是在处理新物体时。受主动视觉理论启发，研究者开发了基于"Glimpse"的主动感知系统(GAP)，通过模拟人眼注视机制依次聚焦图像关键区域。该系统结合注视位置和局部视觉内容来表征图像各部分关系，超越了单纯视觉信息的局限。实验表明，GAP在多项视觉推理任务中达到最先进水平，具有更高的样本效率和更好的分布外泛化能力。这种将注视行为与视觉处理相结合的方法，为提升AI系统的视觉关系理解提供了新思路。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-02T14:01:57Z
- **目录日期**: 2025-04-02
