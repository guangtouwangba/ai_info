# #AI人物对白更真实了##Meta发布演员模型#AI人物短片迎来了突破性进展：Meta推出了“演员”模型MoCha，它不仅实现了精准的嘴型同步，还能生成自然流畅的表情和动...

**URL**: https://weibo.com/6105753431/PloLJg6P5

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23AI%E4%BA%BA%E7%89%A9%E5%AF%B9%E7%99%BD%E6%9B%B4%E7%9C%9F%E5%AE%9E%E4%BA%86%23&amp;extparam=%23AI%E4%BA%BA%E7%89%A9%E5%AF%B9%E7%99%BD%E6%9B%B4%E7%9C%9F%E5%AE%9E%E4%BA%86%23" data-hide=""><span class="surl-text">#AI人物对白更真实了#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Meta%E5%8F%91%E5%B8%83%E6%BC%94%E5%91%98%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23Meta%E5%8F%91%E5%B8%83%E6%BC%94%E5%91%98%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#Meta发布演员模型#</span></a><br><br>AI人物短片迎来了突破性进展：Meta推出了“演员”模型MoCha，它不仅实现了精准的嘴型同步，还能生成自然流畅的表情和动作，整体表现已接近电影级别。<br><br>先来看一波效果——<br>【视频1】展示的是旧版模型，人物表情和语气略显生硬；<br>【视频2】则展现了MoCha优化后的版本，角色神态轻松自然，动作几乎无AI痕迹。<br><br>MoCha的优势还包括：<br><br>-支持结构化输入：用户可使用“Person1: …”“Person2: …”的格式，为每个角色分配台词，实现多角色之间轮流对话与动作展示，操作更清晰高效。<br><br>-简化输入门槛：无需3D骨架、动作捕捉点或参考图像，仅需输入文本与语音，即可生成全身动画，大幅降低使用难度。<br><br>-高质量视频输出：支持720×720分辨率，生成视频长度可达128帧，角色具备完整的身体动作与丰富的面部表情，适用于短片、动画等应用场景。<br><br>MoCha背后的关键技术包括：<br><br>-架构升级：模型采用了30B参数的DiT（Diffusion Transformer），抛弃传统U-Net架构，更擅长处理长时间序列，使生成动作连贯自然。<br><br>-嘴型对齐技术：引入创新的“语音-视频窗口注意力机制”（Speech-Video Window Attention），让每帧视频精准对应音频时点，有效提升嘴型同步与语音节奏匹配度。<br><br>-联合训练策略：采用80%语音视频+20%纯文本的混合训练方式，使模型既能在有声场景中表现细腻，也能在无声场景下维持自然的情绪和动作，具备更强泛化能力。<br><br>-自研评测体系：Meta构建了名为MoCha-Bench的评测基准，涵盖150个多视角、多情绪的视频样本，从嘴型同步、情绪表现、动作流畅度等多个维度对模型进行全面评估。<br><br>从实验结果看，MoCha在各项指标上全面超越现有主流模型，如SadTalker、Hallo3。<br><br>以嘴型同步指标Sync-C为例，MoCha得分达6.037，领先Hallo3约1.2分。动作自然度、情绪表现和画面精细度也均获得人类评审的Top 1评价。<br><br>感兴趣的小伙伴可以点击——<br>抱抱脸：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhuggingface.co%2Fpapers%2F2503.23307" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>项目页面：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fcongwei1230.github.io%2FMoCha%2F" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>暂时无法在飞书文档外展示此内容<img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3ly1i02hdud1ywj310y0k0751.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1i02hdvdn9dj310y0k0wff.jpg" referrerpolicy="no-referrer"><br><br><br clear="both"><div style="clear: both"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/006Fd7o3ly1i02hdug4l4j310y0k0751.jpg" style="width: 100%"><source src="https://f.video.weibocdn.com/o0/NmoinWNylx08n9MKvrtS01041200oiZw0E010.mp4?label=mp4_720p&amp;template=1330x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1743624143&amp;ssig=hUmlL7P%2FfM&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/KrxfHfzxlx08n9MIaKSk01041200cCnp0E010.mp4?label=mp4_hd&amp;template=884x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1743624143&amp;ssig=iFzvxcxHAA&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/akBaUhialx08n9MHVXVS010412008tA40E010.mp4?label=mp4_ld&amp;template=664x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1743624143&amp;ssig=ZA%2FFR7rDEL&amp;KID=unistore,video"><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5151000152178711" target="_blank" rel="noopener noreferrer">微博视频</a>观看。</p></video>

## AI 摘要

Meta最新发布的"演员"模型MoCha在AI人物对白生成方面取得突破性进展。该模型采用30B参数的DiT架构，通过创新的语音-视频窗口注意力机制实现精准嘴型同步，支持720p分辨率、128帧视频生成。MoCha仅需文本和语音输入即可生成自然表情动作，在多角色对话场景中表现优异。测试显示其嘴型同步指标Sync-C达6.037，全面超越现有模型。该技术显著降低了动画制作门槛，可广泛应用于影视短片创作。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-02T19:03:24Z
- **目录日期**: 2025-04-02
