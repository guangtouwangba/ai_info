# #斯坦福Transformer和LLM备忘录##斯坦福AI知识点小抄#斯坦福的CME-295课件被整进了神级cheatsheet里，大语言模型的核心知识全都压缩进一份PDF，这份AI知识点小抄...

**URL**: https://weibo.com/6105753431/PlpwbnutV

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%96%AF%E5%9D%A6%E7%A6%8FTransformer%E5%92%8CLLM%E5%A4%87%E5%BF%98%E5%BD%95%23&amp;extparam=%23%E6%96%AF%E5%9D%A6%E7%A6%8FTransformer%E5%92%8CLLM%E5%A4%87%E5%BF%98%E5%BD%95%23" data-hide=""><span class="surl-text">#斯坦福Transformer和LLM备忘录#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%96%AF%E5%9D%A6%E7%A6%8FAI%E7%9F%A5%E8%AF%86%E7%82%B9%E5%B0%8F%E6%8A%84%23&amp;extparam=%23%E6%96%AF%E5%9D%A6%E7%A6%8FAI%E7%9F%A5%E8%AF%86%E7%82%B9%E5%B0%8F%E6%8A%84%23" data-hide=""><span class="surl-text">#斯坦福AI知识点小抄#</span></a><br><br>斯坦福的CME-295课件被整进了神级cheatsheet里，大语言模型的核心知识全都压缩进一份PDF，这份AI知识点小抄，真的就是看一页顶十页！<br><br>这份小抄由Amidi兄弟（就是那个靠AI手绘笔记爆红的组合）操刀，从基础到前沿，内容涵盖超全：<br><br>• tokenization：教你文本是怎么被切成模型能读的“语言单元”；<br><br>• self-attention：模型如何判断“你说的他”到底是谁；<br><br>• prompting：怎么写提示词才能让AI不跑偏；<br><br>• fine-tuning：怎么微调出你自己的专属模型；<br><br>• LLM-as-a-Judge：AI能不能当评委？模型自己判结果；<br><br>• RAG：老生常谈的检索增强生成，AI生成内容前先查资料。<br><br>• AI Agents：让LLM不只是聊天工具，而是真能拆任务、做计划的“智能体”；<br><br>• reasoning models：模型是怎么一步一步“推理”出答案的也讲了！<br><br>这份小抄不仅内容丰富，还有彩蛋——配套教程《Super Study Guide》厚达250页，600+插图，系统梳理Transformer + LLM的知识图谱，堪称AI人专属的“漫画教材”。<br><br>链接在此，转发分享起来吧👉 <a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2Fafshinea%2Fstanford-cme-295-transformers-large-language-models" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i02kpoy52hj31po1bk4qp.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i02kpqftf9j31ps1bo1kx.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i02kps74hgj31pw1b07wh.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i02kptsfujj31pg1b27wh.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

斯坦福大学推出了一份关于Transformer和大语言模型(LLM)的精华备忘录，将核心知识点浓缩为PDF格式的"小抄"。这份资料由知名AI笔记创作者Amidi兄弟制作，涵盖tokenization、self-attention、prompting、fine-tuning等关键技术，还包括LLM-as-a-Judge、RAG、AI Agents和reasoning models等前沿内容。配套的250页《Super Study Guide》教程包含600多幅插图，系统梳理了Transformer和LLM的知识体系。这份资源以简明易懂的方式呈现复杂概念，适合AI学习者快速掌握大语言模型的核心原理和应用。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-02T21:02:55Z
- **目录日期**: 2025-04-02
