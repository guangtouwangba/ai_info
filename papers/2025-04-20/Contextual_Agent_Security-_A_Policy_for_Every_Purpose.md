# Contextual Agent Security: A Policy for Every Purpose

**URL**: http://arxiv.org/abs/2501.17070v3

## 原始摘要

Judging an action's safety requires knowledge of the context in which the
action takes place. To human agents who act in various contexts, this may seem
obvious: performing an action such as email deletion may or may not be
appropriate depending on the email's content, the goal (e.g., to erase
sensitive emails or to clean up trash), and the type of email address (e.g.,
work or personal). Unlike people, computational systems have often had only
limited agency in limited contexts. Thus, manually crafted policies and user
confirmation (e.g., smartphone app permissions or network access control
lists), while imperfect, have sufficed to restrict harmful actions. However,
with the upcoming deployment of generalist agents that support a multitude of
tasks (e.g., an automated personal assistant), we argue that we must rethink
security designs to adapt to the scale of contexts and capabilities of these
systems. As a first step, this paper explores contextual security in the domain
of agents and proposes contextual agent security (Conseca), a framework to
generate just-in-time, contextual, and human-verifiable security policies.


## AI 摘要

评估一个行为的安全性需要考虑其发生的具体情境。对人类来说，这显而易见，比如删除邮件是否恰当取决于邮件内容、目的（如删除敏感邮件或清理垃圾）和邮箱类型（工作或个人）。然而，计算系统通常只能在有限情境中执行有限操作，因此依赖手动制定的策略（如应用权限或访问控制列表）虽不完美但基本够用。但随着通用智能代理（如自动化个人助手）的兴起，其多任务能力和广泛情境要求重新设计安全机制。本文提出Conseca框架，旨在生成即时、情境化且可人工验证的安全策略，作为适应智能代理安全需求的第一步。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-20T02:31:53Z
- **目录日期**: 2025-04-20
