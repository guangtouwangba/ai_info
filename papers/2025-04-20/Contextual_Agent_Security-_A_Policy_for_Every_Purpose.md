# Contextual Agent Security: A Policy for Every Purpose

**URL**: http://arxiv.org/abs/2501.17070v3

## 原始摘要

Judging an action's safety requires knowledge of the context in which the
action takes place. To human agents who act in various contexts, this may seem
obvious: performing an action such as email deletion may or may not be
appropriate depending on the email's content, the goal (e.g., to erase
sensitive emails or to clean up trash), and the type of email address (e.g.,
work or personal). Unlike people, computational systems have often had only
limited agency in limited contexts. Thus, manually crafted policies and user
confirmation (e.g., smartphone app permissions or network access control
lists), while imperfect, have sufficed to restrict harmful actions. However,
with the upcoming deployment of generalist agents that support a multitude of
tasks (e.g., an automated personal assistant), we argue that we must rethink
security designs to adapt to the scale of contexts and capabilities of these
systems. As a first step, this paper explores contextual security in the domain
of agents and proposes contextual agent security (Conseca), a framework to
generate just-in-time, contextual, and human-verifiable security policies.


## AI 摘要

本文探讨了计算系统在执行操作时需要考虑上下文环境的安全性问题。与人类不同，传统计算系统通常只能在有限情境下运行，依赖手动制定的策略和用户确认来限制有害行为。但随着多功能智能代理（如自动化个人助手）的出现，其广泛的任务执行能力要求安全设计必须适应多样化的上下文环境。为此，研究提出了"上下文代理安全"（Conseca）框架，旨在生成即时、基于上下文且可人工验证的安全策略，以应对这些系统在复杂环境中的安全挑战。该研究为智能代理的安全设计提供了新的思路。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-20T15:02:35Z
- **目录日期**: 2025-04-20
