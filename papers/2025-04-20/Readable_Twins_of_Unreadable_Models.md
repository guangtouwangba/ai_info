# Readable Twins of Unreadable Models

**URL**: http://arxiv.org/abs/2504.13150v1

## 原始摘要

Creating responsible artificial intelligence (AI) systems is an important
issue in contemporary research and development of works on AI. One of the
characteristics of responsible AI systems is their explainability. In the
paper, we are interested in explainable deep learning (XDL) systems. On the
basis of the creation of digital twins of physical objects, we introduce the
idea of creating readable twins (in the form of imprecise information flow
models) for unreadable deep learning models. The complete procedure for
switching from the deep learning model (DLM) to the imprecise information flow
model (IIFM) is presented. The proposed approach is illustrated with an example
of a deep learning classification model for image recognition of handwritten
digits from the MNIST data set.


## AI 摘要

本文探讨了可解释深度学习（XDL）系统在构建负责任AI中的重要性。研究者提出通过创建物理对象的数字孪生，为不可读的深度学习模型建立可读孪生（以不精确信息流模型IIFM形式）。论文完整阐述了从深度学习模型（DLM）到IIFM的转换流程，并以MNIST手写数字图像识别分类模型为例进行了验证。该方法旨在提升AI系统的可解释性，这是负责任AI的关键特征之一。研究通过将复杂模型转化为可理解的近似模型，为深度学习系统的透明化提供了新思路。（100字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-20T13:06:25Z
- **目录日期**: 2025-04-20
