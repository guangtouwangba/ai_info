# How Adding Metacognitive Requirements in Support of AI Feedback in Practice Exams Transforms Student Learning Behaviors

**URL**: http://arxiv.org/abs/2505.13381v1

## 原始摘要

Providing personalized, detailed feedback at scale in large undergraduate
STEM courses remains a persistent challenge. We present an empirically
evaluated practice exam system that integrates AI generated feedback with
targeted textbook references, deployed in a large introductory biology course.
Our system encourages metacognitive behavior by asking students to explain
their answers and declare their confidence. It uses OpenAI's GPT-4o to generate
personalized feedback based on this information, while directing them to
relevant textbook sections. Through interaction logs from consenting
participants across three midterms (541, 342, and 413 students respectively),
totaling 28,313 question-student interactions across 146 learning objectives,
along with 279 surveys and 23 interviews, we examined the system's impact on
learning outcomes and engagement. Across all midterms, feedback types showed no
statistically significant performance differences, though some trends suggested
potential benefits. The most substantial impact came from the required
confidence ratings and explanations, which students reported transferring to
their actual exam strategies. About 40 percent of students engaged with
textbook references when prompted by feedback -- far higher than traditional
reading rates. Survey data revealed high satisfaction (mean rating 4.1 of 5),
with 82.1 percent reporting increased confidence on practiced midterm topics,
and 73.4 percent indicating they could recall and apply specific concepts. Our
findings suggest that embedding structured reflection requirements may be more
impactful than sophisticated feedback mechanisms.


## AI 摘要

这项研究在大型生物学课程中测试了一个结合AI反馈的练习考试系统。系统要求学生解释答案并评估自信度，利用GPT-4生成个性化反馈并提供教材参考。通过对近30,000次答题数据的分析发现，虽然不同反馈形式对成绩影响不显著，但强制自信度评估和解释要求显著影响了学生的考试策略。约40%学生查看了教材参考（远高于传统阅读率），82.1%表示提升了信心，73.4%能更好应用概念。研究表明，结构化反思要求比复杂反馈机制更能促进学习，系统获得较高满意度（平均4.1/5分）。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-20T05:01:24Z
- **目录日期**: 2025-05-20
