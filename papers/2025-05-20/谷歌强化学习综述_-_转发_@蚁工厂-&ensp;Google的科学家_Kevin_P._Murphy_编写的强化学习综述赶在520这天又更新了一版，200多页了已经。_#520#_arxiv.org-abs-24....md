# 谷歌强化学习综述 - 转发 @蚁工厂:&ensp;Google的科学家 Kevin P. Murphy 编写的强化学习综述赶在520这天又更新了一版，200多页了已经。 #520# arxiv.org/abs/24...

**URL**: https://weibo.com/6105753431/PsGWXyemR

## 原始摘要

谷歌强化学习综述<br><blockquote> - 转发 <a href="https://weibo.com/2194035935" target="_blank">@蚁工厂</a>: Google的科学家 Kevin P. Murphy 编写的强化学习综述赶在520这天又更新了一版，200多页了已经。 <a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23520%23&amp;isnewpage=1" data-hide=""><span class="surl-text">#520#</span></a> <br>arxiv.org/abs/2412.05265<br>新版在LLM 章节进行了重大更新（例如 DPO、GRPO、思考部分）。<br>全篇综合性的介绍了强化学习（Reinforcement Learning, RL）的理论基础、方法、应用及其最新进展。文章从序贯决策制定的基本概念出发，详细介绍了值函数、策略梯度和基于模型的强化学习方法，并探讨了多智能体强化学习、大语言模型（LLM）与强化学习的结合等前沿领域。<br><br><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BE%AE%E5%8D%9A%E5%85%B4%E8%B6%A3%E5%88%9B%E4%BD%9C%E8%AE%A1%E5%88%92%23&amp;extparam=%23%E5%BE%AE%E5%8D%9A%E5%85%B4%E8%B6%A3%E5%88%9B%E4%BD%9C%E8%AE%A1%E5%88%92%23" data-hide=""><span class="surl-text">#微博兴趣创作计划#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%89%A9%23" data-hide=""><span class="surl-text">#互联网人物#</span></a><img style="" src="https://tvax4.sinaimg.cn/large/82c654dfly1i1luhr1siwj20vb17776o.jpg" referrerpolicy="no-referrer"><br><br></blockquote>

## AI 摘要

谷歌科学家Kevin P. Murphy更新的强化学习综述（200多页）系统梳理了该领域的理论与应用进展。内容涵盖序贯决策基础、值函数/策略梯度/基于模型的方法三大范式，并新增多智能体RL和大语言模型（LLM）结合的前沿方向，特别在LLM章节重点更新了DPO、GRPO等优化方法及"思考"机制。该综述兼具基础理论与最新突破（如RL与LLM协同），反映了强化学习从传统算法到AI融合应用的发展趋势。论文链接：arxiv.org/abs/2412.05265

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-20T07:03:11Z
- **目录日期**: 2025-05-20
