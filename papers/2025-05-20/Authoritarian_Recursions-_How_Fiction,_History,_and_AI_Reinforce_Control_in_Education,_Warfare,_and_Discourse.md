# Authoritarian Recursions: How Fiction, History, and AI Reinforce Control in Education, Warfare, and Discourse

**URL**: http://arxiv.org/abs/2504.09030v2

## 原始摘要

This article introduces the concept of \textit{authoritarian recursion} to
describe how artificial intelligence (AI) systems increasingly mediate control
across education, warfare, and digital discourse. Drawing on critical discourse
analysis and sociotechnical theory, the study reveals how AI-driven platforms
delegate judgment to algorithmic processes, normalize opacity, and recursively
reinforce behavioral norms under the guise of neutrality and optimization. Case
studies include generative AI models in classroom surveillance, autonomous
targeting in military AI systems, and content curation logics in platform
governance.
  Rather than treating these domains as disparate, the paper maps their
structural convergence within recursive architectures of abstraction,
surveillance, and classification. These feedback systems do not simply automate
tasks -- they encode modes of epistemic authority that disperse accountability
while intensifying political asymmetries. Through cultural and policy analysis,
the article argues that authoritarian recursion operates as a hybrid logic,
fusing technical abstraction with state and market imperatives. The paper
concludes by outlining implications for democratic legitimacy, human oversight,
and the political design of AI governance frameworks.
  This framework contributes to emerging debates on algorithmic accountability
by foregrounding how recursion acts not merely as a technical function but as a
sociopolitical instrument of control.


## AI 摘要

本文提出"威权递归"概念，揭示AI系统如何通过算法中介在教育、军事和数字话语中实施控制。研究显示，AI平台将判断权委托给算法流程，以中立和优化之名掩盖不透明性，递归强化行为规范。案例包括课堂监控的生成式AI、军事AI的自主瞄准系统及平台内容管理逻辑。这些递归架构融合技术抽象与国家/市场需求，通过监控分类形成反馈系统，不仅自动化任务，更编码认知权威模式，分散责任的同时加剧政治不对称。研究强调递归不仅是技术功能，更是社会政治控制工具，对民主监督和AI治理框架提出警示。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-20T00:02:33Z
- **目录日期**: 2025-05-20
