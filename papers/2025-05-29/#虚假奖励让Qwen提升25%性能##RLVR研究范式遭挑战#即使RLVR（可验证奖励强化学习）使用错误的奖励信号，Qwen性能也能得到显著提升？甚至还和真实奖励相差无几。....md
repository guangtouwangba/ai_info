# #虚假奖励让Qwen提升25%性能##RLVR研究范式遭挑战#即使RLVR（可验证奖励强化学习）使用错误的奖励信号，Qwen性能也能得到显著提升？甚至还和真实奖励相差无几。...

**URL**: https://weibo.com/6105753431/Pu4b86HyB

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%99%9A%E5%81%87%E5%A5%96%E5%8A%B1%E8%AE%A9Qwen%E6%8F%90%E5%8D%8725%25%E6%80%A7%E8%83%BD%23&amp;extparam=%23%E8%99%9A%E5%81%87%E5%A5%96%E5%8A%B1%E8%AE%A9Qwen%E6%8F%90%E5%8D%8725%25%E6%80%A7%E8%83%BD%23" data-hide=""><span class="surl-text">#虚假奖励让Qwen提升25%性能#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23RLVR%E7%A0%94%E7%A9%B6%E8%8C%83%E5%BC%8F%E9%81%AD%E6%8C%91%E6%88%98%23&amp;extparam=%23RLVR%E7%A0%94%E7%A9%B6%E8%8C%83%E5%BC%8F%E9%81%AD%E6%8C%91%E6%88%98%23" data-hide=""><span class="surl-text">#RLVR研究范式遭挑战#</span></a><br><br>即使RLVR（可验证奖励强化学习）使用错误的奖励信号，Qwen性能也能得到显著提升？<br><br>甚至还和真实奖励相差无几。<br><br>自从RLVR被DeepSeek-R1带火，RL推理研究层出不穷，走进了蜜月期。<br><br>这不，来自华盛顿大学的一群博士生来火上浇油了——<br><br>使用Qwen模型（尤其是数学版本），对虚假奖励进行RLVR，仍然可以将MATH-500的绝对准确率显著提升约25%。<br><br>团队实验发现：“RLVR通过激活预训练中的推理能力来提升性能，但不考虑奖励信号的正确性。”【图1】<br><br>这彻底颠覆了既往大家对RLVR的认知，原来那些年在虚假奖励上踩过的坑，还真能实现弯道超车？<br><br>X上的网友们纷纷表示，强烈建议每位RLVR研究员都来读一读，尤其是那些围绕Qwen模型精心构造奖励函数的研究员们，该瑟瑟发抖了……【图2】<br><br>Qwen自家的研究员Binyuan Hui也在评论区现身：<br><br>“也许是预训练数据混合以某种方式意外导致了一些有用的行为，又一次侧面印证了代码推理的重要性。”【图3】<br><br>具体啥情况？下面我们娓娓道来：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJ54SU9M-h8v2Mz2AJdXJXA" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">奖励是假的，能让Qwen提升25%性能却是真的！</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1wdy30uptj30us0e4gum.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1wdy4zgpkj30wk0ein3y.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i1wdy6lgjpj30x20eygsa.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

华盛顿大学团队研究发现，即使使用虚假奖励信号进行RLVR（可验证奖励强化学习），Qwen数学模型的MATH-500准确率仍能提升约25%，效果接近真实奖励。这一发现颠覆了传统认知，表明RLVR可能通过激活预训练推理能力而非依赖奖励正确性来提升性能。Qwen研究员推测可能与预训练数据混合或代码推理能力有关。该结果对RLVR研究范式提出挑战，引发学界广泛讨论，尤其影响依赖精心设计奖励函数的研究方向。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-29T09:04:11Z
- **目录日期**: 2025-05-29
