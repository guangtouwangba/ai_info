# Benchmarking Synthetic Tabular Data: A Multi-Dimensional Evaluation Framework

**URL**: http://arxiv.org/abs/2504.01908v1

## 原始摘要

Evaluating the quality of synthetic data remains a key challenge for ensuring
privacy and utility in data-driven research. In this work, we present an
evaluation framework that quantifies how well synthetic data replicates
original distributional properties while ensuring privacy. The proposed
approach employs a holdout-based benchmarking strategy that facilitates
quantitative assessment through low- and high-dimensional distribution
comparisons, embedding-based similarity measures, and nearest-neighbor distance
metrics. The framework supports various data types and structures, including
sequential and contextual information, and enables interpretable quality
diagnostics through a set of standardized metrics. These contributions aim to
support reproducibility and methodological consistency in benchmarking of
synthetic data generation techniques. The code of the framework is available at
https://github.com/mostly-ai/mostlyai-qa.


## AI 摘要

本文提出了一种评估合成数据质量的框架，通过量化合成数据对原始数据分布属性的复现程度，同时兼顾隐私保护。该框架采用保留集基准测试策略，结合低维/高维分布对比、嵌入相似度测量和最近邻距离指标进行量化评估，适用于多种数据类型（包括序列和上下文信息），并通过标准化指标提供可解释的质量诊断。该方案旨在提升合成数据生成技术的可复现性和方法一致性，相关代码已开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-03T10:02:00Z
- **目录日期**: 2025-04-03
