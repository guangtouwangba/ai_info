# Should AI Optimize Your Code? A Comparative Study of Classical Optimizing Compilers Versus Current Large Language Models

**URL**: http://arxiv.org/abs/2406.12146v2

## 原始摘要

Traditional optimizing compilers have played an important role in adapting to
the growing complexity of modern software systems. The need for efficient
parallel programming in current architectures requires strong optimization
techniques. The beginning of Large Language Models (LLMs) raises intriguing
questions about the potential of these AI approaches to revolutionize code
optimization methodologies. This work aims to answer an essential question for
the compiler community: "Can AI-driven models revolutionize the way we approach
code optimization?".
  To address this question, we present a comparative analysis between three
classical optimizing compilers and two recent large language models, evaluating
their respective abilities and limitations in optimizing code for maximum
efficiency. In addition, we introduce a benchmark suite of challenging
optimization patterns and an automatic mechanism for evaluating the performance
and correctness of the code generated by LLMs. We used three different
prompting strategies to evaluate the performance of the LLMs, Simple
Instruction (IP), Detailed Instruction Prompting (DIP), and Chain of Thought
(CoT).
  A key finding is that while LLMs have the potential to outperform current
optimizing compilers, they often generate incorrect code on large code sizes,
calling for automated verification methods. In addition, expressing a compiler
strategy as part of the LLMs prompt substantially improves its overall
performance. Our evaluation across three benchmark suites shows CodeLlama-70B
as the superior LLM, capable of achieving speedups of up to x1.75.
Additionally, CETUS is the best among the current optimizing compilers,
achieving a maximum speedup of 1.67x. We also found substantial differences
among the three prompting strategies.


## AI 摘要

传统优化编译器在现代软件系统发展中至关重要，但并行编程的需求和大型语言模型（LLM）的兴起引发了AI驱动代码优化的潜力探讨。本研究比较了三种传统编译器与两种LLM的优化能力，并开发了包含挑战性优化模式的基准测试套件及自动评估机制。结果显示，LLM（如CodeLlama-70B）最高可实现1.75倍加速，优于传统编译器（如CETUS的1.67倍），但大代码量时易生成错误结果，需自动化验证。提示策略对性能影响显著，其中将编译器策略融入提示可大幅提升LLM表现。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-03T20:02:27Z
- **目录日期**: 2025-04-03
