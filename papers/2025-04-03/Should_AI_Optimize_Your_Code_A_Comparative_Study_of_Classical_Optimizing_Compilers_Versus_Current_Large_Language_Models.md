# Should AI Optimize Your Code? A Comparative Study of Classical Optimizing Compilers Versus Current Large Language Models

**URL**: http://arxiv.org/abs/2406.12146v2

## 原始摘要

Traditional optimizing compilers have played an important role in adapting to
the growing complexity of modern software systems. The need for efficient
parallel programming in current architectures requires strong optimization
techniques. The beginning of Large Language Models (LLMs) raises intriguing
questions about the potential of these AI approaches to revolutionize code
optimization methodologies. This work aims to answer an essential question for
the compiler community: "Can AI-driven models revolutionize the way we approach
code optimization?".
  To address this question, we present a comparative analysis between three
classical optimizing compilers and two recent large language models, evaluating
their respective abilities and limitations in optimizing code for maximum
efficiency. In addition, we introduce a benchmark suite of challenging
optimization patterns and an automatic mechanism for evaluating the performance
and correctness of the code generated by LLMs. We used three different
prompting strategies to evaluate the performance of the LLMs, Simple
Instruction (IP), Detailed Instruction Prompting (DIP), and Chain of Thought
(CoT).
  A key finding is that while LLMs have the potential to outperform current
optimizing compilers, they often generate incorrect code on large code sizes,
calling for automated verification methods. In addition, expressing a compiler
strategy as part of the LLMs prompt substantially improves its overall
performance. Our evaluation across three benchmark suites shows CodeLlama-70B
as the superior LLM, capable of achieving speedups of up to x1.75.
Additionally, CETUS is the best among the current optimizing compilers,
achieving a maximum speedup of 1.67x. We also found substantial differences
among the three prompting strategies.


## AI 摘要

传统优化编译器在现代软件系统的复杂性管理中发挥了重要作用。随着并行编程需求的增长，高效的优化技术变得至关重要。本研究探讨了大型语言模型（LLMs）是否能够革新代码优化方法。通过对比三种传统编译器与两种LLMs的性能，并引入一套优化模式基准测试和自动评估机制，研究发现：虽然LLMs（如CodeLlama-70B）在某些情况下能实现最高1.75倍的加速，优于传统编译器（如CETUS的1.67倍），但其在大规模代码中易生成错误结果，需结合自动化验证方法。此外，将编译器策略融入提示词能显著提升LLMs表现，且不同提示策略效果差异显著。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-03T16:02:38Z
- **目录日期**: 2025-04-03
