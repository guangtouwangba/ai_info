# Beyond the Hype: A dispassionate look at vision-language models in medical scenario

**URL**: http://arxiv.org/abs/2408.08704v2

## 原始摘要

Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated
remarkable capabilities across diverse tasks, garnering significant attention
in AI communities. However, their performance and reliability in specialized
domains such as medicine remain insufficiently assessed. In particular, most
assessments over-concentrate on evaluating VLMs based on simple Visual Question
Answering (VQA) on multi-modality data, while ignoring the in-depth
characteristics of LVLMs. In this study, we introduce RadVUQA, a novel
Radiological Visual Understanding and Question Answering benchmark, to
comprehensively evaluate existing LVLMs. RadVUQA mainly validates LVLMs across
five dimensions: 1) Anatomical understanding, assessing the models' ability to
visually identify biological structures; 2) Multimodal comprehension, which
involves the capability of interpreting linguistic and visual instructions to
produce desired outcomes; 3) Quantitative and spatial reasoning, evaluating the
models' spatial awareness and proficiency in combining quantitative analysis
with visual and linguistic information; 4) Physiological knowledge, measuring
the models' capability to comprehend functions and mechanisms of organs and
systems; and 5) Robustness, which assesses the models' capabilities against
unharmonized and synthetic data. The results indicate that both generalized
LVLMs and medical-specific LVLMs have critical deficiencies with weak
multimodal comprehension and quantitative reasoning capabilities. Our findings
reveal the large gap between existing LVLMs and clinicians, highlighting the
urgent need for more robust and intelligent LVLMs. The code is available at
https://github.com/Nandayang/RadVUQA


## AI 摘要

近期大型视觉语言模型(LVLMs)在多个领域展现出强大能力，但在医学等专业领域的表现尚未充分评估。研究者提出RadVUQA基准测试，从五个维度系统评估LVLMs：1)解剖结构识别能力；2)多模态理解能力；3)定量与空间推理能力；4)生理知识掌握程度；5)对抗不协调和合成数据的鲁棒性。测试结果表明，无论是通用LVLMs还是医学专用LVLMs都存在显著缺陷，特别是在多模态理解和定量推理方面表现薄弱。研究揭示了现有模型与临床医生之间的巨大差距，亟需开发更强大、更智能的LVLMs。代码已开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-10T03:15:32Z
- **目录日期**: 2025-04-10
