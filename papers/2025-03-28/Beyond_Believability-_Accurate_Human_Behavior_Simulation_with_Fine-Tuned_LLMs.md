# Beyond Believability: Accurate Human Behavior Simulation with Fine-Tuned LLMs

**URL**: http://arxiv.org/abs/2503.20749v1

## 原始摘要

Recent research shows that LLMs can simulate ``believable'' human behaviors
to power LLM agents via prompt-only methods. In this work, we focus on
evaluating and improving LLM's objective ``accuracy'' rather than the
subjective ``believability'' in the web action generation task, leveraging a
large-scale, real-world dataset collected from online shopping human actions.
We present the first comprehensive quantitative evaluation of state-of-the-art
LLMs (e.g., DeepSeek-R1, Llama, and Claude) on the task of web action
generation. Our results show that fine-tuning LLMs on real-world behavioral
data substantially improves their ability to generate actions compared to
prompt-only methods. Furthermore, incorporating synthesized reasoning traces
into model training leads to additional performance gains, demonstrating the
value of explicit rationale in behavior modeling. This work establishes a new
benchmark for evaluating LLMs in behavior simulation and offers actionable
insights into how real-world action data and reasoning augmentation can enhance
the fidelity of LLM agents.


## AI 摘要

最新研究表明，通过仅使用提示方法，大语言模型（LLM）可以模拟可信的人类行为以驱动LLM智能体。本研究基于真实网购行为数据集，重点评估并提升LLM在网页操作生成任务中的客观"准确性"而非主观"可信度"。实验对DeepSeek-R1、Llama和Claude等前沿模型进行了首次全面量化评估。结果显示：1）基于真实行为数据的微调显著优于纯提示方法；2）加入合成推理轨迹能进一步提升性能，说明显式逻辑对行为建模的价值。该工作建立了行为模拟的新基准，揭示了真实行为数据和推理增强对提升LLM智能体保真度的作用。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-03-28T00:01:55Z
- **目录日期**: 2025-03-28
