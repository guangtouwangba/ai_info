# #大模型安全全景图##首个大模型全链路安全综述#大模型火了，但它安全吗？对于这个问题，南洋理工、新加坡国立等超40家机构的67位学者，发布了首个大模型全链路安...

**URL**: https://weibo.com/6105753431/PoUfi96EE

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E5%85%A8%E6%99%AF%E5%9B%BE%23&amp;extparam=%23%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E5%85%A8%E6%99%AF%E5%9B%BE%23" data-hide=""><span class="surl-text">#大模型安全全景图#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E9%A6%96%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%AE%89%E5%85%A8%E7%BB%BC%E8%BF%B0%23&amp;extparam=%23%E9%A6%96%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%AE%89%E5%85%A8%E7%BB%BC%E8%BF%B0%23" data-hide=""><span class="surl-text">#首个大模型全链路安全综述#</span></a><br><br>大模型火了，但它安全吗？<br><br>对于这个问题，南洋理工、新加坡国立等超40家机构的67位学者，发布了首个大模型全链路安全综述。<br><br>他们系统梳理了843篇研究，首次把大模型从“出生”到“落地”的各阶段安全问题做了盘点。<br><br>这份综述覆盖范围广，几乎囊括了当前主流的单模态、多模态LLM与智能体（Agent）系统。研究内容从数据采集、预训练、微调、对齐、部署，一直到商业应用和安全评估全流程，整理出一个完整的大模型安全知识图谱。<br><br>文章从不同阶段剖析了当前大模型安全问题，简单划重点👇<br><br>1. 数据阶段：模型可能“记住”个人信息或被喂入带后门的样本，0.1%的数据污染都可能搞坏模型；防御靠数据清洗和差分隐私。<br><br>2. 微调阶段：指令注入、后门攻击、联邦学习中的梯度污染，都可能让模型在关键触发词下“暴走”；对策是多模态审核+鲁棒训练。<br><br>3. 对齐阶段：人类反馈也可能被“毒化”，奖励机制被操控，导致模型输出“伪合规”回答；需引入事实验证和触发器检测机制。<br><br>4. 模型遗忘（Unlearning）：不当删除可能损伤能力，还可能被反利用引入偏见；应结合参数干预+输出过滤来做安全回滚。<br><br>5. 部署阶段：提示注入、模型提取、越狱攻击正在变得复杂和高效；应通过对抗净化、输出过滤和系统防护多层把关。<br><br>6. 商业应用：LLM在医疗、金融、法律等场景可能误伤严重，幻觉、偏见和隐私风险仍未完全解决；技术+治理需协同推进。<br><br>这篇综述为AI从业者、监管者和产品设计者提供了系统性参考。如何构建可信、安全的AI系统，是未来研究者需要思考的问题。<br><br>感兴趣的小伙伴可以点击：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2504.15585" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0t4lcdn06j30ts0k0qfe.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0t4lbrm4gj30nv0k0k7y.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0t4lbyoglj30k00pi4ak.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0t4lca7lqj30xp0k0duw.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0t4lc1ggwj30zk0eok3q.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0t4lbxc4rj30oz0k0wq2.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

这篇由67位学者联合发布的综述首次系统梳理了大模型全链路安全问题，涵盖843篇研究。研究指出大模型从数据采集到商业应用各阶段均存在风险：数据阶段可能记忆隐私或被污染；微调阶段易受指令注入攻击；对齐阶段可能被"毒化"反馈操控；部署阶段面临提示注入等新型攻击；商业应用中幻觉/偏见风险突出。防御需结合数据清洗、多模态审核、事实验证等综合措施。该研究为构建可信AI提供了首个全景式安全框架，强调技术治理需协同推进。论文链接：https://arxiv.org/abs/2504.15585

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-25T21:03:32Z
- **目录日期**: 2025-04-25
