# A Measure Based Generalizable Approach to Understandability

**URL**: http://arxiv.org/abs/2503.21615v2

## 原始摘要

Successful agent-human partnerships require that any agent generated
information is understandable to the human, and that the human can easily steer
the agent towards a goal. Such effective communication requires the agent to
develop a finer-level notion of what is understandable to the human.
State-of-the-art agents, including LLMs, lack this detailed notion of
understandability because they only capture average human sensibilities from
the training data, and therefore afford limited steerability (e.g., requiring
non-trivial prompt engineering).
  In this paper, instead of only relying on data, we argue for developing
generalizable, domain-agnostic measures of understandability that can be used
as directives for these agents. Existing research on understandability measures
is fragmented, we survey various such efforts across domains, and lay a
cognitive-science-rooted groundwork for more coherent and domain-agnostic
research investigations in future.


## AI 摘要

本文探讨如何提升智能体与人类的有效协作，关键在于智能体需精准理解人类可接受的信息表达方式。当前主流智能体（如大语言模型）仅依赖训练数据的平均人类认知，缺乏细粒度可理解性评估，导致可操控性受限（如依赖复杂提示工程）。作者主张开发通用、领域无关的可理解性衡量标准作为智能体指导原则，而非仅依赖数据。通过梳理跨领域相关研究碎片化现状，本文以认知科学为基础，为未来更系统、领域无关的可理解性研究奠定基础，旨在增强人机交互的自然性与目标导向性。（100字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-25T00:02:11Z
- **目录日期**: 2025-04-25
