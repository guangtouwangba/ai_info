# Solving General-Utility Markov Decision Processes in the Single-Trial Regime with Online Planning

**URL**: http://arxiv.org/abs/2505.15782v1

## 原始摘要

In this work, we contribute the first approach to solve infinite-horizon
discounted general-utility Markov decision processes (GUMDPs) in the
single-trial regime, i.e., when the agent's performance is evaluated based on a
single trajectory. First, we provide some fundamental results regarding policy
optimization in the single-trial regime, investigating which class of policies
suffices for optimality, casting our problem as a particular MDP that is
equivalent to our original problem, as well as studying the computational
hardness of policy optimization in the single-trial regime. Second, we show how
we can leverage online planning techniques, in particular a Monte-Carlo tree
search algorithm, to solve GUMDPs in the single-trial regime. Third, we provide
experimental results showcasing the superior performance of our approach in
comparison to relevant baselines.


## AI 摘要

本文首次提出了解决无限时域折扣通用效用马尔可夫决策过程(GUMDP)的单次试验优化方法。研究首先分析了单次试验场景下的策略优化基础问题，包括最优策略类别、等效MDP转化以及计算复杂度。其次，提出利用在线规划技术(特别是蒙特卡洛树搜索算法)来求解单次试验GUMDP。实验结果表明，该方法性能显著优于基线模型。该工作为单次试验场景下的决策优化提供了首个系统性解决方案，兼具理论创新和实用价值。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-22T22:02:02Z
- **目录日期**: 2025-05-22
