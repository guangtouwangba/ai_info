# Solving General-Utility Markov Decision Processes in the Single-Trial Regime with Online Planning

**URL**: http://arxiv.org/abs/2505.15782v1

## 原始摘要

In this work, we contribute the first approach to solve infinite-horizon
discounted general-utility Markov decision processes (GUMDPs) in the
single-trial regime, i.e., when the agent's performance is evaluated based on a
single trajectory. First, we provide some fundamental results regarding policy
optimization in the single-trial regime, investigating which class of policies
suffices for optimality, casting our problem as a particular MDP that is
equivalent to our original problem, as well as studying the computational
hardness of policy optimization in the single-trial regime. Second, we show how
we can leverage online planning techniques, in particular a Monte-Carlo tree
search algorithm, to solve GUMDPs in the single-trial regime. Third, we provide
experimental results showcasing the superior performance of our approach in
comparison to relevant baselines.


## AI 摘要

本文首次提出了解决无限时域折扣通用效用马尔可夫决策过程(GUMDP)的单次试验优化方法。研究揭示了单次试验场景下的策略优化基本特性，包括最优策略类别、问题转化方法及其计算复杂度。作者创新性地将在线规划技术(特别是蒙特卡洛树搜索算法)应用于该场景的GUMDP求解。实验结果表明，该方法在单次试验评估机制下显著优于现有基线方法。这项工作为单轨迹评估场景下的决策优化提供了理论基础和实用算法框架。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-22T04:03:35Z
- **目录日期**: 2025-05-22
