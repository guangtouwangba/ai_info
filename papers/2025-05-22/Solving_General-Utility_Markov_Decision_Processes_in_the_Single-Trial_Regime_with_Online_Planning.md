# Solving General-Utility Markov Decision Processes in the Single-Trial Regime with Online Planning

**URL**: http://arxiv.org/abs/2505.15782v1

## 原始摘要

In this work, we contribute the first approach to solve infinite-horizon
discounted general-utility Markov decision processes (GUMDPs) in the
single-trial regime, i.e., when the agent's performance is evaluated based on a
single trajectory. First, we provide some fundamental results regarding policy
optimization in the single-trial regime, investigating which class of policies
suffices for optimality, casting our problem as a particular MDP that is
equivalent to our original problem, as well as studying the computational
hardness of policy optimization in the single-trial regime. Second, we show how
we can leverage online planning techniques, in particular a Monte-Carlo tree
search algorithm, to solve GUMDPs in the single-trial regime. Third, we provide
experimental results showcasing the superior performance of our approach in
comparison to relevant baselines.


## AI 摘要

本文首次提出了在单次试验条件下解决无限时间折扣通用效用马尔可夫决策过程(GUMDP)的方法。研究首先分析了单次试验场景下的策略优化基础问题，包括最优策略类别、等效MDP转换以及计算复杂度。其次，提出利用在线规划技术(特别是蒙特卡洛树搜索算法)来解决该问题。实验结果表明，该方法在性能上显著优于现有基线方案。该研究为单次评估场景下的决策优化提供了理论框架和实用算法。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-22T10:02:09Z
- **目录日期**: 2025-05-22
