# Solving General-Utility Markov Decision Processes in the Single-Trial Regime with Online Planning

**URL**: http://arxiv.org/abs/2505.15782v1

## 原始摘要

In this work, we contribute the first approach to solve infinite-horizon
discounted general-utility Markov decision processes (GUMDPs) in the
single-trial regime, i.e., when the agent's performance is evaluated based on a
single trajectory. First, we provide some fundamental results regarding policy
optimization in the single-trial regime, investigating which class of policies
suffices for optimality, casting our problem as a particular MDP that is
equivalent to our original problem, as well as studying the computational
hardness of policy optimization in the single-trial regime. Second, we show how
we can leverage online planning techniques, in particular a Monte-Carlo tree
search algorithm, to solve GUMDPs in the single-trial regime. Third, we provide
experimental results showcasing the superior performance of our approach in
comparison to relevant baselines.


## AI 摘要

本文提出了首个解决无限时间折扣广义效用马尔可夫决策过程(GUMDP)单次试验优化问题的方法。研究首先分析了单次试验场景下的策略优化基础问题，包括最优策略类别、等效MDP转换及计算复杂度。其次，创新性地将在线规划技术(特别是蒙特卡洛树搜索算法)应用于单次试验GUMDP求解。实验结果表明，该方法在性能上显著优于现有基线模型。该研究填补了广义效用MDP在单次评估场景下的算法空白，为实际应用中基于单次轨迹的决策优化提供了有效解决方案。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-22T16:02:11Z
- **目录日期**: 2025-05-22
