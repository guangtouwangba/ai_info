# TracLLM: A Generic Framework for Attributing Long Context LLMs

**URL**: http://arxiv.org/abs/2506.04202v1

## 原始摘要

Long context large language models (LLMs) are deployed in many real-world
applications such as RAG, agent, and broad LLM-integrated applications. Given
an instruction and a long context (e.g., documents, PDF files, webpages), a
long context LLM can generate an output grounded in the provided context,
aiming to provide more accurate, up-to-date, and verifiable outputs while
reducing hallucinations and unsupported claims. This raises a research
question: how to pinpoint the texts (e.g., sentences, passages, or paragraphs)
in the context that contribute most to or are responsible for the generated
output by an LLM? This process, which we call context traceback, has various
real-world applications, such as 1) debugging LLM-based systems, 2) conducting
post-attack forensic analysis for attacks (e.g., prompt injection attack,
knowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources
to enhance the trust of users towards outputs generated by LLMs. When applied
to context traceback for long context LLMs, existing feature attribution
methods such as Shapley have sub-optimal performance and/or incur a large
computational cost. In this work, we develop TracLLM, the first generic context
traceback framework tailored to long context LLMs. Our framework can improve
the effectiveness and efficiency of existing feature attribution methods. To
improve the efficiency, we develop an informed search based algorithm in
TracLLM. We also develop contribution score ensemble/denoising techniques to
improve the accuracy of TracLLM. Our evaluation results show TracLLM can
effectively identify texts in a long context that lead to the output of an LLM.
Our code and data are at: https://github.com/Wang-Yanting/TracLLM.


## AI 摘要

这篇论文提出了TracLLM框架，旨在解决长上下文大语言模型(LLM)的"上下文回溯"问题——即识别生成输出所依赖的具体文本片段。现有特征归因方法(如Shapley)在长上下文场景下效果欠佳且计算成本高。TracLLM通过基于信息搜索的算法提高效率，并采用贡献分数集成/去噪技术提升准确性。该框架可应用于LLM系统调试、攻击后取证分析(如提示注入攻击)以及增强用户对输出的信任。实验表明，TracLLM能有效识别长上下文中影响LLM输出的关键文本。代码和数据已开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-06T02:30:53Z
- **目录日期**: 2025-06-06
