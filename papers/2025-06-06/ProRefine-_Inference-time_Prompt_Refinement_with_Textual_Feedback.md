# ProRefine: Inference-time Prompt Refinement with Textual Feedback

**URL**: http://arxiv.org/abs/2506.05305v1

## 原始摘要

Agentic workflows, where multiple AI agents collaborate to accomplish complex
tasks like reasoning or planning, are becoming increasingly prevalent. However,
these workflows often suffer from error propagation and sub-optimal
performance, largely due to poorly designed prompts that fail to effectively
guide individual agents. This is a critical problem because it limits the
reliability and scalability of these powerful systems. We introduce ProRefine,
an innovative inference-time prompt optimization method that leverages textual
feedback from large language models (LLMs) to address this challenge. ProRefine
dynamically refines prompts for multi-step reasoning tasks without additional
training or ground truth labels. Evaluated on five benchmark mathematical
reasoning datasets, ProRefine significantly surpasses zero-shot
Chain-of-Thought baselines by 3 to 37 percentage points. This approach not only
boosts accuracy but also allows smaller models to match the performance of
larger ones, highlighting its potential for efficient and scalable AI
deployment, and democratizing access to high-performing AI.


## AI 摘要

ProRefine是一种创新的提示优化方法，通过利用大语言模型（LLM）的文本反馈，动态优化多智能体协作工作流中的提示，无需额外训练或真实标签。该方法解决了现有智能体工作流中因提示设计不佳导致的错误传播和性能不佳问题。在五个数学推理基准测试中，ProRefine比零样本思维链基线性能提升3-37个百分点，显著提高准确性，还能使小模型达到与大模型相当的性能。这一技术提升了AI系统的可靠性和可扩展性，为高效部署高性能AI提供了新途径，有助于降低AI使用门槛。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-06T19:01:37Z
- **目录日期**: 2025-06-06
