# Embodied World Models Emerge from Navigational Task in Open-Ended Environments

**URL**: http://arxiv.org/abs/2504.11419v1

## 原始摘要

Understanding how artificial systems can develop spatial awareness and
reasoning has long been a challenge in AI research. Traditional models often
rely on passive observation, but embodied cognition theory suggests that deeper
understanding emerges from active interaction with the environment. This study
investigates whether neural networks can autonomously internalize spatial
concepts through interaction, focusing on planar navigation tasks. Using Gated
Recurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we
show that agents can learn to encode spatial properties like direction,
distance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS)
to model the agent-environment interaction as a closed dynamical system,
revealing stable limit cycles that correspond to optimal navigation strategies.
Ridge Representation allows us to map navigation paths into a fixed-dimensional
behavioral space, enabling comparison with neural states. Canonical Correlation
Analysis (CCA) confirms strong alignment between these representations,
suggesting that the agent's neural states actively encode spatial knowledge.
Intervention experiments further show that specific neural dimensions are
causally linked to navigation performance. This work provides an approach to
bridging the gap between action and perception in AI, offering new insights
into building adaptive, interpretable models that can generalize across complex
environments. The causal validation of neural representations also opens new
avenues for understanding and controlling the internal mechanisms of AI
systems, pushing the boundaries of how machines learn and reason in dynamic,
real-world scenarios.


## AI 摘要

这项研究探讨神经网络能否通过主动交互自主内化空间概念。研究者采用门控循环单元(GRU)和元强化学习(Meta-RL)方法，发现智能体可以学习编码方向、距离和避障等空间属性。通过混合动力系统(HDS)建模，揭示了对应最优导航策略的稳定极限环。脊表示法将导航路径映射到固定维度行为空间，典型相关分析(CCA)证实了神经状态与空间表征的强关联。干预实验表明特定神经维度与导航性能存在因果关系。该研究为构建可解释的自适应模型提供了新思路，推动了AI在动态环境中的学习与推理能力发展。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-16T13:10:21Z
- **目录日期**: 2025-04-16
