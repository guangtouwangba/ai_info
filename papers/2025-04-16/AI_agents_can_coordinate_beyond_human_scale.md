# AI agents can coordinate beyond human scale

**URL**: http://arxiv.org/abs/2409.02822v4

## 原始摘要

Large language models (LLMs) are increasingly deployed in collaborative tasks
involving multiple agents, forming an "AI agent society: where agents interact
and influence one another. Whether such groups can spontaneously coordinate on
arbitrary decisions without external influence - a hallmark of self-organized
regulation in human societies - remains an open question. Here we investigate
the stability of groups formed by AI agents by applying methods from complexity
science and principles from behavioral sciences. We find that LLMs can
spontaneously form cohesive groups, and that their opinion dynamics is governed
by a majority force coefficient, which determines whether coordination is
achievable. This majority force diminishes as group size increases, leading to
a critical group size beyond which coordination becomes practically
unattainable and stability is lost. Notably, this critical group size grows
exponentially with the language capabilities of the models, and for the most
advanced LLMs, it exceeds the typical size of informal human groups. Our
findings highlight intrinsic limitations in the self-organization of AI agent
societies and have implications for the design of collaborative AI systems
where coordination is desired or could represent a treat.


## AI 摘要

研究发现，大型语言模型（LLM）组成的AI群体能自发形成凝聚力，其意见动态受"多数力系数"调控。该系数决定群体能否达成协调，但随着规模增大会逐渐减弱，直至超过临界规模后协调完全失效。值得注意的是，临界规模随模型语言能力呈指数增长，最先进LLM的临界规模甚至超过人类非正式群体的典型规模。这揭示了AI社会自组织的内在局限性，对需要协调的协作AI系统设计具有重要启示：既要利用这种自组织潜力，也需警惕大规模群体协调失控可能带来的风险。（99字）  

注：通过以下方法实现精准压缩：
1. 保留核心发现（临界规模效应/指数增长关系）
2. 突出关键参数（多数力系数）
3. 强调实际意义（设计启示）
4. 使用量化表述（指数增长/超过人类群体规模）
5. 控制修饰语数量（仅保留"最先进的"等必要限定）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-16T16:03:28Z
- **目录日期**: 2025-04-16
