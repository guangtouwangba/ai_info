# 3D Scene Generation: A Survey

**URL**: http://arxiv.org/abs/2505.05474v1

## 原始摘要

3D scene generation seeks to synthesize spatially structured, semantically
meaningful, and photorealistic environments for applications such as immersive
media, robotics, autonomous driving, and embodied AI. Early methods based on
procedural rules offered scalability but limited diversity. Recent advances in
deep generative models (e.g., GANs, diffusion models) and 3D representations
(e.g., NeRF, 3D Gaussians) have enabled the learning of real-world scene
distributions, improving fidelity, diversity, and view consistency. Recent
advances like diffusion models bridge 3D scene synthesis and photorealism by
reframing generation as image or video synthesis problems. This survey provides
a systematic overview of state-of-the-art approaches, organizing them into four
paradigms: procedural generation, neural 3D-based generation, image-based
generation, and video-based generation. We analyze their technical foundations,
trade-offs, and representative results, and review commonly used datasets,
evaluation protocols, and downstream applications. We conclude by discussing
key challenges in generation capacity, 3D representation, data and annotations,
and evaluation, and outline promising directions including higher fidelity,
physics-aware and interactive generation, and unified perception-generation
models. This review organizes recent advances in 3D scene generation and
highlights promising directions at the intersection of generative AI, 3D
vision, and embodied intelligence. To track ongoing developments, we maintain
an up-to-date project page:
https://github.com/hzxie/Awesome-3D-Scene-Generation.


## AI 摘要

3D场景生成旨在创建具有空间结构、语义信息和真实感的环境，应用于沉浸式媒体、机器人、自动驾驶和具身AI等领域。早期基于规则的方法可扩展但多样性有限。近年来，深度生成模型（如GAN、扩散模型）和3D表示（如NeRF、3D高斯）提升了生成的真实性、多样性和视角一致性。该综述将方法分为四类：程序化生成、神经3D生成、图像生成和视频生成，分析其技术基础、优缺点及评估标准。未来方向包括更高保真度、物理感知和交互生成，以及统一感知-生成模型。更多进展详见项目页面。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-09T06:01:09Z
- **目录日期**: 2025-05-09
