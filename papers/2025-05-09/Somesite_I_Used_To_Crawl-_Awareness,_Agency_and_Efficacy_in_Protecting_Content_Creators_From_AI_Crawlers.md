# Somesite I Used To Crawl: Awareness, Agency and Efficacy in Protecting Content Creators From AI Crawlers

**URL**: http://arxiv.org/abs/2411.15091v2

## 原始摘要

The success of generative AI relies heavily on training on data scraped
through extensive crawling of the Internet, a practice that has raised
significant copyright, privacy, and ethical concerns. While few measures are
designed to resist a resource-rich adversary determined to scrape a site,
crawlers can be impacted by a range of existing tools such as robots.txt, NoAI
meta tags, and active crawler blocking by reverse proxies.
  In this work, we seek to understand the ability and efficacy of today's
networking tools to protect content creators against AI-related crawling. For
targeted populations like human artists, do they have the technical knowledge
and agency to utilize crawler-blocking tools such as robots.txt, and can such
tools be effective? Using large scale measurements and a targeted user study of
203 professional artists, we find strong demand for tools like robots.txt, but
significantly constrained by critical hurdles in technical awareness, agency in
deploying them, and limited efficacy against unresponsive crawlers. We further
test and evaluate network-level crawler blockers provided by reverse proxies.
Despite relatively limited deployment today, they offer stronger protections
against AI crawlers, but still come with their own set of limitations.


## AI 摘要

生成式AI的成功依赖大量网络爬取的数据训练，但这一做法引发了版权、隐私和伦理争议。现有工具如robots.txt、NoAI元标签和反向代理可限制爬取，但效果有限。本研究调查了网络工具保护创作者免受AI爬取的能力和效果，发现专业艺术家虽强烈需求此类工具，但受限于技术认知、部署能力和对不响应爬虫的无效性。网络级爬虫拦截工具（如反向代理）提供更强保护，但部署较少且仍有局限。研究表明，当前工具难以完全阻止资源丰富的AI爬取者，创作者保护面临技术意识和工具效力的双重挑战。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-09T00:02:30Z
- **目录日期**: 2025-05-09
