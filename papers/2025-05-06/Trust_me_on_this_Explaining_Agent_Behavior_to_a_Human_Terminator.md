# "Trust me on this" Explaining Agent Behavior to a Human Terminator

**URL**: http://arxiv.org/abs/2504.04592v2

## 原始摘要

Consider a setting where a pre-trained agent is operating in an environment
and a human operator can decide to temporarily terminate its operation and
take-over for some duration of time. These kind of scenarios are common in
human-machine interactions, for example in autonomous driving, factory
automation and healthcare. In these settings, we typically observe a trade-off
between two extreme cases -- if no take-overs are allowed, then the agent might
employ a sub-optimal, possibly dangerous policy. Alternatively, if there are
too many take-overs, then the human has no confidence in the agent, greatly
limiting its usefulness. In this paper, we formalize this setup and propose an
explainability scheme to help optimize the number of human interventions.


## AI 摘要

本文研究在人机协作场景中（如自动驾驶、工业自动化等）如何优化人类接管AI代理的干预频率。研究指出两种极端情况：完全不接管可能导致AI执行次优甚至危险策略，而接管过多则反映人类对AI缺乏信心，降低系统效用。作者通过形式化建模提出了一种可解释性方案，旨在平衡干预频率，使AI在保持自主性的同时获得必要的人类监督，从而提升整体系统性能与可靠性。该方案有助于在安全性和实用性之间找到最佳平衡点。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-06T10:02:06Z
- **目录日期**: 2025-05-06
