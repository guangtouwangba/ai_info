# #多模态模型推理能力大考##新基准Gemini2.5Pro仅得60分#多模态大模型推理能力到底强不强？一场“考试”揭晓答案。复旦大学、香港中文大学等联合发布MME-Reasonin...

**URL**: https://weibo.com/6105753431/PvrTu7LQv

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E5%A4%A7%E8%80%83%23&amp;extparam=%23%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E5%A4%A7%E8%80%83%23" data-hide=""><span class="surl-text">#多模态模型推理能力大考#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%96%B0%E5%9F%BA%E5%87%86Gemini2.5Pro%E4%BB%85%E5%BE%9760%E5%88%86%23&amp;extparam=%23%E6%96%B0%E5%9F%BA%E5%87%86Gemini2.5Pro%E4%BB%85%E5%BE%9760%E5%88%86%23" data-hide=""><span class="surl-text">#新基准Gemini2.5Pro仅得60分#</span></a><br><br>多模态大模型推理能力到底强不强？一场“考试”揭晓答案。复旦大学、香港中文大学等联合发布MME-Reasoning基准，首次系统评估多模态大语言模型的逻辑推理水平。<br><br>这个基准不走寻常路，严格区分三类推理：演绎、归纳和溯因。测试题还分三种类型——选择题、自由作答题和基于规则验证的题目，同时按难度分为三档，力图避开知识偏见，专注逻辑本身。<br><br>题库收录1188道题，涵盖五种能力：模式分析、规划探索、空间时间、计算和因果链。回答过程由GPT抽取答案，通过匹配、函数评估等方式判断正误。<br><br>测评了30多款模型，从GPT-4o、Qwen系列到R1-VL、MM-Eureka等。最优模型得分也只有60%左右。<br><br>案例分析还发现，模型经常反复推理、规划、假设验证，甚至生成超长回答。MME-Reasoning无疑是当前最具挑战的多模态推理评估基准之一。 <a href="https://weibo.com/ttarticle/p/show?id=2309405174953963553050" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">多模态推理新基准！最强Gemini 2.5 Pro仅得60分，复旦港中文等出品</span></a><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3ly1i26wd1xe2gj30rs0fm0wc.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

复旦大学与香港中文大学联合发布MME-Reasoning基准，首次系统评估多模态大模型的逻辑推理能力。该基准包含1188道题，涵盖演绎、归纳等三类推理及五种能力维度，严格避免知识偏见。测试30余款模型（如GPT-4o、Gemini 2.5 Pro），最优成绩仅60分，显示当前模型在复杂推理任务上仍有明显不足。案例分析发现模型存在重复推理、过度生成等问题。该基准成为目前最具挑战性的多模态推理评估标准之一。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-07T18:03:30Z
- **目录日期**: 2025-06-07
