# Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games

**URL**: http://arxiv.org/abs/2506.05309v1

## 原始摘要

LLMs are used predominantly in synchronous communication, where a human user
and a model communicate in alternating turns. In contrast, many real-world
settings are inherently asynchronous. For example, in group chats, online team
meetings, or social games, there is no inherent notion of turns; therefore, the
decision of when to speak forms a crucial part of the participant's decision
making. In this work, we develop an adaptive asynchronous LLM-agent which, in
addition to determining what to say, also decides when to say it. To evaluate
our agent, we collect a unique dataset of online Mafia games, including both
human participants, as well as our asynchronous agent. Overall, our agent
performs on par with human players, both in game performance, as well as in its
ability to blend in with the other human players. Our analysis shows that the
agent's behavior in deciding when to speak closely mirrors human patterns,
although differences emerge in message content. We release all our data and
code to support and encourage further research for more realistic asynchronous
communication between LLM agents. This work paves the way for integration of
LLMs into realistic human group settings, from assistance in team discussions
to educational and professional environments where complex social dynamics must
be navigated.


## AI 摘要

当前大语言模型（LLMs）主要用于同步对话（轮流发言），而现实场景（如群聊、在线会议或社交游戏）多为异步交流，参与者需自主决定发言时机。本研究开发了一种异步LLM智能体，不仅能生成内容，还能动态判断发言时机。通过在"狼人杀"游戏中与人类玩家对比测试，该智能体在游戏表现和社交融入度上均达到人类水平，其发言时机决策与人类高度相似，但内容存在差异。研究公开了数据集和代码，为LLM在团队协作、教育等复杂社交场景的应用提供了新思路，推动了异步人机交互的发展。（98字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-07T16:01:26Z
- **目录日期**: 2025-06-07
