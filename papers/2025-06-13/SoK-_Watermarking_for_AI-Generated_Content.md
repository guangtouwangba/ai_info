# SoK: Watermarking for AI-Generated Content

**URL**: http://arxiv.org/abs/2411.18479v3

## 原始摘要

As the outputs of generative AI (GenAI) techniques improve in quality, it
becomes increasingly challenging to distinguish them from human-created
content. Watermarking schemes are a promising approach to address the problem
of distinguishing between AI and human-generated content. These schemes embed
hidden signals within AI-generated content to enable reliable detection. While
watermarking is not a silver bullet for addressing all risks associated with
GenAI, it can play a crucial role in enhancing AI safety and trustworthiness by
combating misinformation and deception. This paper presents a comprehensive
overview of watermarking techniques for GenAI, beginning with the need for
watermarking from historical and regulatory perspectives. We formalize the
definitions and desired properties of watermarking schemes and examine the key
objectives and threat models for existing approaches. Practical evaluation
strategies are also explored, providing insights into the development of robust
watermarking techniques capable of resisting various attacks. Additionally, we
review recent representative works, highlight open challenges, and discuss
potential directions for this emerging field. By offering a thorough
understanding of watermarking in GenAI, this work aims to guide researchers in
advancing watermarking methods and applications, and support policymakers in
addressing the broader implications of GenAI.


## AI 摘要

随着生成式AI（GenAI）输出的质量提升，区分其与人类创作内容愈发困难。数字水印技术通过嵌入隐藏信号来可靠检测AI生成内容，成为解决这一问题的有效方法。虽然水印不能完全消除GenAI的所有风险，但它在对抗错误信息和欺骗、增强AI安全性和可信度方面至关重要。本文系统综述了GenAI水印技术，从历史和监管角度阐述了水印的必要性，明确了水印的定义和理想特性，分析了现有方法的核心目标和威胁模型，并探讨了实用评估策略。此外，文章总结了最新代表性研究，指出开放挑战和未来方向，为研究者和政策制定者提供指导。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-13T23:02:09Z
- **目录日期**: 2025-06-13
