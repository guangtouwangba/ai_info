# #关键句决定模型回答的安全调性##唤醒模型安全信号防越狱#大型推理模型（LRMs）在解决复杂任务时展现出的强大能力令人惊叹，但其背后隐藏的安全风险不容忽视。尽...

**URL**: https://weibo.com/6105753431/Pwmpl6skE

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%B3%E9%94%AE%E5%8F%A5%E5%86%B3%E5%AE%9A%E6%A8%A1%E5%9E%8B%E5%9B%9E%E7%AD%94%E7%9A%84%E5%AE%89%E5%85%A8%E8%B0%83%E6%80%A7%23&amp;extparam=%23%E5%85%B3%E9%94%AE%E5%8F%A5%E5%86%B3%E5%AE%9A%E6%A8%A1%E5%9E%8B%E5%9B%9E%E7%AD%94%E7%9A%84%E5%AE%89%E5%85%A8%E8%B0%83%E6%80%A7%23" data-hide=""><span class="surl-text">#关键句决定模型回答的安全调性#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%94%A4%E9%86%92%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%BF%A1%E5%8F%B7%E9%98%B2%E8%B6%8A%E7%8B%B1%23&amp;extparam=%23%E5%94%A4%E9%86%92%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%BF%A1%E5%8F%B7%E9%98%B2%E8%B6%8A%E7%8B%B1%23" data-hide=""><span class="surl-text">#唤醒模型安全信号防越狱#</span></a><br><br>大型推理模型（LRMs）在解决复杂任务时展现出的强大能力令人惊叹，但其背后隐藏的安全风险不容忽视。<br><br>尽管学术界已尝试通过监督微调（SFT）有效地提升模型安全，但下图的测试结果所示，监督微调在面对训练数据领域外的层出不穷的“越狱”攻击时，往往显得捉襟见肘，泛化能力有限。<br><br>同时，之前的工作没有对大型推理模型的安全思考做深入的分析，以进行针对性的提升。<br><br>来自加州大学圣克鲁兹分校，加州大学伯克利分校，思科研究和耶鲁大学的的研究团队提出了创新的SafeKey框架，成功在不影响模型核心能力的前提下，显著增强了其安全稳健性。<br><br>具体细节，欢迎查看文章👇 <a href="https://weibo.com/ttarticle/p/show?id=2309405177126352715862" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">AI自己给自己当网管，实现安全“顿悟时刻”，风险率直降9.6%</span></a><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i2dpwr4l43j30id0acta9.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

加州大学等机构的研究团队针对大型推理模型(LRMs)的安全漏洞问题，提出了SafeKey创新框架。该研究指出传统监督微调(SFT)方法在面对新型"越狱"攻击时泛化能力不足。SafeKey框架通过关键安全机制，在不影响模型核心功能的前提下，显著提升了9.6%的安全性能，有效防止恶意提示的越狱攻击。这一突破性方案为AI系统的安全防护提供了新思路，实现了模型安全性的自我增强。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-13T11:03:19Z
- **目录日期**: 2025-06-13
