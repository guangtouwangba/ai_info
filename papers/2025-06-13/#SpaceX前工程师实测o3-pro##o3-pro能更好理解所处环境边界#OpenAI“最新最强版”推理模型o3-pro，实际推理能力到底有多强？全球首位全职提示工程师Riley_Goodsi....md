# #SpaceX前工程师实测o3-pro##o3-pro能更好理解所处环境边界#OpenAI“最新最强版”推理模型o3-pro，实际推理能力到底有多强？全球首位全职提示工程师Riley Goodsi...

**URL**: https://weibo.com/6105753431/PwkiZ44KA

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23SpaceX%E5%89%8D%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%AE%9E%E6%B5%8Bo3-pro%23&amp;extparam=%23SpaceX%E5%89%8D%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%AE%9E%E6%B5%8Bo3-pro%23" data-hide=""><span class="surl-text">#SpaceX前工程师实测o3-pro#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23o3-pro%E8%83%BD%E6%9B%B4%E5%A5%BD%E7%90%86%E8%A7%A3%E6%89%80%E5%A4%84%E7%8E%AF%E5%A2%83%E8%BE%B9%E7%95%8C%23&amp;extparam=%23o3-pro%E8%83%BD%E6%9B%B4%E5%A5%BD%E7%90%86%E8%A7%A3%E6%89%80%E5%A4%84%E7%8E%AF%E5%A2%83%E8%BE%B9%E7%95%8C%23" data-hide=""><span class="surl-text">#o3-pro能更好理解所处环境边界#</span></a><br><br>OpenAI“最新最强版”推理模型o3-pro，实际推理能力到底有多强？<br><br>全球首位全职提示工程师Riley Goodside来给它上难度：<br><br>“说出歌手Sabrina Carpenter的一首歌的歌名，回答这个问题时，每个单词最后一个字母连起来看，也能对应这首歌名。”<br><br>结果，o3-pro在经过4分25秒的推理过后，成功给出正确答案。【图1】<br><br>经实测，o3只能做对个大概，通常只能把最后几个字母凑对。【图2】<br><br>该测试引来OpenAI前AGI Readiness团队负责人Miles Brundage的转发关注。<br><br>虽然人已经不在OpenAI了，但Miles Brundage还是替老东家直接开大阴阳苹果：如果这都不叫推理那什么叫推理。【图3】<br><br>PS：苹果前几天发了个新研究，称推理模型的思考只是一种假象，详情可见：<a href="https://weibo.com/6105753431/PvAACahAY" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br><br>除了网友实测外，各大评测榜单已陆续同步更新排名。<br><br>总结来看，和官方给的测试结果略有不同。<br><br>官方测评中，o3-pro超越o3、o1-pro，成为当前最擅长编码的OpenAI模型。【图4】<br><br>而在大模型权威榜单LiveBench上，o3-pro和o3编码平均得分几乎无差，o3-pro仅有0.07分的优势。<br><br>智能体编码平均得分方面，o3-pro甚至大比分落后于o3（31.67 vs 36.67）。【图5】<br><br>另外，针对大模型长上下文理解的基准测试Fiction.LiveBench也放榜了。<br><br>o3-pro在较短上下文场景下表现很出色，较o3有所提升。<br><br>然鹅，192k超长上下文处理依然是Gemini 2.5 Pro占优势，Gemini 2.5 Pro得分90.6，而o3-pro仅得分65.6。【图6】<br><br>让人困惑的是，在这个基准测试中，不管是o3-pro还是o3，在16k上下文中分数都下降了，到了32k，两个模型得分又回到了100。<br><br>除此之外，苹果&amp;SpaceX前工程师Ben Hylak之前分享o1使用心得，得到不少网友关注。这次o3-pro他同样没放过，而且又被奥特曼翻了牌子。【图7】<br><br>他的分享，好似恰巧解释了o3-pro的官方测评和各大评测榜单结果有所出入的问题。【图8】<br><br>Ben Hylak曾任SpaceX软件工程师、苹果VisionOS人机交互设计师，目前在创业为AI产品提供分析服务。<br><br>此前o1 pro推出满血$200/月版本时，Ben Hyla第一天就交了钱，整整测试了一天。<br><br>结果体验很糟糕，很多人表示同感，但也有人强烈反对。Ben Hylak在与持不同观点人激烈讨论了一番后，意识到自己的使用方法完全错了。<br><br>“我还在把o1当聊天模型来用，但o1已经不是聊天模型了。”<br><br>这次，他透露自己一周前就已经提前接触到了o3-pro，o3-pro“以不同方式测试，实际体验会有所不同”。<br><br>从经常测评大模型的经验来看，Ben Hylak认为“模型能力的发挥高度依赖背景信息”，他表示自己目前使用o3关键就是：<br><br>“不把它当聊天对象，而是当作报告生成器。给它背景信息、设定目标，然后让它自由发挥。”<br><br>由此，要看出o3-pro的真正实力，得给它多得多的背景信息。然鹅，Ben Hylak手头的信息素材都快榨干了。于是，Ben Hylak换了种方法：<br><br>他和他的联合创始人Alexis花时间把他们在Raindrop所有历史会议记录、目标全翻出来，甚至录了语音备忘录，一股脑塞给o3-pro，让它做规划。<br><br>结果，被o3-pro惊艳到了：<br><br>“它输出的计划精准踩中我们想要的点——目标数据、时间排期、优先级排序，连“必须砍哪些业务”都写得明明白白。<br><br>“o3给出的计划合理、说得通；但o3-pro给出的计划足够具体、有依据，真真切切改变了我们对未来的思考方式。<br><br>“这在评估中很难体现出来。”<br><br>除此之外，Ben Hylak认为如今的模型在孤立环境下表现已然十分出色，简单测试难不倒它，真正的挑战在于将其融入社会。<br><br>这种融入主要体现在工具调用方面，即模型与人类、外部数据以及其它AI协作得如何。<br><br>经测试，Ben Hylak表示o3-pro在这方面有了实实在在的提升——<br><br>“它在识别自身所处环境、准确说明可使用的工具、知晓何时需询问外部世界信息（而非假装自己掌握相关信息或权限 ）以及为任务挑选合适工具等方面，表现都明显更优。”<br><br>下面是展示示例。Ben Hylak让o3-pro和o3做一个日历。<br><br>o3-pro显然能更好地理解其所处环境的边界，明确表示：<br><br>在这个聊天窗口中无法显示实时交互的HTML预览（我的环境仅支持纯文本和代码片段）。<br><br>并且给出了要查看渲染后日历的详细步骤操作，还描述了用户将看到的视觉内容。【图9】<br><br>相比之下，o3明明做不到还装能做，表示可以“创建日历小组件的实时交互预览”。<br><br>下面这个例子，Ben Hylak让模型找今年关于Borges的Substack文章。【图10】<br><br>o3-pro同样明确表示进行实时Substack查询所需的网页搜索工具在当前环境未启用，所以无法直接获取最新链接。<br><br>而o3表示搜索了，但没有找到2025年发布的Borges的Substack文章。<br><br>Ben Hylak还发现，需要给o3-pro提供更多上下文，要是不提供足够的上下文，它会出现过度思考的情况。<br><br>“它在分析方面超强，也很擅长借助工具做事，但自己直接动手做事就没那么在行。我觉得它会是个超棒的协调者。不过，有些ClickHouse SQL相关问题，o3处理得更好。实际效果因人而异。”<br><br>o3-pro给Ben Hylak带来的体验与Claude Opus、Gemini 2.5 Pro相比，都不同。<br><br>Ben Hylak认为Claude Opus虽体量庞大，但没让他真切感受到这种“大”的独特价值；而o3-pro的输出更优，仿佛两者完全处于不同的竞争维度。<br><br>他继续补充道，OpenAI正沿着强化学习路径深挖（比如Deep Research、Codex项目），不只是教模型“怎么用工具”，更是教它们“思考何时该用工具”。<br><br>最后，Ben Hylak总结认为推理模型的Prompt技巧核心逻辑不变，之前他写的o1提示指南，现在依然适用o3-pro。<br><br>首先，“语境”是一切，就像给“饼干怪兽”喂饼干，精准投喂才有效，它是一种引导大语言模型激活“类记忆能力”的方式，但因为足够精准，所以效果拔群。<br><br>另外，系统提示的影响极大。如今模型的可塑性超强，那些能让模型“理解自身所处环境与目标”的LLM调教框架，能产生远超预期的价值。<img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i2dkjzq0ebj30ok0vc7bb.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i2dkk1hor9j30oi07mtba.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i2dkk3djwdj30oi04sdh2.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i2dkk597mmj30zk0k047y.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i2dkk7pan8j30zk0lpwp5.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i2dkkq0ogjj30zk0saaoz.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i2dkkdo0q0j30oe0fidjh.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i2dkkf9twzj30sy0owq8d.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i2dkkhh4qyj30zk0kyn7k.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i2dkkjhed6j30zk0sx14u.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

OpenAI最新推理模型o3-pro在复杂推理任务中表现优异，如成功解答需要多步推理的歌词谜题（耗时4分25秒），而o3仅能部分完成。评测显示o3-pro编码能力与o3相近，但在长文本处理（192k上下文）上弱于Gemini 2.5 Pro。前SpaceX工程师Ben Hylak实测发现，o3-pro在业务规划、工具调用和环境边界认知方面显著提升，能精准输出可执行计划，但需充足上下文支持。其突出特点是能明确识别自身能力边界，避免虚假承诺，展现了强化学习在工具使用决策上的进展。提示工程核心仍依赖精准的语境引导和系统提示。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-13T08:04:24Z
- **目录日期**: 2025-06-13
