# Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy

**URL**: http://arxiv.org/abs/2506.09958v1

## 原始摘要

Medical Visual Question Answering (MedVQA) is a promising field for
developing clinical decision support systems, yet progress is often limited by
the available datasets, which can lack clinical complexity and visual
diversity. To address these gaps, we introduce Kvasir-VQA-x1, a new,
large-scale dataset for gastrointestinal (GI) endoscopy. Our work significantly
expands upon the original Kvasir-VQA by incorporating 159,549 new
question-answer pairs that are designed to test deeper clinical reasoning. We
developed a systematic method using large language models to generate these
questions, which are stratified by complexity to better assess a model's
inference capabilities. To ensure our dataset prepares models for real-world
clinical scenarios, we have also introduced a variety of visual augmentations
that mimic common imaging artifacts. The dataset is structured to support two
main evaluation tracks: one for standard VQA performance and another to test
model robustness against these visual perturbations. By providing a more
challenging and clinically relevant benchmark, Kvasir-VQA-x1 aims to accelerate
the development of more reliable and effective multimodal AI systems for use in
clinical settings. The dataset is fully accessible and adheres to FAIR data
principles, making it a valuable resource for the wider research community.
Code and data: https://github.com/Simula/Kvasir-VQA-x1 and
https://huggingface.co/datasets/SimulaMet/Kvasir-VQA-x1


## AI 摘要

研究人员推出了Kvasir-VQA-x1数据集，这是一个用于胃肠道内窥镜医学视觉问答（MedVQA）的大规模新数据集。该数据集在原有基础上新增了159,549个问题-答案对，旨在测试更深入的临床推理能力。通过使用大语言模型生成分层复杂度的临床问题，并引入模拟常见成像伪影的视觉增强，该数据集支持标准VQA性能评估和模型鲁棒性测试。Kvasir-VQA-x1遵循FAIR数据原则，为开发更可靠的多模态AI临床决策系统提供了更具挑战性的基准。数据集已开源，可供研究社区使用。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-13T00:01:59Z
- **目录日期**: 2025-06-13
