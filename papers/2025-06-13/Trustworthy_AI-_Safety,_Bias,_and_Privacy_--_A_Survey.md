# Trustworthy AI: Safety, Bias, and Privacy -- A Survey

**URL**: http://arxiv.org/abs/2502.10450v2

## 原始摘要

The capabilities of artificial intelligence systems have been advancing to a
great extent, but these systems still struggle with failure modes,
vulnerabilities, and biases. In this paper, we study the current state of the
field, and present promising insights and perspectives regarding concerns that
challenge the trustworthiness of AI models. In particular, this paper
investigates the issues regarding three thrusts: safety, privacy, and bias,
which hurt models' trustworthiness. For safety, we discuss safety alignment in
the context of large language models, preventing them from generating toxic or
harmful content. For bias, we focus on spurious biases that can mislead a
network. Lastly, for privacy, we cover membership inference attacks in deep
neural networks. The discussions addressed in this paper reflect our own
experiments and observations.


## AI 摘要

该论文探讨了当前人工智能系统在可信赖性方面的三大关键问题：安全性、隐私和偏见。在安全性方面，研究聚焦于大型语言模型的安全对齐，防止生成有害内容；偏见问题主要关注误导网络的虚假偏见；隐私部分则涉及深度神经网络中的成员推理攻击。这些讨论基于作者自身的实验和观察，旨在为提升AI系统的可靠性提供见解。尽管AI能力显著提升，但上述问题仍制约其可信度，需进一步研究解决。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-13T01:30:02Z
- **目录日期**: 2025-06-13
