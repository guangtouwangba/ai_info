# Applying LLM-Powered Virtual Humans to Child Interviews in Child-Centered Design

**URL**: http://arxiv.org/abs/2504.20016v1

## 原始摘要

In child-centered design, directly engaging children is crucial for deeply
understanding their experiences. However, current research often prioritizes
adult perspectives, as interviewing children involves unique challenges such as
environmental sensitivities and the need for trust-building. AI-powered virtual
humans (VHs) offer a promising approach to facilitate engaging and multimodal
interactions with children. This study establishes key design guidelines for
LLM-powered virtual humans tailored to child interviews, standardizing
multimodal elements including color schemes, voice characteristics, facial
features, expressions, head movements, and gestures. Using ChatGPT-based prompt
engineering, we developed three distinct Human-AI workflows (LLM-Auto,
LLM-Interview, and LLM-Analyze) and conducted a user study involving 15
children aged 6 to 12. The results indicated that the LLM-Analyze workflow
outperformed the others by eliciting longer responses, achieving higher user
experience ratings, and promoting more effective child engagement.


## AI 摘要

这项研究探讨了如何利用AI驱动的虚拟人(VHs)改善儿童访谈体验。针对现有研究多从成人视角出发的问题，研究制定了基于大语言模型(LLM)的虚拟儿童访谈设计指南，规范了色彩、语音、表情等多模态元素。通过ChatGPT提示工程开发了三种人机协作模式(LLM-Auto、LLM-Interview和LLM-Analyze)，并对15名6-12岁儿童进行测试。结果显示，LLM-Analyze模式表现最优，能获得更长的回答、更高的用户体验评分和更有效的儿童参与度。该研究为儿童中心设计提供了新思路，突出了AI在儿童研究中的应用潜力。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-29T06:01:22Z
- **目录日期**: 2025-04-29
