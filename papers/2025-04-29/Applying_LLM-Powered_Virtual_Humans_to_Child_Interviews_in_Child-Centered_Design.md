# Applying LLM-Powered Virtual Humans to Child Interviews in Child-Centered Design

**URL**: http://arxiv.org/abs/2504.20016v1

## 原始摘要

In child-centered design, directly engaging children is crucial for deeply
understanding their experiences. However, current research often prioritizes
adult perspectives, as interviewing children involves unique challenges such as
environmental sensitivities and the need for trust-building. AI-powered virtual
humans (VHs) offer a promising approach to facilitate engaging and multimodal
interactions with children. This study establishes key design guidelines for
LLM-powered virtual humans tailored to child interviews, standardizing
multimodal elements including color schemes, voice characteristics, facial
features, expressions, head movements, and gestures. Using ChatGPT-based prompt
engineering, we developed three distinct Human-AI workflows (LLM-Auto,
LLM-Interview, and LLM-Analyze) and conducted a user study involving 15
children aged 6 to 12. The results indicated that the LLM-Analyze workflow
outperformed the others by eliciting longer responses, achieving higher user
experience ratings, and promoting more effective child engagement.


## AI 摘要

当前儿童中心设计常依赖成人视角，而直接访谈儿童面临环境敏感性和信任建立等挑战。本研究探索了基于LLM的虚拟人（VHs）解决方案，制定了针对儿童访谈的多模态设计规范（色彩、语音、表情、动作等），并开发了三种人机协作模式（LLM-Auto/Interview/Analyze）。通过15名6-12岁儿童的测试发现，LLM-Analyze模式表现最优：能获得更长的回答、更高的用户体验评分，并实现更有效的儿童参与。研究表明AI虚拟人可成为理解儿童体验的有效工具，其中分析型交互流程最具潜力。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-29T08:01:21Z
- **目录日期**: 2025-04-29
