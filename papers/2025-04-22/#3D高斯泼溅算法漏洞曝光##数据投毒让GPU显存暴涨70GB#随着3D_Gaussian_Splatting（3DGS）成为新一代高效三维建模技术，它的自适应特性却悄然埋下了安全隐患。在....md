# #3D高斯泼溅算法漏洞曝光##数据投毒让GPU显存暴涨70GB#随着3D Gaussian Splatting（3DGS）成为新一代高效三维建模技术，它的自适应特性却悄然埋下了安全隐患。在...

**URL**: https://weibo.com/6105753431/Poshhl5xw

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%233D%E9%AB%98%E6%96%AF%E6%B3%BC%E6%BA%85%E7%AE%97%E6%B3%95%E6%BC%8F%E6%B4%9E%E6%9B%9D%E5%85%89%23&amp;extparam=%233D%E9%AB%98%E6%96%AF%E6%B3%BC%E6%BA%85%E7%AE%97%E6%B3%95%E6%BC%8F%E6%B4%9E%E6%9B%9D%E5%85%89%23" data-hide=""><span class="surl-text">#3D高斯泼溅算法漏洞曝光#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%95%B0%E6%8D%AE%E6%8A%95%E6%AF%92%E8%AE%A9GPU%E6%98%BE%E5%AD%98%E6%9A%B4%E6%B6%A870GB%23&amp;extparam=%23%E6%95%B0%E6%8D%AE%E6%8A%95%E6%AF%92%E8%AE%A9GPU%E6%98%BE%E5%AD%98%E6%9A%B4%E6%B6%A870GB%23" data-hide=""><span class="surl-text">#数据投毒让GPU显存暴涨70GB#</span></a><br><br>随着3D Gaussian Splatting（3DGS）成为新一代高效三维建模技术，它的自适应特性却悄然埋下了安全隐患。<br><br>在本篇ICLR 2025 Spotlight 论文中，研究者们提出首个专门针对3DGS的攻击方法——Poison-Splat，通过对输入图像加入扰动，即可显著拖慢训练速度、暴涨显存占用，甚至导致系统宕机。<br><br>这一攻击不仅隐蔽、可迁移，还在现实平台中具备可行性，揭示了当前主流3D重建系统中一个未被重视的安全盲区。【图1】<br><br>引言：3D视觉的新时代与未设防的后门隐患  <br>过去两年，3D视觉技术经历了飞跃式发展，尤其是由 Kerbi等人在2023年提出的3D Gaussian Splatting (3DGS)，以其超高的渲染效率和拟真度，一跃成为替代NeRF的3D视觉主力军。<br><br>你是否用过 LumaAI、Spline 或者 Polycam 之类的应用上传图片生成三维模型？它们背后很多就用到了3DGS技术。3D高斯泼溅无需繁重的神经网络，仅靠一团团显式的、不固定数量的3D高斯点即可构建逼真的三维世界。<br><br>但你知道吗？这个看起来高效又灵活的“新王者”，居然隐藏着一个巨大的安全隐患——只要改动图片的细节，就能让系统在训练阶段直接崩溃！<br><br>来自新加坡国立大学和昆仑万维的研究者在 ICLR 2025上的Spotlight论文《Poison-Splat: Computation Cost Attack on 3D Gaussian Splatting》中，首次揭示了这一致命漏洞，并提出了首个针对3DGS计算复杂度的攻击算法：Poison-Splat。【图2】<br><br>图一：干净（左）与Poison-Splat攻击后（右）的输入图像、三维高斯点云，以及GPU显存、训练时间和渲染速度的显著变化。这里的每张图片由像素表征（左上）和3DGS高斯点的可视化（右下）拼接而成，更好地展示其二维像素空间和三维高斯空间的变化。<br><br>问题背景：强大的模型“适应性”是优点，还是漏洞？【图3】  <br>图二：NeRF (左) 和 3D Gaussian Splatting (右) 分别引领了3D视觉的一个时代，但它们的核心思想却截然不同。NeRF (图a) 使用神经网络对三维场景隐式建模，其复杂度和计算成本由训练者通过超参数人为指定；而 3DGS (图b) 使用不固定数量的三维高斯对场景显式建模，其复杂度和计算成本会根据需要建模的三维内容进行自适应调整。<br><br>3D Gaussian Splatting 相比于NeRF最大的区别之一，就是它拥有自适应的模型复杂度：<br><br>训练过程中，模型会根据图像复杂度自动增加或减少高斯点（3D Gaussian）<br><br>图像越复杂，模型训练过程就会产生越多的高斯点 → 占用更多显存、需要更长训练时间<br><br>本质上，3DGS会智能地根据建模场景“细节多不多”来决定要分配多少计算资源。【图4】<br><br>图三：计算成本（GPU显存占用、训练效率）、高斯点数量、数据集图像复杂度之间的强正相关关系。对于不同的数据集场景，(a) GPU显存占用和高斯点数量的关系；(b)训练耗时和高斯点数量的关系；(c) 高斯点数量和图片复杂程度(以Total Variation Score衡量)的关系。<br><br>这原本是一个很聪明的设计, 3DGS依靠其强大的适应性，可以让每一个参与训练的高斯点都“物尽其用”。<br><br>但问题来了，如果有人故意上传“带毒的复杂图像”，会发生什么？<br><br>揭秘3DGS的复杂度漏洞：Poison-Splat攻击算法  <br>攻击目标：GPU占用率和训练时间<br><br>设计一种扰动输入图像的方法，将经过扰动的图像作为3DGS的输入后，能够大幅增加训练成本（GPU显存和训练时长）。<br><br>问题建模：max-min双层优化问题<br><br>我们可以将整个攻击建模成一个 max-min双层优化(bi-level optimization)问题：<br><br>内层(min)：3DGS 尝试还原三维场景，拟合各视角的输入图像。（正常训练）  <br>外层(max)：攻击者试图找到最“消耗资源”的图像扰动方式。（攻击目标）  <br>这类双层优化问题通常都极难直接求解。为此，研究者们提出了三大创新策略：<br><br>核心技术1：引入“代理模型”(proxy model) 作为内层近似器<br><br>为了降低计算成本，我们训练一个轻量的代理 3DGS 模型，用于快速模拟 victim 的行为  <br>每次攻击迭代时，从代理模型生成视图，再进行优化更新  <br>保证多视角一致性（multi-view consistency），避免图像之间相互矛盾  <br>核心技术2：利用图像“非光滑性”诱导高斯密度增长<br><br>观察发现，3DGS 会在细节丰富/边缘突出的图像区域生成更多高斯点  <br>Total Variation(TV)值是对图像“非光滑度”的一个很好的度量。因此我们最大化图像的 Total Variation(TV)值，从而诱导3DGS模型过度复杂。  <br>核心技术3：约束扰动强度，提升攻击隐蔽性<br><br>攻击图像若改动过大，容易被检测  <br>借鉴对抗攻击领域的经典设定，攻击者可引入 L-∞球约束（ϵ-ball）控制每个像素最大扰动，确保图像语义完整、肉眼难以分辨  <br>如果没有隐蔽性要求，攻击者可以无限制扰动输入图像，最大化攻击效果【图5】【图6】<br><br>图四：在约束条件下，攻击者的代理模型产生的变化被限制在像素扰动预算内，可以隐蔽地增加三维重建需要的计算消耗。<br><br>图五：无约束攻击中，攻击者使用的代理模型的三维表征不受限制地复杂化，使三维重建所需的计算成本大大增加。<br><br>实验结果：最高让训练时间翻倍、显存飙升20倍  <br>研究者在多个公开3D数据集（NeRF-Synthetic、Mip-NeRF360、Tanks and Temples）上评估了攻击效果。实验结果证实，对于危害最大的无限制攻击，其攻击效果令人震惊。在被攻击的最差3D场景下：<br><br>GPU显存：从原本不到4GB飙升到80GB（直接击穿主流显卡）  <br>训练时间：最长可达接近5倍增长  <br>高斯数量：最高可增加至原来的20倍+  <br>渲染速度：最坏可降至原来的1/10【图7】<br><br>图六：当攻击者可以无限制地对输入图像进行改动，可以带来极高的额外计算开销，对服务提供商造成重大的资源浪费。<br><br>就算对输入图片做了隐蔽性约束，当图片中每个像素的扰动都不得和干净图片偏离16个像素值时，其攻击效果仍然不容小觑，且隐蔽性更高，更加难以识别和检测：【图8】<br><br>图七：在像素值扰动不超过16/255的约束下，部分场景能使显存消耗增高超过8倍，以至超过常见24GB显卡的显上限。<br><br>此外，攻击对黑盒模型同样有效（如 Scaffold-GS），表明它不仅“杀伤力强”，还具备“跨平台传染性”。【图9】<br><br>图八：即使攻击者无法事先知道服务商具体的模型和参数，黑盒攻击也能产生效果。当攻击者针对原始3DGS算法进行Poison-splat攻击，产生的投毒数据对于Scaffold-GS这样的变体模型仍然有很好的攻击效果。<br><br>实际风险：这不是学术游戏，而是真实威胁  <br>现实中，很多3D服务商（如 Polycam、Kiri）都支持用户自由上传图像或视频进行建模。<br><br>这意味着：<br><br>攻击者可以伪装成普通用户提交“毒图”  <br>在高峰时段导致系统“忙不过来”  <br>若GPU资源被“毒图”霸占，其他用户任务将被拒绝执行，导致服务瘫痪（DoS）【图10】<br><br>图九：原始图像、约束攻击、无约束攻击作为输入时的计算代价对比。横坐标是3DGS模型拟合输入图片需要的训练时长，纵坐标是训练过程中GPU实时显存消耗。相比于原始图像，poison-splat攻击会大幅增加GPU显存占用和训练时长，让系统负载飙升。<br><br>意义与贡献：为何要“攻击”3DGS？  <br>提出风险不是在“捣乱”，而是在为AI系统打预防针。这项工作是：<br><br>首次系统性地揭示3DGS训练阶段的资源安全漏洞  <br>首个在三维视觉中将“数据投毒”扩展到“训练资源消耗”这一维度  <br>提出一套通用且具备可迁移性的攻击框架，推动 3D 安全领域发展  <br>与此同时，研究者们也揭示了简单的防御（如限制高斯数量）无法有效应对攻击，且会严重降低模型重建精度，导致模型“学不好”，服务方依然无法交付高质量 3D 场景。【图11】<br><br>图十：简单限制高斯点总量并不是理想的防御。虽然能限制资源消耗，但会严重影响3D重建的服务质量。如何设计更加智能的防御仍然是一个开放问题。<br><br>这些结果预示着，如果 3D 重建厂商没有相应防护，一旦有人“恶意上传”或“篡改”用户数据，系统很可能出现显存不足或训练无效。<br><br>目前该研究已将全部代码、数据处理流程、可复现实验开源，感兴趣的小伙伴可以在Github上查看【图12】<br><br>在空间智能、世界模型更加需要依赖三维视觉的今天，讨论其算法的安全性也变得越来越重要。  <br>在通往更强大AI的道路上，我们需要的不仅是性能的飞跃，还有安全的护栏。希望这篇工作能唤起大家对3D AI系统安全性的重视。<br><br>欢迎在留言区分享你的观点、疑问或补充！<br><br>论文链接：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fpdf%2F2410.08190" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a>  <br>GitHub：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2Fjiahaolu97%2Fpoison-splat" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0pq1ihzvqj30zk0cqjvb.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0pq1gk711j30zk0b8qjz.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0pq1g2g3nj30zk09un9i.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0pq1g1excj30zk09uwox.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0pq1j8d91j30uv0k0dm5.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0pq1iv43lj30zk0dxk38.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0pq1j0at8j30zk0drdrq.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0pq1j14mjj30zk0emn7c.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0pq1i8d6wj30zk0g0njl.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0pq1kbxinj30pu0k0ah5.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

新加坡国立大学和昆仑万维的研究团队在ICLR 2025 Spotlight论文中揭示了3D高斯泼溅算法(3DGS)的安全漏洞。他们提出的"Poison-Splat"攻击方法通过扰动输入图像，能诱导3DGS模型产生过多高斯点，导致GPU显存暴涨(最高达80GB)、训练时间延长5倍。这种攻击隐蔽性强，在黑盒场景下仍有效，可能被用于DoS攻击。研究首次将数据投毒扩展到3D视觉的计算资源消耗维度，警示了当前3D重建系统的安全盲区。论文和代码已开源，呼吁业界重视3D AI系统的安全性问题。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-22T17:03:33Z
- **目录日期**: 2025-04-22
