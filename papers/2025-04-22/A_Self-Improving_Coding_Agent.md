# A Self-Improving Coding Agent

**URL**: http://arxiv.org/abs/2504.15228v1

## 原始摘要

We demonstrate that an LLM coding agent, equipped with basic coding tools,
can autonomously edit itself, and thereby improve its performance on benchmark
tasks. We find performance gains from 17% to 53% on a random subset of SWE
Bench Verified, with additional performance gains on LiveCodeBench, as well as
synthetically generated agent benchmarks. Our work represents an advancement in
the automated and open-ended design of agentic systems, and provides a
reference agent framework for those seeking to post-train LLMs on tool use and
other agentic tasks.


## AI 摘要

研究表明，配备基础编程工具的大语言模型（LLM）编码代理能够自主修改自身代码，从而显著提升基准任务表现。在SWE Bench Verified随机子集上，性能提升幅度达17%至53%，在LiveCodeBench和合成代理基准测试中也观察到额外增益。该工作推动了自主开放式智能代理系统的发展，为后续研究工具使用和代理任务的LLM微调提供了参考框架。这一突破展示了LLM通过自我迭代实现能力进化的潜力，为自动化智能系统设计开辟了新方向。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-22T18:01:42Z
- **目录日期**: 2025-04-22
