# A Self-Improving Coding Agent

**URL**: http://arxiv.org/abs/2504.15228v1

## 原始摘要

We demonstrate that an LLM coding agent, equipped with basic coding tools,
can autonomously edit itself, and thereby improve its performance on benchmark
tasks. We find performance gains from 17% to 53% on a random subset of SWE
Bench Verified, with additional performance gains on LiveCodeBench, as well as
synthetically generated agent benchmarks. Our work represents an advancement in
the automated and open-ended design of agentic systems, and provides a
reference agent framework for those seeking to post-train LLMs on tool use and
other agentic tasks.


## AI 摘要

研究表明，配备基本编码工具的大语言模型（LLM）编码代理能够自主修改自身代码，从而显著提升基准任务表现。在SWE Bench Verified随机子集上，性能提升幅度达17%-53%，在LiveCodeBench和合成代理基准测试中也观察到额外增益。该工作推动了自主开放式智能代理系统的发展，为后续基于工具使用和代理任务的大语言模型微调提供了参考框架。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-22T04:01:41Z
- **目录日期**: 2025-04-22
