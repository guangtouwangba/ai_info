# A Self-Improving Coding Agent

**URL**: http://arxiv.org/abs/2504.15228v1

## 原始摘要

We demonstrate that an LLM coding agent, equipped with basic coding tools,
can autonomously edit itself, and thereby improve its performance on benchmark
tasks. We find performance gains from 17% to 53% on a random subset of SWE
Bench Verified, with additional performance gains on LiveCodeBench, as well as
synthetically generated agent benchmarks. Our work represents an advancement in
the automated and open-ended design of agentic systems, and provides a
reference agent framework for those seeking to post-train LLMs on tool use and
other agentic tasks.


## AI 摘要

研究表明，配备基本编码工具的大语言模型（LLM）编码代理能够自主修改自身代码，从而提升基准任务表现。在SWE Bench Verified随机子集上，性能提升达17%至53%，在LiveCodeBench和合成代理基准测试中也观察到额外增益。该工作推动了自主开放式智能代理系统的设计，为工具使用和其他代理任务的后训练提供了参考框架。这一突破展示了LLM通过自我迭代实现持续优化的潜力，为开发更强大的自主智能系统奠定了基础。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-22T15:01:54Z
- **目录日期**: 2025-04-22
