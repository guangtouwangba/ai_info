# A Self-Improving Coding Agent

**URL**: http://arxiv.org/abs/2504.15228v1

## 原始摘要

We demonstrate that an LLM coding agent, equipped with basic coding tools,
can autonomously edit itself, and thereby improve its performance on benchmark
tasks. We find performance gains from 17% to 53% on a random subset of SWE
Bench Verified, with additional performance gains on LiveCodeBench, as well as
synthetically generated agent benchmarks. Our work represents an advancement in
the automated and open-ended design of agentic systems, and provides a
reference agent framework for those seeking to post-train LLMs on tool use and
other agentic tasks.


## AI 摘要

研究表明，配备基础编程工具的大语言模型（LLM）编码代理能够自主修改自身代码，从而显著提升基准任务性能。在SWE Bench Verified随机子集上，性能提升达17%至53%，在LiveCodeBench和合成代理基准测试中也表现更优。该研究推动了自动化、开放式智能代理系统的设计，为工具使用和代理任务的后训练提供了参考框架。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-22T06:01:45Z
- **目录日期**: 2025-04-22
