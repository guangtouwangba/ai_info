# #一图介绍八种AI模型##AI模型不仅只有LLM#LLM是一种强大的AI模型，但实际上，AI模型的种类远不止于此。这张图生动形象地总结了八种AI模型的前沿架构，它们各自擅...

**URL**: https://weibo.com/6105753431/PsyJIi7OC

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%B8%80%E5%9B%BE%E4%BB%8B%E7%BB%8D%E5%85%AB%E7%A7%8DAI%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E4%B8%80%E5%9B%BE%E4%BB%8B%E7%BB%8D%E5%85%AB%E7%A7%8DAI%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#一图介绍八种AI模型#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23AI%E6%A8%A1%E5%9E%8B%E4%B8%8D%E4%BB%85%E5%8F%AA%E6%9C%89LLM%23&amp;extparam=%23AI%E6%A8%A1%E5%9E%8B%E4%B8%8D%E4%BB%85%E5%8F%AA%E6%9C%89LLM%23" data-hide=""><span class="surl-text">#AI模型不仅只有LLM#</span></a><br><br>LLM是一种强大的AI模型，但实际上，AI模型的种类远不止于此。<br><br>这张图生动形象地总结了八种AI模型的前沿架构，它们各自擅长不同的任务。<br><br>一起来深入了解一下：<br><br>一、大语言模型（Large Language Model）<br>1. 输入（Input）<br>2. 标记化（Tokenization）：将输入的文本分解成token<br>3. 嵌入表示（Embedding）：将token映射为高维向量，捕捉其语义和语法特征<br>4. Transformer处理：通过多层自注意力机制和前馈神经网络，建模token之间的上下文依赖关系<br>5. 输出（Output）：基于概率分布生成最合理的后续文本<br><br>二、潜在上下文模型（Latent Context Model），专注于长上下文建模的架构<br>1. 输入（Input）<br>2. 句子分割（Sentence Segmentation）：将输入的文本分割成独立的句子或短语。<br>3. SONAR嵌入（SONAR Embedding）：提取句子中的语义和语法信息，生成包含丰富上下文的向量表示<br>4. 扩散处理（Diffusion）：用于增强句子之间的联系，减少噪声或补充缺失的信息，从而更好地理解上下文<br>5. 隐式处理（Hidden Process）：模型会进一步提取文本中更高层次的抽象特征，例如上下文融合和消除歧义<br>6. 高级模式识别（Advanced Patterning）：识别文本中的复杂模式，如情感、意图、实体关系等<br>7. 量化（Quantization）：对特征表示进行低精度编码，提升计算效率<br>8. 输出（Output）<br><br>三、语言-行动模型（Language-Action Model），专注于将语言理解转化为实际行动<br>1. 输入处理（Input Processing）：消除噪声，将输入转换为结构化数据<br>2. 感知系统（Perception System）：提取上下文信息，补充纯语言之外的语义<br>3. 意图识别（Intent Recognition）：识别用户指令的核心目标与隐含需求<br>4. 任务分解（Task Breakdown）：将复杂的任务分解成一系列简单的步骤<br>5. 神经符号整合（Neuro-Symbolic Integration）：将语言指令转化为具体的行动计划<br>6. 行动规划与记忆系统：避免重复操作，个性化响应<br>7. 神经符号整合（Neuro-Symbolic Integration）：不断检查和修正行动计划中的冲突，确保计划的可行性<br>8. 反馈集成（Feedback Integration）：实现闭环学习，优化后续决策<br><br>四、混合专家系统（Mixture of Experts），是一种稀疏化的大模型架构<br>1. 输入处理（Input）：对输入进行预处理，使其适合后续路由和专家处理。<br>2. 路由机制（Router Mechanism）：根据输入数据的特点，决定将数据分配给哪些专家模型进行处理。<br>3. 专家网络（Expert 1-4）：包含多个独立子网络，每个专家处理输入的不同方面<br>4. Top-k选择：从所有专家模型中选出最相关的k个专家<br>5. 加权组合：结合多个专家的知识，生成最终表示<br>6. 输出（Output）<br><br>五、视觉-语言多模态模型（Vision-Language Model），能够建模图像与文本的跨模态长上下文<br>1. 双模态输入：图像输入与文本输入<br>2. 编码器层：模型使用不同的编码器分别处理图像和文本，将它们转换成向量表示<br>3. 投影接口（Projection Interface）：将图像和文本的向量表示映射到一个共享的语义空间，使得它们可以进行比较和交互<br>4. 多模态处理器（Multimodal Processor）：深度融合视觉和语言特征，进行跨模态交互<br>5. 语言模型（Language Model）：基于融合后的多模态表示，生成自然语言的输出<br>6. 输出生成（Output Generation）<br><br>六、轻量化语言模型（Small Language Model），是专门为资源受限环境优化的精简版AI模型<br>1. 输入处理（Input Processing）<br>2. 紧凑分词（Compact Tokenization）：采用精简词汇表，减少token序列长度，降低计算开销<br>3. 优化嵌入（Optimized Embeddings）：将token映射为低维向量，减少存储和计算成本<br>4. 高效Transformer（Efficiency Transformer）：减少注意力计算开销，让模型在低算力设备上也能运行。<br>5. 模型量化（Model Quantization）：让模型体积缩小3-4倍，便于存储和传输<br>6. 内存优化（Memory Optimization）：减少运行时内存占用，适应边缘设备限制。<br>7. 边缘部署（Edge Deployment）：将模型部署到手机、嵌入式设备等终端。<br>8. 输出生成（Output Generation）<br><br>七、掩码语言模型（Masked Language Model），是一种通过预测被遮盖的词汇来学习语言规律的AI模型<br>1. 文本输入（Text Input）<br>2. 掩码处理（Token Masking）：随机遮盖输入文本中的词汇<br>3. 嵌入层（Embedding Layer）：把每个词转换成向量，让模型能计算<br>4. 左上下文和右上下文：同时利用被掩码词左右两侧的上下文信息<br>5. 双向注意力（Bidirectional Attention）：让模型同时从左到右、从右到左分析句子，全面理解上下文<br>6. 掩码预测（Masked Token Prediction）：模型根据上下文猜出被掩码的词<br>7. 特征表示（Feature Representation）：把简单的词向量升级成包含上下文信息的“综合特征”<br><br>八、通用分割模型（Segment Anything Model），能够根据简单指令自动识别并分割图像中的任意物体<br>1. 双模态输入：提示输入与图像输入<br>2. 编码器层：使用不同的编码器将提示和图像映射到统一的特征空间<br>3. 特征相关计算（Feature Correlation）：建立提示和图像区域之间的关联，引导模型关注相关的图像区域。<br>4. 图像嵌入（Image Embedding）：将图像特征压缩成高维向量，保留关键信息。<br>5. 掩码解码器（Mask Decoder）：根据提示和图像特征，生成目标的分割掩码<br>6. Feature Correlation（特征相关性计算）：在生成掩码时动态调整提示与图像的关系，提高分割的准确性。<br>7. 分割输出（Segmentation Output）：输出最终的分割结果<img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i1kxfaeoapg30m80rse81.gif" referrerpolicy="no-referrer"><br><br>

## AI 摘要

这张图总结了八种AI模型架构：1）大语言模型（LLM）通过Transformer处理文本；2）潜在上下文模型专注长文本理解；3）语言-行动模型将指令转为具体行动；4）混合专家系统动态分配任务给专业子模型；5）视觉-语言模型处理图像与文本的跨模态交互；6）轻量化模型优化资源占用；7）掩码语言模型通过预测遮盖词学习语义；8）通用分割模型实现图像任意区域分割。每种模型针对不同任务设计，展现了AI技术的多样性。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-19T13:13:15Z
- **目录日期**: 2025-05-19
