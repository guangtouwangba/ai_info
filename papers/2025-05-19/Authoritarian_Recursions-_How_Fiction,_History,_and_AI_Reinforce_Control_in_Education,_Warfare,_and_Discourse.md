# Authoritarian Recursions: How Fiction, History, and AI Reinforce Control in Education, Warfare, and Discourse

**URL**: http://arxiv.org/abs/2504.09030v2

## 原始摘要

This article introduces the concept of \textit{authoritarian recursion} to
describe how artificial intelligence (AI) systems increasingly mediate control
across education, warfare, and digital discourse. Drawing on critical discourse
analysis and sociotechnical theory, the study reveals how AI-driven platforms
delegate judgment to algorithmic processes, normalize opacity, and recursively
reinforce behavioral norms under the guise of neutrality and optimization. Case
studies include generative AI models in classroom surveillance, autonomous
targeting in military AI systems, and content curation logics in platform
governance.
  Rather than treating these domains as disparate, the paper maps their
structural convergence within recursive architectures of abstraction,
surveillance, and classification. These feedback systems do not simply automate
tasks -- they encode modes of epistemic authority that disperse accountability
while intensifying political asymmetries. Through cultural and policy analysis,
the article argues that authoritarian recursion operates as a hybrid logic,
fusing technical abstraction with state and market imperatives. The paper
concludes by outlining implications for democratic legitimacy, human oversight,
and the political design of AI governance frameworks.
  This framework contributes to emerging debates on algorithmic accountability
by foregrounding how recursion acts not merely as a technical function but as a
sociopolitical instrument of control.


## AI 摘要

这篇论文提出"威权递归"概念，揭示AI系统如何通过算法中介在教育、军事和数字话语中实施控制。研究表明，AI平台将判断权委托给算法流程，以中立和优化为名，使不透明操作常态化并递归强化行为规范。通过课堂监控、军事目标识别和内容审核等案例，作者指出这些领域在抽象化、监控和分类的递归架构中趋同。这种递归不仅是技术功能，更成为分散责任、加剧政治不对称的社会控制工具。文章批判了技术抽象与政府/市场需求的结合，呼吁关注AI治理对民主合法性和人类监督的影响。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-19T13:11:41Z
- **目录日期**: 2025-05-19
