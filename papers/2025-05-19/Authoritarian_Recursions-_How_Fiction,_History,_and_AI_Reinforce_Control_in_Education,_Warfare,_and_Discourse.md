# Authoritarian Recursions: How Fiction, History, and AI Reinforce Control in Education, Warfare, and Discourse

**URL**: http://arxiv.org/abs/2504.09030v2

## 原始摘要

This article introduces the concept of \textit{authoritarian recursion} to
describe how artificial intelligence (AI) systems increasingly mediate control
across education, warfare, and digital discourse. Drawing on critical discourse
analysis and sociotechnical theory, the study reveals how AI-driven platforms
delegate judgment to algorithmic processes, normalize opacity, and recursively
reinforce behavioral norms under the guise of neutrality and optimization. Case
studies include generative AI models in classroom surveillance, autonomous
targeting in military AI systems, and content curation logics in platform
governance.
  Rather than treating these domains as disparate, the paper maps their
structural convergence within recursive architectures of abstraction,
surveillance, and classification. These feedback systems do not simply automate
tasks -- they encode modes of epistemic authority that disperse accountability
while intensifying political asymmetries. Through cultural and policy analysis,
the article argues that authoritarian recursion operates as a hybrid logic,
fusing technical abstraction with state and market imperatives. The paper
concludes by outlining implications for democratic legitimacy, human oversight,
and the political design of AI governance frameworks.
  This framework contributes to emerging debates on algorithmic accountability
by foregrounding how recursion acts not merely as a technical function but as a
sociopolitical instrument of control.


## AI 摘要

这篇论文提出"威权递归"概念，揭示人工智能系统如何在教育、军事和数字话语领域通过算法中介实施控制。研究指出，AI平台以中立和优化为名，将判断权委托给算法流程，使不透明操作常态化，并递归强化行为规范。通过课堂监控、军事目标识别和内容审核等案例，论文展示了这些系统如何通过抽象化、监控和分类的递归架构，将技术抽象与国家/市场需求结合，形成混合控制逻辑，加剧政治不对称并分散问责。研究强调递归不仅是技术功能，更是社会政治控制工具，对AI治理框架的民主合法性提出挑战。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-19T12:02:25Z
- **目录日期**: 2025-05-19
