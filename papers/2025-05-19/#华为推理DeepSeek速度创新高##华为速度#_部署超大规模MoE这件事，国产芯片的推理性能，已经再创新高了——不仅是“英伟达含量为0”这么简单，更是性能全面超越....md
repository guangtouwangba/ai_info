# #华为推理DeepSeek速度创新高##华为速度# 部署超大规模MoE这件事，国产芯片的推理性能，已经再创新高了——不仅是“英伟达含量为0”这么简单，更是性能全面超越...

**URL**: https://weibo.com/6105753431/PsxahsZ0N

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%8D%8E%E4%B8%BA%E6%8E%A8%E7%90%86DeepSeek%E9%80%9F%E5%BA%A6%E5%88%9B%E6%96%B0%E9%AB%98%23&amp;extparam=%23%E5%8D%8E%E4%B8%BA%E6%8E%A8%E7%90%86DeepSeek%E9%80%9F%E5%BA%A6%E5%88%9B%E6%96%B0%E9%AB%98%23" data-hide=""><span class="surl-text">#华为推理DeepSeek速度创新高#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%8D%8E%E4%B8%BA%E9%80%9F%E5%BA%A6%23" data-hide=""><span class="surl-text">#华为速度#</span></a> <br><br>部署超大规模MoE这件事，国产芯片的推理性能，已经再创新高了——<br><br>不仅是“英伟达含量为0”这么简单，更是性能全面超越英伟达Hopper架构！<br><br>而做到这一点的，正是华为昇腾；具体而言，共包含两个产品：<br><br>- CloudMatrix 384超节点：部署DeepSeek V3/R1，在50ms时延约束下单卡Decode吞吐突破1920 Tokens/s<br>- Atlas 800I A2推理服务器：部署DeepSeek V3/R1，在100ms时延约束下单卡吞吐达到808 Tokens/s，可支持灵活的分布式部署<br><br>之所以能够这般，是因为华为昇腾所采取的“以数学补物理”——这种通过数学理论、工具、算法和建模等方式，来弥补硬件和工艺的局限性，实现最大化发挥芯片和系统能力效果。<br><br>华为昇腾还不只是“官宣”一下而已，后面更会是全面开源。<br><br>不仅已经将昇腾在超大规模MoE模型推理部署的技术报告分享了出来，在一个月时间内，还会把实现这些核心技术的相关代码也都会陆续开源出来。<br><br>那么接下来，我们就来深入了解一下华为昇腾背后的技术实力。<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUzXNIFesgBcMtfetgp2Y7Q" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">华为+DeepSeek，推理性能创新高！技术报告也公布出来了</span></a><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3ly1i1kqhf0vqej30u00gn4hm.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

华为昇腾在超大规模MoE模型推理部署上取得突破性进展，性能超越英伟达Hopper架构。其CloudMatrix 384超节点和Atlas 800I A2推理服务器分别实现单卡1920 Tokens/s（50ms时延）和808 Tokens/s（100ms时延）的高吞吐量。关键技术在于"以数学补物理"，通过算法优化弥补硬件限制。华为宣布将开源相关技术报告及核心代码，进一步推动国产AI芯片发展。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-19T06:02:47Z
- **目录日期**: 2025-05-19
