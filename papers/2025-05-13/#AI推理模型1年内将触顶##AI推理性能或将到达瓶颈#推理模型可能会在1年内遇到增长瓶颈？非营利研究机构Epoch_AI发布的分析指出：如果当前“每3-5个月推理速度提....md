# #AI推理模型1年内将触顶##AI推理性能或将到达瓶颈#推理模型可能会在1年内遇到增长瓶颈？非营利研究机构Epoch AI发布的分析指出：如果当前“每3-5个月推理速度提...

**URL**: https://weibo.com/6105753431/PrEaIAFqH

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23AI%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B1%E5%B9%B4%E5%86%85%E5%B0%86%E8%A7%A6%E9%A1%B6%23&amp;extparam=%23AI%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B1%E5%B9%B4%E5%86%85%E5%B0%86%E8%A7%A6%E9%A1%B6%23" data-hide=""><span class="surl-text">#AI推理模型1年内将触顶#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23AI%E6%8E%A8%E7%90%86%E6%80%A7%E8%83%BD%E6%88%96%E5%B0%86%E5%88%B0%E8%BE%BE%E7%93%B6%E9%A2%88%23&amp;extparam=%23AI%E6%8E%A8%E7%90%86%E6%80%A7%E8%83%BD%E6%88%96%E5%B0%86%E5%88%B0%E8%BE%BE%E7%93%B6%E9%A2%88%23" data-hide=""><span class="surl-text">#AI推理性能或将到达瓶颈#</span></a><br><br>推理模型可能会在1年内遇到增长瓶颈？<br><br>非营利研究机构Epoch AI发布的分析指出：如果当前“每3-5个月推理速度提升10倍”的趋势继续下去，所需的算力将快速收敛，也就是说，AI的扩展空间会迅速被吃光。【图1】<br><br>看了这个结果，有围观网友都着急了：既然在o3基础上再scaling非常困难，那为啥咱不探索模块化架构或针对特定任务的专用模型呢？“效率”比“研究过剩”更重要！【图2】<br><br>这份研究主要聚焦OpenAI的推理模型发展路径，从o1到o3，再参考DeepSeek-R1、Llama-Nemotron、微软Phi-4-reasoning等模型的公开数据，推导出目前推理训练还处在“还能再卷一卷”的阶段。<br><br>关键信息如下：<br><br>首先，OpenAI公开过这样一张图表，上面展示了o3和o1在AIME基准测试中的表现，以及两者在推理训练阶段可能所需的算力的对比——【图3】<br><br>可以看到，终版o3花费的算力是o1的10倍。<br><br>Epoch AI分析道：“x轴很可能显示的是推理训练所需算力而不是总算力。”<br><br>Epoch AI罗列了这一猜测的证据。<br><br>第一，初代o1耗费的算力比o3低四个数量级，其在AIME上的得分约为25%。<br><br>如果x轴表示总计算量，“不太可能呈现这种情况”。<br><br>第二，如果x轴表示的是所需总算力，这张图意义就不大了。<br><br>因为这就意味着OpenAI训练了N个版本的o1，且预训练阶段非常不完整。<br><br>依照Epoch AI的猜测，如果o3在推理结算花费的算力是o1的10倍，这意味着什么？<br><br>由于很多推理模型背后团队都学精了，并不公开训练方法和过程，所以只能从现有公开资料里去寻找答案。<br><br>比如DeepSeek-R1。<br><br>Epoch AI此前估算，DeepSeek-R1推理训练中使用的算力约为6e23 FLOP（成本约 100 万美元），需要生成大约 20万亿个tokens——这只有DeepSeek-V3预训练成本的20%。<br><br>虽然只是一种估算，但R1在各个榜单上的得分和o1非常接近，“因此可以用它来为o1所需算力设定一个baseline”。<br><br>比如英伟达的Llama-Nemotron Ultra，它在各个基准上的分数与DeepSeek-R1和o1相当。<br><br>它是在DeepSeek-R1生成的数据上训练的。<br><br>公开信息显示，Llama-Nemotron Ultra的推理阶段耗时140000 H100小时，约等于1e23 FLOP。这甚至低于它的原始基础模型预训练成本的1%。<br><br>再比如微软的Phi-4-reasoning。<br><br>它是在o3-mini生成的数据上训练的。<br><br>Phi-4-reasoning在推理阶段规模更小，成本低于1e20 FLOP，可能是预训练所需算力成本的&lt;0.01%。<br><br>值得注意的是，Llama-Nemotron和Phi-4-reasoning都在RL阶段之前进行了有监督微调。<br><br>咱们再来看看今年1月DeepSeek-R1发布后，Anthropic的CEODario Amodei写的一篇文章，这被视为关于现有推理模型所需算力规模的最后一点线索：<br><br>由于这是新范式，我们目前仍处于规模拓展的初期阶段：所有参与者在第二阶段投入的资金量都很少，花费从10万美元提高到100万美元就能带来巨大收益。  <br>如今，各公司正迅速加快步伐，将第二阶段的规模扩大到数亿乃至数十亿美元。  <br>有一点必须重视，那就是我们正处于一个独特的转折点上。<br><br>当然了，Amodei对非Anthropic模型所需算力的看法可能只基于自家公司内部数据。<br><br>但可以清晰了解，截至今年1月，他认为推理模型的训练成本远低于“数千万美元”，大于1e26 FLOP。<br><br>Epoch AI总结道——<br><br>上述的预估和线索指向一个事实，那就是目前最前沿的推理模型，比如o1，甚至o3，它们的推理训练规模都还没见顶，还能继续scalable。<br><br>但1年内可能就撞墙了  <br>换句话说，如果推理训练还没见顶，那么推理模型还是有潜力在短期内快速实现能力拓展的。<br><br>这就意味着，推理模型还很能打，潜力巨大。<br><br>就像OpenAI展示出的下图，以及DeepSeek-R1论文中的图2一样——模型答题准确率随着推理训练步骤的增加而大致呈对数线性增长。【图4】<br><br>这表明，至少在数学和编程任务上，推理模型的性能随着推理训练的扩展而增强，就像预训练的scaling law一样。<br><br>行文至此处，Epoch AI写下这样一段话：<br><br>如果推理阶段的算力需求见顶，那么其带来的增长率将收敛，大概是每年增长4倍。  <br>绝不会像o1推出后4个月就有了o3那样，保持几个月增长10倍的态势。<br><br>因此，他得出这样一个结论——<br><br>如果一个推理模型的训练阶段仅比前沿推理模型低几个（比如说少于三个）数量级，这种增长率可能在一、两年内减缓，甚至撞墙。<br><br>然鹅，想要扩展推理模型并不是那么简单的。<br><br>单单是数据不够这一项，就可能导致其停滞不前。<br><br>大家也都还不清楚，除了数学、编程领域，推理训练是否能泛化到其它规律性没那么强的领域。<br><br>但可以肯定的是，随着推理模型的训练越来越成熟，所有推理模型所需的成本可能都趋同。<br><br>虽然研究成本的高低并不影响算力和性能之间的关系，但如果相关研究保持“花钱如流水”的状态，那么推理模型可能无法达到人们心中预期的最佳水平。<br><br>另一方面，即使所需算力的增长速度放缓，推理模型也可能持续进化，就像R1那样。<br><br>换句话说，不只有数据或算法创新能推动推理模型的进步，算力大增也是推动推理模型进步的关键因素。<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fcgi-bin%2Fappmsgpublish%3Fsub%3Dlist%26begin%3D0%26count%3D10%26token%3D313163021%26lang%3Dzh_CN" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br><br>参考链接：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fepoch.ai%2Fgradient-updates%2Fhow-far-can-reasoning-models-scale" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1dyzkz6sgj30s50k0afw.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1dyzkquz2j30zk0aiq87.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i1dyzlatnhj30zk0ivwgj.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i1dyzl3ymmj30va0k0dhq.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

Epoch AI最新研究指出，当前AI推理模型（如OpenAI的o3、DeepSeek-R1等）仍处于算力扩展的红利期，性能随训练算力投入呈对数级提升。但若保持现有"每3-5个月推理速度提升10倍"的趋势，算力需求将快速收敛，预计1年内触及增长瓶颈。数据显示，o3推理训练算力已达o1的10倍，而微软Phi-4等模型推理成本已不足预训练的0.01%。虽然数学/编程领域仍存扩展空间，但数据短缺和泛化能力限制可能迫使行业转向模块化架构或专用模型开发。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-13T11:03:25Z
- **目录日期**: 2025-05-13
