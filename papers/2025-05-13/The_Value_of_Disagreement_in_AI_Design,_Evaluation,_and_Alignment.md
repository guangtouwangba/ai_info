# The Value of Disagreement in AI Design, Evaluation, and Alignment

**URL**: http://arxiv.org/abs/2505.07772v1

## 原始摘要

Disagreements are widespread across the design, evaluation, and alignment
pipelines of artificial intelligence (AI) systems. Yet, standard practices in
AI development often obscure or eliminate disagreement, resulting in an
engineered homogenization that can be epistemically and ethically harmful,
particularly for marginalized groups. In this paper, we characterize this risk,
and develop a normative framework to guide practical reasoning about
disagreement in the AI lifecycle. Our contributions are two-fold. First, we
introduce the notion of perspectival homogenization, characterizing it as a
coupled ethical-epistemic risk that arises when an aspect of an AI system's
development unjustifiably suppresses disagreement and diversity of
perspectives. We argue that perspectival homogenization is best understood as a
procedural risk, which calls for targeted interventions throughout the AI
development pipeline. Second, we propose a normative framework to guide such
interventions, grounded in lines of research that explain why disagreement can
be epistemically beneficial, and how its benefits can be realized in practice.
We apply this framework to key design questions across three stages of AI
development tasks: when disagreement is epistemically valuable; whose
perspectives should be included and preserved; how to structure tasks and
navigate trade-offs; and how disagreement should be documented and
communicated. In doing so, we challenge common assumptions in AI practice,
offer a principled foundation for emerging participatory and pluralistic
approaches, and identify actionable pathways for future work in AI design and
governance.


## AI 摘要

当前人工智能（AI）系统的设计、评估和对齐流程中普遍存在分歧，但标准化实践常压制或消除分歧，导致“视角同质化”风险，可能对边缘群体造成伦理和认知危害。本文提出“视角同质化”概念，指出其作为程序性风险会不公正地压制多元观点，需在AI开发全流程干预。作者构建了规范性框架，强调分歧的认知价值，并指导实践：何时需要分歧、应纳入哪些视角、如何权衡取舍及记录分歧。该研究挑战了AI常规假设，为参与式、多元化方法提供理论基础，并为未来AI治理指明可行路径。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-13T20:02:07Z
- **目录日期**: 2025-05-13
