# The Value of Disagreement in AI Design, Evaluation, and Alignment

**URL**: http://arxiv.org/abs/2505.07772v1

## 原始摘要

Disagreements are widespread across the design, evaluation, and alignment
pipelines of artificial intelligence (AI) systems. Yet, standard practices in
AI development often obscure or eliminate disagreement, resulting in an
engineered homogenization that can be epistemically and ethically harmful,
particularly for marginalized groups. In this paper, we characterize this risk,
and develop a normative framework to guide practical reasoning about
disagreement in the AI lifecycle. Our contributions are two-fold. First, we
introduce the notion of perspectival homogenization, characterizing it as a
coupled ethical-epistemic risk that arises when an aspect of an AI system's
development unjustifiably suppresses disagreement and diversity of
perspectives. We argue that perspectival homogenization is best understood as a
procedural risk, which calls for targeted interventions throughout the AI
development pipeline. Second, we propose a normative framework to guide such
interventions, grounded in lines of research that explain why disagreement can
be epistemically beneficial, and how its benefits can be realized in practice.
We apply this framework to key design questions across three stages of AI
development tasks: when disagreement is epistemically valuable; whose
perspectives should be included and preserved; how to structure tasks and
navigate trade-offs; and how disagreement should be documented and
communicated. In doing so, we challenge common assumptions in AI practice,
offer a principled foundation for emerging participatory and pluralistic
approaches, and identify actionable pathways for future work in AI design and
governance.


## AI 摘要

这篇论文探讨了人工智能（AI）开发中忽视分歧的伦理与认知风险，提出了“视角同质化”概念，即压制多元观点可能导致对边缘群体的危害。作者主张将分歧视为有价值的资源，并提出了一个规范框架，指导在AI生命周期的各个阶段（如设计、评估和沟通）中纳入多元视角。该框架挑战了AI开发中的常见假设，支持参与式和多元化方法，并为未来AI设计与治理提供了可操作的路径。核心观点是：合理保留分歧能提升AI系统的公平性与认知质量，需通过系统性干预实现这一目标。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-13T21:01:51Z
- **目录日期**: 2025-05-13
