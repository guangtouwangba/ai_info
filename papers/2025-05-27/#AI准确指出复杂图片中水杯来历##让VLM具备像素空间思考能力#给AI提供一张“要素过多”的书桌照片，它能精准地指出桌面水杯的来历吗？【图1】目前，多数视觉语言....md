# #AI准确指出复杂图片中水杯来历##让VLM具备像素空间思考能力#给AI提供一张“要素过多”的书桌照片，它能精准地指出桌面水杯的来历吗？【图1】目前，多数视觉语言...

**URL**: https://weibo.com/6105753431/PtCziA9Xo

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23AI%E5%87%86%E7%A1%AE%E6%8C%87%E5%87%BA%E5%A4%8D%E6%9D%82%E5%9B%BE%E7%89%87%E4%B8%AD%E6%B0%B4%E6%9D%AF%E6%9D%A5%E5%8E%86%23&amp;extparam=%23AI%E5%87%86%E7%A1%AE%E6%8C%87%E5%87%BA%E5%A4%8D%E6%9D%82%E5%9B%BE%E7%89%87%E4%B8%AD%E6%B0%B4%E6%9D%AF%E6%9D%A5%E5%8E%86%23" data-hide=""><span class="surl-text">#AI准确指出复杂图片中水杯来历#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%A9VLM%E5%85%B7%E5%A4%87%E5%83%8F%E7%B4%A0%E7%A9%BA%E9%97%B4%E6%80%9D%E8%80%83%E8%83%BD%E5%8A%9B%23&amp;extparam=%23%E8%AE%A9VLM%E5%85%B7%E5%A4%87%E5%83%8F%E7%B4%A0%E7%A9%BA%E9%97%B4%E6%80%9D%E8%80%83%E8%83%BD%E5%8A%9B%23" data-hide=""><span class="surl-text">#让VLM具备像素空间思考能力#</span></a><br><br>给AI提供一张“要素过多”的书桌照片，它能精准地指出桌面水杯的来历吗？【图1】<br><br>目前，多数视觉语言模型主要通过文字来分析图像，这限制了它们对视觉细节的深入理解和直观推理。<br><br>受GPT-o3图像内思考的启发，来自港科大和中科大的研究团队推出了开源框架Pixel Reasoner，让模型在像素空间中进行推理。<br><br>Pixel Reasoner将视觉操作（如放大、选取）直接转化为AI的推理动作，从而构建出更直接的视觉推理机制。<br><br>在训练过程中，研究人员发现视觉语言模型常常存在“偏科”现象：文本推理强而像素空间推理弱。<br><br>这导致AI常倾向于放弃视觉操作，转而依赖文本推理，只为追求“正确答案”。<br><br>为了解决这个问题，团队采用了两阶段训练：温启动指令调整和好奇心驱动的强化学习。<br><br>1. 温启动指令调整<br>- 数据收集：从包含丰富视觉信息和明确标注的数据集中，收集视觉语言查询。<br>- 专家轨迹合成：利用GPT-4o生成带有视觉操作的专家轨迹，并模拟错误操作以训练AI自我纠正。<br>- 训练：通过监督微调（SFT）进行训练，并屏蔽错误操作的损失，防止模型学习执行错误。<br><br>2. 好奇心驱动的强化学习：<br>- 约束优化问题：将培养像素空间推理的目标形式化为一个约束优化问题，包括像素空间推理的触发率（RaPR）和视觉操作的数量限制。<br>- 拉格朗日松弛：通过拉格朗日松弛将约束优化问题转化为无约束问题，引入了“好奇心奖励”和“效率惩罚”。<br>- 训练：使用OpenRLHF实现基于GRPO的RL训练，通过选择性样本回放（SSR）解决优势消失问题，让模型在保持效率的同时，更多地利用像素空间推理。<br><br>实验表明，Pixel Reasoner在多项视觉推理测试中表现出色，如V* Bench、TallyQA-Complex和InfographicsVQA，超越了现有开源及部分专有模型。<br><br>交互式Demo：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhuggingface.co%2Fspaces%2FTIGER-Lab%2FPixel-Reasoner" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>项目主页：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Ftiger-ai-lab.github.io%2FPixel-Reasoner%2F" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>代码仓库：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FTIGER-AI-Lab%2FPixel-Reasoner" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>论文主页：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2505.15966" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i1t0077snuj31040pqndt.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i1t008ba00j30gg0oyn23.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3ly1i1t014kikxj31hc0u074c.jpg" referrerpolicy="no-referrer"><br><br><br clear="both"><div style="clear: both"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/006Fd7o3ly1i1t01478pzj31hc0u0wic.jpg" style="width: 100%"><source src="https://f.video.weibocdn.com/o0/9zJxhczjlx08oy2pQQZi01041200bW2r0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1748316678&amp;ssig=smkhjcmVfh&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/X2gZzq0Plx08oy2p6Tgs010412005YMt0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1748316678&amp;ssig=ME1Sn9rl0R&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/X0MxLkHolx08oy2qrDQk010412003BhO0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1748316678&amp;ssig=FwWRDbd5vq&amp;KID=unistore,video"><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5170597303615498" target="_blank" rel="noopener noreferrer">微博视频</a>观看。</p></video>

## AI 摘要

港科大和中科大团队开发了开源框架Pixel Reasoner，通过让视觉语言模型(VLM)直接在像素空间进行推理（如放大、选取等视觉操作），提升其对复杂图片的细节理解能力。该研究采用两阶段训练：1）温启动指令调整，利用GPT-4o生成带视觉操作的专家轨迹；2）好奇心驱动的强化学习，通过约束优化促进模型主动使用像素推理。实验显示，该方法在V* Bench等测试中超越现有模型，解决了传统VLM过度依赖文本推理的问题。项目已开源，提供在线Demo和论文。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-27T02:32:51Z
- **目录日期**: 2025-05-27
