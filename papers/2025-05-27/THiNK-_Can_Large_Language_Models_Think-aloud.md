# THiNK: Can Large Language Models Think-aloud?

**URL**: http://arxiv.org/abs/2505.20184v1

## 原始摘要

Assessing higher-order thinking skills in large language models (LLMs)
remains a fundamental challenge, especially in tasks that go beyond
surface-level accuracy. In this work, we propose THiNK (Testing Higher-order
Notion of Knowledge), a multi-agent, feedback-driven evaluation framework
grounded in Bloom's Taxonomy. THiNK frames reasoning assessment as an iterative
task of problem generation, critique, and revision, encouraging LLMs to
think-aloud through step-by-step reflection and refinement. This enables a
systematic evaluation of both lower-order (e.g., remember, understand) and
higher-order (e.g., evaluate, create) thinking skills. We apply THiNK to seven
state-of-the-art LLMs and perform a detailed cognitive analysis of their
outputs. Results reveal that while models reliably perform lower-order
categories well, they struggle with applying knowledge in realistic contexts
and exhibit limited abstraction. Structured feedback loops significantly
improve reasoning performance, particularly in higher-order thinking.
Qualitative evaluations further confirm that THiNK-guided outputs better align
with domain logic and problem structure. The code of our framework provides a
scalable methodology for probing and enhancing LLM reasoning, offering new
directions for evaluation grounded in learning science, which is available at
our GitHub repository.


## AI 摘要

本文提出THiNK框架，基于布鲁姆分类法，通过多智能体反馈机制评估大语言模型(LLMs)的高阶思维能力。THiNK采用问题生成-批判-修订的迭代流程，引导模型逐步反思和改进，系统评估从低阶(记忆、理解)到高阶(评估、创造)的认知能力。测试7个前沿LLM发现：模型在低阶任务表现稳定，但在实际应用和抽象推理中表现欠佳；结构化反馈显著提升推理能力，尤其在高阶思维方面。定性分析表明THiNK引导的输出更符合领域逻辑。该框架为探索和增强LLM推理提供了可扩展方法。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-27T14:02:06Z
- **目录日期**: 2025-05-27
