# THiNK: Can Large Language Models Think-aloud?

**URL**: http://arxiv.org/abs/2505.20184v1

## 原始摘要

Assessing higher-order thinking skills in large language models (LLMs)
remains a fundamental challenge, especially in tasks that go beyond
surface-level accuracy. In this work, we propose THiNK (Testing Higher-order
Notion of Knowledge), a multi-agent, feedback-driven evaluation framework
grounded in Bloom's Taxonomy. THiNK frames reasoning assessment as an iterative
task of problem generation, critique, and revision, encouraging LLMs to
think-aloud through step-by-step reflection and refinement. This enables a
systematic evaluation of both lower-order (e.g., remember, understand) and
higher-order (e.g., evaluate, create) thinking skills. We apply THiNK to seven
state-of-the-art LLMs and perform a detailed cognitive analysis of their
outputs. Results reveal that while models reliably perform lower-order
categories well, they struggle with applying knowledge in realistic contexts
and exhibit limited abstraction. Structured feedback loops significantly
improve reasoning performance, particularly in higher-order thinking.
Qualitative evaluations further confirm that THiNK-guided outputs better align
with domain logic and problem structure. The code of our framework provides a
scalable methodology for probing and enhancing LLM reasoning, offering new
directions for evaluation grounded in learning science, which is available at
our GitHub repository.


## AI 摘要

本文提出了THiNK框架，一种基于布鲁姆分类法的多智能体反馈驱动评估方法，用于系统评估大语言模型（LLMs）的高阶思维能力。THiNK通过问题生成、批判和修订的迭代过程，促进模型逐步反思与优化。实验发现，现有模型在低阶认知（如记忆、理解）表现良好，但在实际应用和抽象推理方面存在不足。结构化反馈显著提升了高阶思维能力，使输出更符合领域逻辑。该框架为LLM推理能力的测评与提升提供了可扩展方法，相关代码已开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-27T06:01:49Z
- **目录日期**: 2025-05-27
