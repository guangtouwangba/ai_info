# THiNK: Can Large Language Models Think-aloud?

**URL**: http://arxiv.org/abs/2505.20184v1

## 原始摘要

Assessing higher-order thinking skills in large language models (LLMs)
remains a fundamental challenge, especially in tasks that go beyond
surface-level accuracy. In this work, we propose THiNK (Testing Higher-order
Notion of Knowledge), a multi-agent, feedback-driven evaluation framework
grounded in Bloom's Taxonomy. THiNK frames reasoning assessment as an iterative
task of problem generation, critique, and revision, encouraging LLMs to
think-aloud through step-by-step reflection and refinement. This enables a
systematic evaluation of both lower-order (e.g., remember, understand) and
higher-order (e.g., evaluate, create) thinking skills. We apply THiNK to seven
state-of-the-art LLMs and perform a detailed cognitive analysis of their
outputs. Results reveal that while models reliably perform lower-order
categories well, they struggle with applying knowledge in realistic contexts
and exhibit limited abstraction. Structured feedback loops significantly
improve reasoning performance, particularly in higher-order thinking.
Qualitative evaluations further confirm that THiNK-guided outputs better align
with domain logic and problem structure. The code of our framework provides a
scalable methodology for probing and enhancing LLM reasoning, offering new
directions for evaluation grounded in learning science, which is available at
our GitHub repository.


## AI 摘要

本文提出了THiNK框架，一个基于布鲁姆分类法的多智能体反馈驱动评估系统，用于评估大语言模型（LLMs）的高阶思维能力。THiNK通过问题生成、批评和修订的迭代过程，系统评估了从低阶（记忆、理解）到高阶（评估、创造）的认知能力。测试7个先进LLMs后发现，模型在低阶任务表现良好，但在实际应用中运用知识和抽象思维方面存在困难。结构化反馈显著提升了推理能力，尤其在高阶思维方面。THiNK引导的输出更符合领域逻辑，为基于学习科学的评估提供了新方向。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-27T08:01:44Z
- **目录日期**: 2025-05-27
