# Revisiting Adversarial Perception Attacks and Defense Methods on Autonomous Driving Systems

**URL**: http://arxiv.org/abs/2505.11532v2

## 原始摘要

Autonomous driving systems (ADS) increasingly rely on deep learning-based
perception models, which remain vulnerable to adversarial attacks. In this
paper, we revisit adversarial attacks and defense methods, focusing on road
sign recognition and lead object detection and prediction (e.g., relative
distance). Using a Level-2 production ADS, OpenPilot by Comma$.$ai, and the
widely adopted YOLO model, we systematically examine the impact of adversarial
perturbations and assess defense techniques, including adversarial training,
image processing, contrastive learning, and diffusion models. Our experiments
highlight both the strengths and limitations of these methods in mitigating
complex attacks. Through targeted evaluations of model robustness, we aim to
provide deeper insights into the vulnerabilities of ADS perception systems and
contribute guidance for developing more resilient defense strategies.


## AI 摘要

本文研究了自动驾驶系统（ADS）中基于深度学习的感知模型对抗攻击的脆弱性，以Comma.ai的OpenPilot和YOLO模型为例，系统评估了对抗扰动对路标识别和前方物体检测的影响。研究测试了多种防御方法（对抗训练、图像处理、对比学习和扩散模型），揭示了这些技术在应对复杂攻击时的优势与局限。通过针对性评估模型鲁棒性，该研究为理解ADS感知系统的漏洞提供了新见解，并为开发更有效的防御策略提供了指导。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-27T01:29:45Z
- **目录日期**: 2025-05-27
