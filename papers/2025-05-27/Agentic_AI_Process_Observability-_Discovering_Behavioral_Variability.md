# Agentic AI Process Observability: Discovering Behavioral Variability

**URL**: http://arxiv.org/abs/2505.20127v1

## 原始摘要

AI agents that leverage Large Language Models (LLMs) are increasingly
becoming core building blocks of modern software systems. A wide range of
frameworks is now available to support the specification of such applications.
These frameworks enable the definition of agent setups using natural language
prompting, which specifies the roles, goals, and tools assigned to the various
agents involved. Within such setups, agent behavior is non-deterministic for
any given input, highlighting the critical need for robust debugging and
observability tools. In this work, we explore the use of process and causal
discovery applied to agent execution trajectories as a means of enhancing
developer observability. This approach aids in monitoring and understanding the
emergent variability in agent behavior. Additionally, we complement this with
LLM-based static analysis techniques to distinguish between intended and
unintended behavioral variability. We argue that such instrumentation is
essential for giving developers greater control over evolving specifications
and for identifying aspects of functionality that may require more precise and
explicit definitions.


## AI 摘要

本文探讨了基于大型语言模型(LLM)的AI代理在现代软件系统中的核心作用。随着各种框架支持通过自然语言提示定义代理角色、目标和工具，代理行为的不确定性凸显了调试和可观测性工具的重要性。研究提出利用过程和因果发现技术分析代理执行轨迹，结合LLM静态分析技术，帮助开发者区分预期和非预期的行为变异。这种方法增强了开发者对行为变化的监控和理解能力，为规范演进提供更好控制，并识别需要更精确定义的功能方面。这些工具对确保AI代理系统的稳健性至关重要。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-27T17:02:07Z
- **目录日期**: 2025-05-27
