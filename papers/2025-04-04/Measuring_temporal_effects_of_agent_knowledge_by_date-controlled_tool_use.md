# Measuring temporal effects of agent knowledge by date-controlled tool use

**URL**: http://arxiv.org/abs/2503.04188v2

## 原始摘要

Temporal progression is an integral part of knowledge accumulation and
update. Web search is frequently adopted as grounding for agent knowledge, yet
an improper configuration affects the quality of the agent's responses. Here,
we assess the agent behavior using distinct date-controlled tools (DCTs) as
stress test to measure the knowledge variability of large language model (LLM)
agents. We demonstrate the temporal effects of an LLM agent as a writing
assistant, which uses web search to complete scientific publication abstracts.
We show that the temporality of search engine translates into tool-dependent
agent performance but can be alleviated with base model choice and explicit
reasoning instructions such as chain-of-thought prompting. Our results indicate
that agent design and evaluations should take a dynamical view and implement
measures to account for the temporal influence of external resources to ensure
reliability.


## AI 摘要

研究表明，大型语言模型（LLM）代理的知识表现受外部工具（如限定日期的搜索引擎）的时间性影响显著。通过评估LLM代理作为写作助手完成科学摘要的任务，发现其性能依赖于搜索工具的时效性。但通过合理选择基础模型和引入思维链（chain-of-thought）等显式推理指令，可缓解这一问题。研究强调，代理设计和评估需采用动态视角，并采取措施减少外部资源的时间性干扰，以确保可靠性。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-04T19:02:07Z
- **目录日期**: 2025-04-04
