# PhySense: Principle-Based Physics Reasoning Benchmarking for Large Language Models

**URL**: http://arxiv.org/abs/2505.24823v1

## 原始摘要

Large language models (LLMs) have rapidly advanced and are increasingly
capable of tackling complex scientific problems, including those in physics.
Despite this progress, current LLMs often fail to emulate the concise,
principle-based reasoning characteristic of human experts, instead generating
lengthy and opaque solutions. This discrepancy highlights a crucial gap in
their ability to apply core physical principles for efficient and interpretable
problem solving. To systematically investigate this limitation, we introduce
PhySense, a novel principle-based physics reasoning benchmark designed to be
easily solvable by experts using guiding principles, yet deceptively difficult
for LLMs without principle-first reasoning. Our evaluation across multiple
state-of-the-art LLMs and prompt types reveals a consistent failure to align
with expert-like reasoning paths, providing insights for developing AI systems
with efficient, robust and interpretable principle-based scientific reasoning.


## AI 摘要

当前大语言模型（LLMs）虽能处理复杂科学问题，但缺乏人类专家基于物理原理的简洁、可解释推理能力，常生成冗长且不透明的解答。为此，研究者提出PhySense基准测试，评估LLMs在物理问题中的原理优先推理能力。测试显示，即使最先进的LLMs也难以像专家一样运用核心原理高效解题。这一差距凸显了LLMs在科学推理中的关键局限，为开发更高效、稳健且可解释的AI系统提供了改进方向。研究强调，未来需增强模型对基础原理的掌握与应用能力。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-02T14:02:21Z
- **目录日期**: 2025-06-02
