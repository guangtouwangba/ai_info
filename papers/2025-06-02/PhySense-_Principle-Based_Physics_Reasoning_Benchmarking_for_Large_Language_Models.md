# PhySense: Principle-Based Physics Reasoning Benchmarking for Large Language Models

**URL**: http://arxiv.org/abs/2505.24823v1

## 原始摘要

Large language models (LLMs) have rapidly advanced and are increasingly
capable of tackling complex scientific problems, including those in physics.
Despite this progress, current LLMs often fail to emulate the concise,
principle-based reasoning characteristic of human experts, instead generating
lengthy and opaque solutions. This discrepancy highlights a crucial gap in
their ability to apply core physical principles for efficient and interpretable
problem solving. To systematically investigate this limitation, we introduce
PhySense, a novel principle-based physics reasoning benchmark designed to be
easily solvable by experts using guiding principles, yet deceptively difficult
for LLMs without principle-first reasoning. Our evaluation across multiple
state-of-the-art LLMs and prompt types reveals a consistent failure to align
with expert-like reasoning paths, providing insights for developing AI systems
with efficient, robust and interpretable principle-based scientific reasoning.


## AI 摘要

当前大语言模型(LLMs)虽能处理复杂物理问题，但常缺乏人类专家基于原理的简洁推理能力，产生冗长不透明的解决方案。为系统研究这一局限，研究者开发了PhySense基准测试——人类专家可轻松用原理解决，但LLMs若不以原理优先则难以应对。评估显示，现有先进LLMs均无法实现专家级推理路径。该研究为开发具有高效、稳健且可解释的科学推理AI系统提供了新见解，突显了LLMs在运用核心物理原理进行有效推理方面的关键不足。(99字)

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-02T04:08:11Z
- **目录日期**: 2025-06-02
