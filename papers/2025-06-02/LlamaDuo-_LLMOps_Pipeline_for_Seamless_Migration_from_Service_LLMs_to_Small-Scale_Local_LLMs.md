# LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs

**URL**: http://arxiv.org/abs/2408.13467v3

## 原始摘要

The widespread adoption of cloud-based proprietary large language models
(LLMs) has introduced significant challenges, including operational
dependencies, privacy concerns, and the necessity of continuous internet
connectivity. In this work, we introduce an LLMOps pipeline, "LlamaDuo", for
the seamless migration of knowledge and abilities from service-oriented LLMs to
smaller, locally manageable models. This pipeline is crucial for ensuring
service continuity in the presence of operational failures, strict privacy
policies, or offline requirements. Our LlamaDuo involves fine-tuning a small
language model against the service LLM using a synthetic dataset generated by
the latter. If the performance of the fine-tuned model falls short of
expectations, it is automatically improved through additional fine-tuning using
extra similar data generated by the service LLM. This multi-turn process
guarantees that the smaller model can eventually match or even surpass the
service LLM's capabilities in specific downstream tasks, offering a practical
and scalable solution for managing AI deployments in constrained environments.
Extensive experiments with leading-edge LLMs are conducted to demonstrate the
effectiveness, adaptability, and affordability of LlamaDuo across various
downstream tasks. Our pipeline implementation is available at
https://github.com/deep-diver/llamaduo.


## AI 摘要

本文提出了一种名为"LlamaDuo"的LLMOps管道，旨在将云端大型语言模型(LLMs)的知识和能力迁移到本地可管理的小型模型上。该方案通过使用服务型LLM生成的合成数据对小型模型进行微调，若效果不佳则自动追加相似数据进行多轮优化，最终使小型模型能在特定下游任务中达到或超越原服务型LLM的性能。LlamaDuo解决了云服务依赖、隐私问题和离线需求等挑战，为受限环境中的AI部署提供了实用且可扩展的解决方案。实验证明该方法具有高效性、适应性和经济性优势。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-02T15:02:45Z
- **目录日期**: 2025-06-02
