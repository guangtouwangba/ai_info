# Challenging Vision-Language Models with Surgical Data: A New Dataset and Broad Benchmarking Study

**URL**: http://arxiv.org/abs/2506.06232v1

## 原始摘要

While traditional computer vision models have historically struggled to
generalize to endoscopic domains, the emergence of foundation models has shown
promising cross-domain performance. In this work, we present the first
large-scale study assessing the capabilities of Vision Language Models (VLMs)
for endoscopic tasks with a specific focus on laparoscopic surgery. Using a
diverse set of state-of-the-art models, multiple surgical datasets, and
extensive human reference annotations, we address three key research questions:
(1) Can current VLMs solve basic perception tasks on surgical images? (2) Can
they handle advanced frame-based endoscopic scene understanding tasks? and (3)
How do specialized medical VLMs compare to generalist models in this context?
Our results reveal that VLMs can effectively perform basic surgical perception
tasks, such as object counting and localization, with performance levels
comparable to general domain tasks. However, their performance deteriorates
significantly when the tasks require medical knowledge. Notably, we find that
specialized medical VLMs currently underperform compared to generalist models
across both basic and advanced surgical tasks, suggesting that they are not yet
optimized for the complexity of surgical environments. These findings highlight
the need for further advancements to enable VLMs to handle the unique
challenges posed by surgery. Overall, our work provides important insights for
the development of next-generation endoscopic AI systems and identifies key
areas for improvement in medical visual language models.


## AI 摘要

本研究评估了视觉语言模型(VLM)在内窥镜手术任务中的表现，重点关注腹腔镜手术。通过多组先进模型、手术数据集和人工标注，探讨了三个核心问题：(1)VLM能否完成基本手术感知任务；(2)能否处理高级内窥镜场景理解；(3)专业医疗VLM与通用模型的对比。结果显示，VLM在对象计数和定位等基础任务表现良好，但涉及医学知识时性能显著下降。值得注意的是，当前专业医疗VLM在各类手术任务中均逊于通用模型，表明其尚未适应手术环境的复杂性。研究为下一代内窥镜AI系统开发提供了重要方向。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-09T02:34:51Z
- **目录日期**: 2025-06-09
