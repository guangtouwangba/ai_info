# Visual Graph Arena: Evaluating Visual Conceptualization of Vision and Multimodal Large Language Models

**URL**: http://arxiv.org/abs/2506.06242v1

## 原始摘要

Recent advancements in multimodal large language models have driven
breakthroughs in visual question answering. Yet, a critical gap persists,
`conceptualization'-the ability to recognize and reason about the same concept
despite variations in visual form, a basic ability of human reasoning. To
address this challenge, we introduce the Visual Graph Arena (VGA), a dataset
featuring six graph-based tasks designed to evaluate and improve AI systems'
capacity for visual abstraction. VGA uses diverse graph layouts (e.g.,
Kamada-Kawai vs. planar) to test reasoning independent of visual form.
Experiments with state-of-the-art vision models and multimodal LLMs reveal a
striking divide: humans achieved near-perfect accuracy across tasks, while
models totally failed on isomorphism detection and showed limited success in
path/cycle tasks. We further identify behavioral anomalies suggesting
pseudo-intelligent pattern matching rather than genuine understanding. These
findings underscore fundamental limitations in current AI models for visual
understanding. By isolating the challenge of representation-invariant
reasoning, the VGA provides a framework to drive progress toward human-like
conceptualization in AI visual models. The Visual Graph Arena is available at:
\href{https://vga.csail.mit.edu/}{vga.csail.mit.edu}


## AI 摘要

近期研究提出了视觉图竞技场（VGA）数据集，用于评估AI系统的视觉抽象能力。VGA包含6个基于图的任务，通过不同布局测试模型对概念的泛化理解。实验发现人类表现近乎完美，而当前最先进的视觉模型和多模态大语言模型在图形同构检测上完全失败，路径/循环任务表现也有限，表明其依赖模式匹配而非真正理解。该研究揭示了现有AI在视觉概念化方面的根本局限。VGA为推进AI实现类人视觉推理提供了基准框架。数据集已公开：vga.csail.mit.edu。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-09T21:01:17Z
- **目录日期**: 2025-06-09
