# Visual Graph Arena: Evaluating Visual Conceptualization of Vision and Multimodal Large Language Models

**URL**: http://arxiv.org/abs/2506.06242v1

## 原始摘要

Recent advancements in multimodal large language models have driven
breakthroughs in visual question answering. Yet, a critical gap persists,
`conceptualization'-the ability to recognize and reason about the same concept
despite variations in visual form, a basic ability of human reasoning. To
address this challenge, we introduce the Visual Graph Arena (VGA), a dataset
featuring six graph-based tasks designed to evaluate and improve AI systems'
capacity for visual abstraction. VGA uses diverse graph layouts (e.g.,
Kamada-Kawai vs. planar) to test reasoning independent of visual form.
Experiments with state-of-the-art vision models and multimodal LLMs reveal a
striking divide: humans achieved near-perfect accuracy across tasks, while
models totally failed on isomorphism detection and showed limited success in
path/cycle tasks. We further identify behavioral anomalies suggesting
pseudo-intelligent pattern matching rather than genuine understanding. These
findings underscore fundamental limitations in current AI models for visual
understanding. By isolating the challenge of representation-invariant
reasoning, the VGA provides a framework to drive progress toward human-like
conceptualization in AI visual models. The Visual Graph Arena is available at:
\href{https://vga.csail.mit.edu/}{vga.csail.mit.edu}


## AI 摘要

多模态大语言模型在视觉问答方面取得突破，但AI系统仍缺乏人类"概念化"能力——即识别不同视觉形式下相同概念并进行推理的能力。为此，研究者提出了视觉图竞技场(VGA)数据集，包含6项基于图的任务，用于评估AI的视觉抽象能力。实验显示：人类任务准确率接近完美，而顶尖视觉模型和多模态大模型在图同构检测上完全失败，在路径/环任务上表现有限，表明当前AI仅具备伪智能模式匹配而非真正理解。VGA为提升AI视觉概念化能力提供了评估框架。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-09T10:01:07Z
- **目录日期**: 2025-06-09
