# Visual Graph Arena: Evaluating Visual Conceptualization of Vision and Multimodal Large Language Models

**URL**: http://arxiv.org/abs/2506.06242v1

## 原始摘要

Recent advancements in multimodal large language models have driven
breakthroughs in visual question answering. Yet, a critical gap persists,
`conceptualization'-the ability to recognize and reason about the same concept
despite variations in visual form, a basic ability of human reasoning. To
address this challenge, we introduce the Visual Graph Arena (VGA), a dataset
featuring six graph-based tasks designed to evaluate and improve AI systems'
capacity for visual abstraction. VGA uses diverse graph layouts (e.g.,
Kamada-Kawai vs. planar) to test reasoning independent of visual form.
Experiments with state-of-the-art vision models and multimodal LLMs reveal a
striking divide: humans achieved near-perfect accuracy across tasks, while
models totally failed on isomorphism detection and showed limited success in
path/cycle tasks. We further identify behavioral anomalies suggesting
pseudo-intelligent pattern matching rather than genuine understanding. These
findings underscore fundamental limitations in current AI models for visual
understanding. By isolating the challenge of representation-invariant
reasoning, the VGA provides a framework to drive progress toward human-like
conceptualization in AI visual models. The Visual Graph Arena is available at:
\href{https://vga.csail.mit.edu/}{vga.csail.mit.edu}


## AI 摘要

该研究介绍了视觉图竞技场（VGA）数据集，包含六个基于图的任务，旨在评估AI系统在视觉抽象概念化方面的能力。VGA通过不同图形布局（如Kamada-Kawai与平面图）测试模型对视觉形式变化的独立推理能力。实验发现，人类在任务中表现近乎完美，而先进视觉模型和多模态大语言模型在图同构检测上完全失败，路径/循环任务也表现有限，表明当前AI仅进行伪智能模式匹配而非真正理解。VGA为推进AI视觉模型实现人类级概念化提供了基准框架。数据集地址：vga.csail.mit.edu

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-09T23:01:13Z
- **目录日期**: 2025-06-09
