# Superhuman Game AI Disclosure: Expertise and Context Moderate Effects on Trust and Fairness

**URL**: http://arxiv.org/abs/2503.15514v2

## 原始摘要

As artificial intelligence surpasses human performance in select tasks,
disclosing superhuman capabilities poses distinct challenges for fairness,
accountability, and trust. However, the impact of such disclosures on diverse
user attitudes and behaviors remains unclear, particularly concerning potential
negative reactions like discouragement or overreliance. This paper investigates
these effects by utilizing Persona Cards: a validated, standardized set of
synthetic personas designed to simulate diverse user reactions and fairness
perspectives. We conducted an ethics board-approved study (N=32), utilizing
these personas to investigate how capability disclosure influenced behaviors
with a superhuman game AI in competitive StarCraft II scenarios. Our results
reveal transparency is double-edged: while disclosure could alleviate
suspicion, it also provoked frustration and strategic defeatism among novices
in cooperative scenarios, as well as overreliance in competitive contexts.
Experienced and competitive players interpreted disclosure as confirmation of
an unbeatable opponent, shifting to suboptimal goals. We release the Persona
Cards Dataset, including profiles, prompts, interaction logs, and protocols, to
foster reproducible research into human alignment AI design. This work
demonstrates that transparency is not a cure-all; successfully leveraging
disclosure to enhance trust and accountability requires careful tailoring to
user characteristics, domain norms, and specific fairness objectives.


## AI 摘要

研究发现，AI在特定任务中展示超人类能力时，透明度是一把双刃剑。通过《角色卡片》模拟多样化用户反应的研究(N=32)显示：披露AI超强能力虽能减少怀疑，但会引发新手在合作场景中的挫败感与"战略性失败主义"，以及在竞争场景中的过度依赖。经验玩家则会将披露视为"不可战胜对手"的确认，转而追求次优目标。研究表明，透明度并非万能方案，要有效利用披露来增强信任与问责，必须根据用户特征、领域规范和公平目标进行精心设计。相关数据集已公开以促进可重复研究。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-08T15:03:04Z
- **目录日期**: 2025-04-08
