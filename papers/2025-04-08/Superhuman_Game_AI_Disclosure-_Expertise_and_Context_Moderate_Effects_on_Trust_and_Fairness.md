# Superhuman Game AI Disclosure: Expertise and Context Moderate Effects on Trust and Fairness

**URL**: http://arxiv.org/abs/2503.15514v2

## 原始摘要

As artificial intelligence surpasses human performance in select tasks,
disclosing superhuman capabilities poses distinct challenges for fairness,
accountability, and trust. However, the impact of such disclosures on diverse
user attitudes and behaviors remains unclear, particularly concerning potential
negative reactions like discouragement or overreliance. This paper investigates
these effects by utilizing Persona Cards: a validated, standardized set of
synthetic personas designed to simulate diverse user reactions and fairness
perspectives. We conducted an ethics board-approved study (N=32), utilizing
these personas to investigate how capability disclosure influenced behaviors
with a superhuman game AI in competitive StarCraft II scenarios. Our results
reveal transparency is double-edged: while disclosure could alleviate
suspicion, it also provoked frustration and strategic defeatism among novices
in cooperative scenarios, as well as overreliance in competitive contexts.
Experienced and competitive players interpreted disclosure as confirmation of
an unbeatable opponent, shifting to suboptimal goals. We release the Persona
Cards Dataset, including profiles, prompts, interaction logs, and protocols, to
foster reproducible research into human alignment AI design. This work
demonstrates that transparency is not a cure-all; successfully leveraging
disclosure to enhance trust and accountability requires careful tailoring to
user characteristics, domain norms, and specific fairness objectives.


## AI 摘要

当AI在特定任务中超越人类时，披露其超能力会带来公平性、问责制和信任方面的挑战。研究表明，透明度具有双重影响：虽然能减少怀疑，但也可能引发新手在合作场景中的挫败感与"战略失败主义"，或导致竞争环境中的过度依赖。经验丰富的玩家则可能将披露视为对手不可战胜的证明，转而追求次优目标。这项研究强调，透明度并非万能药，需根据用户特征、领域规范和具体公平目标进行针对性设计。研究人员发布了包含用户画像和交互数据的"角色卡片数据集"，以促进可重复的人机对齐研究。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-08T17:02:52Z
- **目录日期**: 2025-04-08
