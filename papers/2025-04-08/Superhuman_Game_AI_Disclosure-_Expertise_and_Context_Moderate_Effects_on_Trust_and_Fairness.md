# Superhuman Game AI Disclosure: Expertise and Context Moderate Effects on Trust and Fairness

**URL**: http://arxiv.org/abs/2503.15514v2

## 原始摘要

As artificial intelligence surpasses human performance in select tasks,
disclosing superhuman capabilities poses distinct challenges for fairness,
accountability, and trust. However, the impact of such disclosures on diverse
user attitudes and behaviors remains unclear, particularly concerning potential
negative reactions like discouragement or overreliance. This paper investigates
these effects by utilizing Persona Cards: a validated, standardized set of
synthetic personas designed to simulate diverse user reactions and fairness
perspectives. We conducted an ethics board-approved study (N=32), utilizing
these personas to investigate how capability disclosure influenced behaviors
with a superhuman game AI in competitive StarCraft II scenarios. Our results
reveal transparency is double-edged: while disclosure could alleviate
suspicion, it also provoked frustration and strategic defeatism among novices
in cooperative scenarios, as well as overreliance in competitive contexts.
Experienced and competitive players interpreted disclosure as confirmation of
an unbeatable opponent, shifting to suboptimal goals. We release the Persona
Cards Dataset, including profiles, prompts, interaction logs, and protocols, to
foster reproducible research into human alignment AI design. This work
demonstrates that transparency is not a cure-all; successfully leveraging
disclosure to enhance trust and accountability requires careful tailoring to
user characteristics, domain norms, and specific fairness objectives.


## AI 摘要

研究表明，AI在特定任务中展示超人类能力时，透明度是一把双刃剑。通过《角色卡片》模拟实验发现，披露AI超强能力虽能减少怀疑，但新手在合作场景中易产生挫败感，竞争场景则导致过度依赖；经验玩家会认定对手不可战胜而降低目标。研究强调，透明度并非万能，需结合用户特征、领域规范和公平目标来设计披露策略。相关数据集已公开以促进可重复研究。该成果发表于《ACM公平、问责与透明会议》，突显AI能力披露需谨慎权衡信任与负面效应。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-08T06:02:48Z
- **目录日期**: 2025-04-08
