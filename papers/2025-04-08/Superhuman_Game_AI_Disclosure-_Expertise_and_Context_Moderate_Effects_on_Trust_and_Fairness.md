# Superhuman Game AI Disclosure: Expertise and Context Moderate Effects on Trust and Fairness

**URL**: http://arxiv.org/abs/2503.15514v2

## 原始摘要

As artificial intelligence surpasses human performance in select tasks,
disclosing superhuman capabilities poses distinct challenges for fairness,
accountability, and trust. However, the impact of such disclosures on diverse
user attitudes and behaviors remains unclear, particularly concerning potential
negative reactions like discouragement or overreliance. This paper investigates
these effects by utilizing Persona Cards: a validated, standardized set of
synthetic personas designed to simulate diverse user reactions and fairness
perspectives. We conducted an ethics board-approved study (N=32), utilizing
these personas to investigate how capability disclosure influenced behaviors
with a superhuman game AI in competitive StarCraft II scenarios. Our results
reveal transparency is double-edged: while disclosure could alleviate
suspicion, it also provoked frustration and strategic defeatism among novices
in cooperative scenarios, as well as overreliance in competitive contexts.
Experienced and competitive players interpreted disclosure as confirmation of
an unbeatable opponent, shifting to suboptimal goals. We release the Persona
Cards Dataset, including profiles, prompts, interaction logs, and protocols, to
foster reproducible research into human alignment AI design. This work
demonstrates that transparency is not a cure-all; successfully leveraging
disclosure to enhance trust and accountability requires careful tailoring to
user characteristics, domain norms, and specific fairness objectives.


## AI 摘要

研究表明，AI超强能力披露对用户态度和行为具有双重影响。通过《角色卡片》模拟工具和《星际争霸II》实验（N=32）发现：透明度虽能减少怀疑，但新手在合作中易产生挫败感，竞争中则过度依赖AI；而老手会将披露视为对手不可战胜的证明，转而追求次优目标。研究强调透明度并非万能，需结合用户特征、领域规范和公平目标进行定制。相关数据集已公开以促进可重复研究。该成果揭示了AI能力披露需谨慎设计，才能有效提升信任与责任。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-08T18:02:55Z
- **目录日期**: 2025-04-08
