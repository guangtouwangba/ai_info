# LLM-based Automated Grading with Human-in-the-Loop

**URL**: http://arxiv.org/abs/2504.05239v1

## 原始摘要

The rise of artificial intelligence (AI) technologies, particularly large
language models (LLMs), has brought significant advancements to the field of
education. Among various applications, automatic short answer grading (ASAG),
which focuses on evaluating open-ended textual responses, has seen remarkable
progress with the introduction of LLMs. These models not only enhance grading
performance compared to traditional ASAG approaches but also move beyond simple
comparisons with predefined "golden" answers, enabling more sophisticated
grading scenarios, such as rubric-based evaluation. However, existing
LLM-powered methods still face challenges in achieving human-level grading
performance in rubric-based assessments due to their reliance on fully
automated approaches. In this work, we explore the potential of LLMs in ASAG
tasks by leveraging their interactive capabilities through a human-in-the-loop
(HITL) approach. Our proposed framework, GradeHITL, utilizes the generative
properties of LLMs to pose questions to human experts, incorporating their
insights to refine grading rubrics dynamically. This adaptive process
significantly improves grading accuracy, outperforming existing methods and
bringing ASAG closer to human-level evaluation.


## AI 摘要

大型语言模型（LLMs）在教育领域的自动简答题评分（ASAG）中展现出显著优势，超越传统方法并支持基于量规的评估。然而，完全自动化的LLM方法在量规评估中仍难以达到人类水平。为此，研究提出GradeHITL框架，通过人机协同（HITL）方式，利用LLMs的生成能力向专家提问，动态优化评分量规。这种交互式方法显著提升了评分准确性，优于现有技术，使ASAG更接近人类评估水平。研究凸显了LLMs结合人类专业知识的潜力，为教育评估提供了新思路。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-08T08:02:03Z
- **目录日期**: 2025-04-08
