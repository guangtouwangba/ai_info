# Bonsai: Interpretable Tree-Adaptive Grounded Reasoning

**URL**: http://arxiv.org/abs/2504.03640v1

## 原始摘要

To develop general-purpose collaborative agents, humans need reliable AI
systems that can (1) adapt to new domains and (2) transparently reason with
uncertainty to allow for verification and correction. Black-box models
demonstrate powerful data processing abilities but do not satisfy these
criteria due to their opaqueness, domain specificity, and lack of uncertainty
awareness. We introduce Bonsai, a compositional and probabilistic reasoning
system that generates adaptable inference trees by retrieving relevant
grounding evidence and using it to compute likelihoods of sub-claims derived
from broader natural language inferences. Bonsai's reasoning power is tunable
at test-time via evidence scaling and it demonstrates reliable handling of
varied domains including transcripts, photographs, videos, audio, and
databases. Question-answering and human alignment experiments demonstrate that
Bonsai matches the performance of domain-specific black-box methods while
generating interpretable, grounded, and uncertainty-aware reasoning traces.


## AI 摘要

研究人员开发了名为Bonsai的可组合概率推理系统，旨在解决黑箱模型在适应性和透明度方面的不足。Bonsai通过检索相关证据并计算子主张的似然度，生成可调整的推理树，支持多模态数据处理（文本、图像、视频、音频等）。该系统具有三大优势：(1)通过证据缩放实现推理能力动态调节；(2)提供可解释的推理过程；(3)具备不确定性感知能力。实验表明，Bonsai在问答任务中性能媲美专业黑箱模型，同时能生成基于证据、可验证的推理轨迹，显著提升了AI系统的可靠性和人机协作潜力。（100字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-08T00:01:11Z
- **目录日期**: 2025-04-08
