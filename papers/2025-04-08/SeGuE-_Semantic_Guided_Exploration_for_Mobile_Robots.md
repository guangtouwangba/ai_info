# SeGuE: Semantic Guided Exploration for Mobile Robots

**URL**: http://arxiv.org/abs/2504.03629v1

## 原始摘要

The rise of embodied AI applications has enabled robots to perform complex
tasks which require a sophisticated understanding of their environment. To
enable successful robot operation in such settings, maps must be constructed so
that they include semantic information, in addition to geometric information.
In this paper, we address the novel problem of semantic exploration, whereby a
mobile robot must autonomously explore an environment to fully map both its
structure and the semantic appearance of features. We develop a method based on
next-best-view exploration, where potential poses are scored based on the
semantic features visible from that pose. We explore two alternative methods
for sampling potential views and demonstrate the effectiveness of our framework
in both simulation and physical experiments. Automatic creation of high-quality
semantic maps can enable robots to better understand and interact with their
environments and enable future embodied AI applications to be more easily
deployed.


## AI 摘要

本文提出了一种基于语义探索的机器人自主建图方法，使机器人不仅能构建环境几何结构，还能识别语义特征。研究者采用"最佳下一视点"策略，根据视角下可见的语义特征对候选位姿进行评分，并比较了两种视图采样方法。通过仿真和实物实验验证，该框架能高效创建高质量语义地图，有助于机器人更好地理解环境并执行交互任务，为具身AI应用的实际部署提供了支持。这一技术解决了传统建图缺乏语义信息的问题，推动了机器人在复杂环境中的智能化发展。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-08T01:28:37Z
- **目录日期**: 2025-04-08
