# The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support

**URL**: http://arxiv.org/abs/2401.14362v3

## 原始摘要

People experiencing severe distress increasingly use Large Language Model
(LLM) chatbots as mental health support tools. Discussions on social media have
described how engagements were lifesaving for some, but evidence suggests that
general-purpose LLM chatbots also have notable risks that could endanger the
welfare of users if not designed responsibly. In this study, we investigate the
lived experiences of people who have used LLM chatbots for mental health
support. We build on interviews with 21 individuals from globally diverse
backgrounds to analyze how users create unique support roles for their
chatbots, fill in gaps in everyday care, and navigate associated cultural
limitations when seeking support from chatbots. We ground our analysis in
psychotherapy literature around effective support, and introduce the concept of
therapeutic alignment, or aligning AI with therapeutic values for mental health
contexts. Our study offers recommendations for how designers can approach the
ethical and effective use of LLM chatbots and other AI mental health support
tools in mental health care.


## AI 摘要

越来越多处于严重心理困扰的人使用大语言模型（LLM）聊天机器人作为心理健康支持工具。社交媒体讨论显示，这类互动对部分用户具有挽救生命的作用，但证据表明通用型LLM聊天机器人若设计不当也可能带来重大风险。本研究通过访谈21位全球多元背景的用户，分析他们如何为聊天机器人创造独特支持角色、填补日常护理缺口，并在寻求支持时应对文化限制。基于心理治疗文献，研究提出"治疗性对齐"概念——使AI与心理健康治疗价值观保持一致，并为设计者提供伦理有效运用AI心理支持工具的建议。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-12T07:02:28Z
- **目录日期**: 2025-05-12
