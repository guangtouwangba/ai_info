# The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support

**URL**: http://arxiv.org/abs/2401.14362v3

## 原始摘要

People experiencing severe distress increasingly use Large Language Model
(LLM) chatbots as mental health support tools. Discussions on social media have
described how engagements were lifesaving for some, but evidence suggests that
general-purpose LLM chatbots also have notable risks that could endanger the
welfare of users if not designed responsibly. In this study, we investigate the
lived experiences of people who have used LLM chatbots for mental health
support. We build on interviews with 21 individuals from globally diverse
backgrounds to analyze how users create unique support roles for their
chatbots, fill in gaps in everyday care, and navigate associated cultural
limitations when seeking support from chatbots. We ground our analysis in
psychotherapy literature around effective support, and introduce the concept of
therapeutic alignment, or aligning AI with therapeutic values for mental health
contexts. Our study offers recommendations for how designers can approach the
ethical and effective use of LLM chatbots and other AI mental health support
tools in mental health care.


## AI 摘要

越来越多的人使用大型语言模型(LLM)聊天机器人作为心理健康支持工具。研究发现，虽然一些用户认为这种互动具有救命效果，但通用型LLM聊天机器人也存在显著风险。通过对21位来自不同文化背景的受访者访谈，研究探讨了用户如何为聊天机器人创造独特的支持角色、填补日常护理空白，以及应对文化限制。研究基于心理治疗文献提出了"治疗性对齐"概念，即让AI与心理健康治疗价值观保持一致。最后为设计者提供了关于如何道德有效地使用LLM聊天机器人等AI心理健康支持工具的建议。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-12T09:02:43Z
- **目录日期**: 2025-05-12
