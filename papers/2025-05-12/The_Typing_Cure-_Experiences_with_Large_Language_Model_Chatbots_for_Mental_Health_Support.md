# The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support

**URL**: http://arxiv.org/abs/2401.14362v3

## 原始摘要

People experiencing severe distress increasingly use Large Language Model
(LLM) chatbots as mental health support tools. Discussions on social media have
described how engagements were lifesaving for some, but evidence suggests that
general-purpose LLM chatbots also have notable risks that could endanger the
welfare of users if not designed responsibly. In this study, we investigate the
lived experiences of people who have used LLM chatbots for mental health
support. We build on interviews with 21 individuals from globally diverse
backgrounds to analyze how users create unique support roles for their
chatbots, fill in gaps in everyday care, and navigate associated cultural
limitations when seeking support from chatbots. We ground our analysis in
psychotherapy literature around effective support, and introduce the concept of
therapeutic alignment, or aligning AI with therapeutic values for mental health
contexts. Our study offers recommendations for how designers can approach the
ethical and effective use of LLM chatbots and other AI mental health support
tools in mental health care.


## AI 摘要

越来越多的人使用大型语言模型（LLM）聊天机器人作为心理健康支持工具。研究表明，尽管这类工具可能挽救生命，但也存在风险。本研究通过访谈21位来自不同背景的用户，探讨了他们如何利用聊天机器人填补日常心理支持的缺口，并应对文化局限。研究基于心理治疗理论，提出“治疗对齐”概念，即让AI与心理健康治疗价值观保持一致。最后，研究为设计者提供了伦理且有效的AI心理健康支持工具的建议。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-12T08:02:25Z
- **目录日期**: 2025-05-12
