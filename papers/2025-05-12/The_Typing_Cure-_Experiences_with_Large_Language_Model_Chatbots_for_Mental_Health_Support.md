# The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support

**URL**: http://arxiv.org/abs/2401.14362v3

## 原始摘要

People experiencing severe distress increasingly use Large Language Model
(LLM) chatbots as mental health support tools. Discussions on social media have
described how engagements were lifesaving for some, but evidence suggests that
general-purpose LLM chatbots also have notable risks that could endanger the
welfare of users if not designed responsibly. In this study, we investigate the
lived experiences of people who have used LLM chatbots for mental health
support. We build on interviews with 21 individuals from globally diverse
backgrounds to analyze how users create unique support roles for their
chatbots, fill in gaps in everyday care, and navigate associated cultural
limitations when seeking support from chatbots. We ground our analysis in
psychotherapy literature around effective support, and introduce the concept of
therapeutic alignment, or aligning AI with therapeutic values for mental health
contexts. Our study offers recommendations for how designers can approach the
ethical and effective use of LLM chatbots and other AI mental health support
tools in mental health care.


## AI 摘要

越来越多处于严重心理困扰的人使用大型语言模型（LLM）聊天机器人作为心理健康支持工具。社交媒体讨论显示，这种互动对某些人具有挽救生命的作用，但证据表明，通用LLM聊天机器人也存在显著风险，若设计不当可能危害用户福祉。本研究通过访谈21名不同文化背景的使用者，分析他们如何为聊天机器人创造独特支持角色、填补日常护理缺口，并在寻求支持时应对文化限制。基于心理治疗文献，研究提出"治疗性对齐"概念，即让人工智能与心理健康治疗价值观保持一致，并为设计伦理有效的AI心理支持工具提供建议。（100字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-12T23:02:14Z
- **目录日期**: 2025-05-12
