# The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support

**URL**: http://arxiv.org/abs/2401.14362v3

## 原始摘要

People experiencing severe distress increasingly use Large Language Model
(LLM) chatbots as mental health support tools. Discussions on social media have
described how engagements were lifesaving for some, but evidence suggests that
general-purpose LLM chatbots also have notable risks that could endanger the
welfare of users if not designed responsibly. In this study, we investigate the
lived experiences of people who have used LLM chatbots for mental health
support. We build on interviews with 21 individuals from globally diverse
backgrounds to analyze how users create unique support roles for their
chatbots, fill in gaps in everyday care, and navigate associated cultural
limitations when seeking support from chatbots. We ground our analysis in
psychotherapy literature around effective support, and introduce the concept of
therapeutic alignment, or aligning AI with therapeutic values for mental health
contexts. Our study offers recommendations for how designers can approach the
ethical and effective use of LLM chatbots and other AI mental health support
tools in mental health care.


## AI 摘要

越来越多的人使用大型语言模型（LLM）聊天机器人作为心理健康支持工具。研究发现，虽然部分用户认为这类互动具有救生作用，但通用型LLM聊天机器人也存在显著风险，可能威胁用户福祉。本研究通过访谈21位来自不同文化背景的用户，探讨了他们如何为聊天机器人创造独特的支持角色、填补日常护理缺口，并应对文化限制。基于心理治疗文献，研究提出"治疗性对齐"概念，即让人工智能与心理健康治疗价值观保持一致。最后，研究为设计者提供了关于如何伦理且有效地应用LLM聊天机器人等AI心理健康支持工具的建议。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-12T13:11:49Z
- **目录日期**: 2025-05-12
