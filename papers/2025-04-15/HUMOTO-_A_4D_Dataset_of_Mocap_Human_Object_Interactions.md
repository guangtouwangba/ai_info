# HUMOTO: A 4D Dataset of Mocap Human Object Interactions

**URL**: http://arxiv.org/abs/2504.10414v1

## 原始摘要

We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of
human-object interactions for motion generation, computer vision, and robotics
applications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO
captures interactions with 63 precisely modeled objects and 72 articulated
parts. Our innovations include a scene-driven LLM scripting pipeline creating
complete, purposeful tasks with natural progression, and a mocap-and-camera
recording setup to effectively handle occlusions. Spanning diverse activities
from cooking to outdoor picnics, HUMOTO preserves both physical accuracy and
logical task flow. Professional artists rigorously clean and verify each
sequence, minimizing foot sliding and object penetrations. We also provide
benchmarks compared to other datasets. HUMOTO's comprehensive full-body motion
and simultaneous multi-object interactions address key data-capturing
challenges and provide opportunities to advance realistic human-object
interaction modeling across research domains with practical applications in
animation, robotics, and embodied AI systems. Project:
https://jiaxin-lu.github.io/humoto/ .


## AI 摘要

HUMOTO是一个高精度的人-物交互数据集，包含736段动作序列（7,875秒30fps视频），涵盖63种精确建模的物体和72个可动部件。该数据集通过创新的场景驱动LLM脚本流程和动捕-相机混合采集系统，捕捉了从烹饪到野餐等多样活动，确保物理准确性和任务逻辑性。专业团队对每段动作进行严格清理，减少脚步滑动和物体穿透问题。HUMOTO提供了全身动作与多物体同步交互数据，解决了关键数据采集挑战，为动画、机器人和具身AI等领域的真实人-物交互建模研究提供了重要资源。项目网址见摘要。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T07:02:09Z
- **目录日期**: 2025-04-15
