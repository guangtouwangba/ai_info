# HUMOTO: A 4D Dataset of Mocap Human Object Interactions

**URL**: http://arxiv.org/abs/2504.10414v1

## 原始摘要

We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of
human-object interactions for motion generation, computer vision, and robotics
applications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO
captures interactions with 63 precisely modeled objects and 72 articulated
parts. Our innovations include a scene-driven LLM scripting pipeline creating
complete, purposeful tasks with natural progression, and a mocap-and-camera
recording setup to effectively handle occlusions. Spanning diverse activities
from cooking to outdoor picnics, HUMOTO preserves both physical accuracy and
logical task flow. Professional artists rigorously clean and verify each
sequence, minimizing foot sliding and object penetrations. We also provide
benchmarks compared to other datasets. HUMOTO's comprehensive full-body motion
and simultaneous multi-object interactions address key data-capturing
challenges and provide opportunities to advance realistic human-object
interaction modeling across research domains with practical applications in
animation, robotics, and embodied AI systems. Project:
https://jiaxin-lu.github.io/humoto/ .


## AI 摘要

HUMOTO是一个高精度的人-物交互数据集，包含736段动作序列（共7,875秒，30帧/秒），涵盖63种精确建模的物体和72个可动部件。该数据集通过创新的场景驱动LLM脚本流程生成有逻辑的任务流，并采用动捕与相机结合的系统有效处理遮挡问题。其内容覆盖烹饪、野餐等多样化活动，经专业艺术家严格清理以确保物理准确性（如减少脚滑和物体穿透）。相比现有数据集，HUMOTO以全身动作和多物体同步交互为特色，为动画、机器人和具身AI等领域提供研究基准。项目网址见摘要。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T15:02:04Z
- **目录日期**: 2025-04-15
