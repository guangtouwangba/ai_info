# HUMOTO: A 4D Dataset of Mocap Human Object Interactions

**URL**: http://arxiv.org/abs/2504.10414v1

## 原始摘要

We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of
human-object interactions for motion generation, computer vision, and robotics
applications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO
captures interactions with 63 precisely modeled objects and 72 articulated
parts. Our innovations include a scene-driven LLM scripting pipeline creating
complete, purposeful tasks with natural progression, and a mocap-and-camera
recording setup to effectively handle occlusions. Spanning diverse activities
from cooking to outdoor picnics, HUMOTO preserves both physical accuracy and
logical task flow. Professional artists rigorously clean and verify each
sequence, minimizing foot sliding and object penetrations. We also provide
benchmarks compared to other datasets. HUMOTO's comprehensive full-body motion
and simultaneous multi-object interactions address key data-capturing
challenges and provide opportunities to advance realistic human-object
interaction modeling across research domains with practical applications in
animation, robotics, and embodied AI systems. Project:
https://jiaxin-lu.github.io/humoto/ .


## AI 摘要

研究人员推出了HUMOTO数据集，这是一个用于动作生成、计算机视觉和机器人应用的高保真人类-物体交互数据集。该数据集包含736个序列（7875秒，30fps），涵盖63种精确建模的物体和72个可动部件。创新点包括基于场景的LLM脚本生成完整任务流程，以及优化的动作捕捉系统处理遮挡问题。数据集覆盖烹饪、野餐等多种活动，保持物理精确性和逻辑任务流，并由专业人员清理验证。相比现有数据集，HUMOTO提供了更全面的全身动作和同步多物体交互数据，可推动动画、机器人和具身AI系统的发展。项目网址已公开。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T23:03:09Z
- **目录日期**: 2025-04-15
