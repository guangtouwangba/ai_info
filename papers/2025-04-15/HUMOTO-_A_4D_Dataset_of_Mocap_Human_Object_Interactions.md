# HUMOTO: A 4D Dataset of Mocap Human Object Interactions

**URL**: http://arxiv.org/abs/2504.10414v1

## 原始摘要

We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of
human-object interactions for motion generation, computer vision, and robotics
applications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO
captures interactions with 63 precisely modeled objects and 72 articulated
parts. Our innovations include a scene-driven LLM scripting pipeline creating
complete, purposeful tasks with natural progression, and a mocap-and-camera
recording setup to effectively handle occlusions. Spanning diverse activities
from cooking to outdoor picnics, HUMOTO preserves both physical accuracy and
logical task flow. Professional artists rigorously clean and verify each
sequence, minimizing foot sliding and object penetrations. We also provide
benchmarks compared to other datasets. HUMOTO's comprehensive full-body motion
and simultaneous multi-object interactions address key data-capturing
challenges and provide opportunities to advance realistic human-object
interaction modeling across research domains with practical applications in
animation, robotics, and embodied AI systems. Project:
https://jiaxin-lu.github.io/humoto/ .


## AI 摘要

HUMOTO是一个高保真的人-物交互数据集，包含736段序列（7875秒，30fps），涵盖63种精确建模的物体和72个可动部件。该数据集通过场景驱动的LLM脚本生成自然连贯的任务流程，并采用动捕与多相机系统有效处理遮挡问题，覆盖烹饪、野餐等多样化活动。所有序列经专业艺术家严格清理，减少脚步滑动和物体穿透问题。HUMOTO以全身动作和多物体同步交互为特色，解决了关键数据采集挑战，为动画、机器人和具身AI等领域的真实人-物交互建模提供了新机遇。项目网址见摘要。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T20:02:43Z
- **目录日期**: 2025-04-15
