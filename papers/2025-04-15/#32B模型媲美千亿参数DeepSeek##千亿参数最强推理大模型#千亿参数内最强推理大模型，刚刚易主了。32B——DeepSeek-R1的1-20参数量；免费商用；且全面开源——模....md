# #32B模型媲美千亿参数DeepSeek##千亿参数最强推理大模型#千亿参数内最强推理大模型，刚刚易主了。32B——DeepSeek-R1的1/20参数量；免费商用；且全面开源——模...

**URL**: https://weibo.com/6105753431/PnfOwD1uu

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%2332B%E6%A8%A1%E5%9E%8B%E5%AA%B2%E7%BE%8E%E5%8D%83%E4%BA%BF%E5%8F%82%E6%95%B0DeepSeek%23&amp;extparam=%2332B%E6%A8%A1%E5%9E%8B%E5%AA%B2%E7%BE%8E%E5%8D%83%E4%BA%BF%E5%8F%82%E6%95%B0DeepSeek%23" data-hide=""><span class="surl-text">#32B模型媲美千亿参数DeepSeek#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%8D%83%E4%BA%BF%E5%8F%82%E6%95%B0%E6%9C%80%E5%BC%BA%E6%8E%A8%E7%90%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E5%8D%83%E4%BA%BF%E5%8F%82%E6%95%B0%E6%9C%80%E5%BC%BA%E6%8E%A8%E7%90%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#千亿参数最强推理大模型#</span></a><br><br>千亿参数内最强推理大模型，刚刚易主了。<br><br>32B——DeepSeek-R1的1/20参数量；免费商用；且全面开源——模型权重、训练数据集和完整训练代码，都开源了。<br><br>这就是刚刚亮相的Skywork-OR1 (Open Reasoner 1)系列模型——<br><br>通用32B尺寸（Skywork-OR1-32B）完全超越同规模阿里QwQ-32B；代码生成媲美DeepSeek-R1，但性价比更高。【图1】  △Skywork-OR1-32B-Preview  <br><br>数学推理方面：7B、32B都达到同规模最优，数学专项模型（Skywork-OR1-Math-7B）表现更突出。【图2】  <br><br>Skywork，天工是也，来自AIGC巨头玩家昆仑万维。<br><br>Skywork-OR1系列模型现已全面开源，模型权重、训练数据集和完整训练代码，所有资源均已上传至GitHub和Huggingface平台。配套的技术博客已发布于Notion平台，详细阐述了数据处理流程、训练方法和关键技术发现，为社区提供了完全可复现的实践参考。<br><br>Skywork-OR1系列开源地址：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FSkyworkAI%2FSkywork-OR1" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a>&nbsp;（包含模型，代码，数据）<br><br>昆仑万维天工团队更多开源项目：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhuggingface.co%2FSkywork" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br><br>目前Skywork-OR1-7B和Skywork-OR1-32B的能力还在持续提升，在两周内会发布两个模型的正式版本，同时也会推出更为系统详尽的技术报告，分享推理模型训练中的经验与洞察。<br><br>3款模型全量开源  <br>Skywork-OR1 (Open Reasoner 1) 系列开源共有3款模型：<br><br>-Skywork-OR1-Math-7B：专注数学领域的专项模型，同时也具有较强的代码能力。  <br>-Skywork-OR1-7B-Preview：融合数学与代码能力，兼顾通用与专业性  <br>-Skywork-OR1-32B-Preview：面向高复杂度任务、具备更强推理能力的旗舰版本  <br><br>团队对比了Skywork-OR1系列在AIME24、AIME25、LiveCodeBench上的表现。<br><br>AIME24/25是美国数学邀请赛基准测试，LiveCodeBench主要评估大语言模型代码生成和编程能力。<br><br>在评测方面，Skywork-OR1系列模型引入avg<a href="https://weibo.com/n/k%E4%BD%9C%E4%B8%BA%E6%A0%B8%E5%BF%83%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87">@k作为核心评估指标</a>，用于衡量模型在进行k次尝试时成功解决问题的平均表现。<br><br>传统的pass<a href="https://weibo.com/n/k%E6%8C%87%E6%A0%87%E4%BB%85%E5%85%B3%E6%B3%A8">@k指标仅关注</a>“至少一次成功”，相对而言avg<a href="https://weibo.com/n/k%E6%9B%B4%E5%85%B3%E6%B3%A8%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%92%8C%E6%95%B4%E4%BD%93%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B">@k更关注模型的稳定性和整体推理能力</a>，为模型实际落地提供更全面真实的参考。【图3】  <br><br>在数学方面，通用模型Skywork-OR1-7B-Preview和Skywork-OR1-32B-Preview在AIME24与AIME25数据集上均实现了同参数规模下最优表现，32B整体表现基本与DeepSeek-R1齐平。<br><br>编程方面，通用模型Skywork-OR1-7B-Preview与Skywork-OR1-32B-Preview在LiveCodeBench上均取得了同等参数规模下的最优性能。<br><br>整体而言，Skywork-OR1-32B-Preview甚至与DeepSeek-R1的差距非常微小。要知道后者的参数规模是前者的20倍，这意味着Skywork-OR1能带来更具性价比的性能表现。<br><br>由此综合来看，Skywork-OR1-32B-Preview成为当前同规模最强中文推理模型，也是现役支持免费商用的模型中最强且最具性价比的成员之一。<br><br>此外，数学专项模型Skywork-OR1-Math-7B在AIME24/25的表现远超当前主流7B级模型，甚至接近蒸馏版Deepseek-32B模型同等水平（DeepSeek-R1-Distill-Qwen-32B）。<br><br>如下为该模型在AIME24上的训练准确率曲线。【图4】<br><br>最终模型在AIME24和AIME25上分别达到69.8%和52.3%，超越了OpenAI-o3-mini (low)，达到了当前尺寸SOTA性能。与此同时，该专项模型在代码领域也表现出了较好的泛化性（训练后，Livecodebench从37.6%提升到43.6%）。【图5】  △OpenAI-o3-mini(low)的AIME24分数来自官网，AIME25分数来自评测网站<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmatharena.ai%2F" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a>  <br><br>去年11月，昆仑万维发布国内首款中文复杂推理模型Skywork-o1，Skywork-OR1系列模型正是在此基础上迭代而来。<br><br>不同于简单复刻OpenAI o1模型，Skywork-o1内生出了思考、计划、反思等能力。它共包括三款模型Skywork-o1-Open、SI’m kywork-o1-Lite和Skywork-o1-Preview，分别适用于不同的应用场景，可以满足开源到高性能推理的多样化需求。<br><br>Skywork-OR1系列站在Skywork-o1的肩膀上有了更强基座，但想要如此强大，也离不开一系列先进技术加持。<br><br>背后秘诀：AGI技术洞藏，训练效率提升50%  <br>Skywork-OR1在数据处理、训练策略等方面都做了进一步创新。<br><br>首先在数据方面。<br><br>为提升模型在数学和代码方面能力，Skywork-OR1构建了一个高质量数学和代码数据集。<br><br>团队设计了三个标准进行数据筛选：可验证性（Verifiable）、正确性（Correct）与挑战性（Challenging），剔除无法自动验证的证明类题目、有误题目、和缺少unit test的代码问题。<br><br>数学领域共计收集11万道题目，主要依赖NuminaMath-1.5（含约89.6万题），选用如AIME和Olympiads等较难子集，并补充了如DeepScaleR、Omni-MATH、AIME 1983-2023难题来源。<br><br>代码领域收集了13.7k条高质量代码问题，主要以LeetCode和TACO数据为主，保留了单元测试完整、验证通过的问题，并进行向量级语义去重。<br><br>在数据过滤部分，团队对每道题进行了多轮采样并验证答案，以避免“全对”或“全错”现象对策略学习无效——模型生成全部错误，无法提供有效的学习信号；“全对”意味着模型已完全掌握，继续学习会浪费计算资源。<br><br>并通过人类审核结合LLM自动判题机制，对语义不清、信息不全、格式错误或含有无关内容的项目进行清理。使用LLM-as-a-Judge剔除掉约1-2K道质量不达标的数学题。<br><br>其次在强化学习部分，Skywork-OR1使用GRPO（Group Relative Policy Optimization）进行训练，并引入一系列优化策略。<br><br>在训练时数据优化上，一方面采用双重过滤策略：<br><br>离线过滤：训练前使用待训练模型评估数据，剔除正确率为0或1的样本；  <br>在线过滤：每个epoch动态移除上一轮已完全掌握的数据，确保模型持续面对有挑战性的内容。  <br>另一方面使用拒绝采样（Rejection Sampling）进行更精细的实时筛选，在每个训练步骤中动态剔除当前训练步中采样正确率为0或1的样本。这样可以维持policy loss、entropy loss和KL loss的合理比例，防止非policy loss比重异常增加导致的训练不稳定。<br><br>在训练Pipeline优化上主要做了两方面的探索。<br><br>（1）多阶段训练（Multi Stage Training）：从小窗口开始，逐步增加上下文长度(seq_len)，可以促使模型在有限token内高效完成任务；随后逐步扩展窗口大小，迭代增加生成长度，使模型逐渐掌握更复杂的长链思维能力。实验证明，多阶段训练能显著缩短训练时间，同时完全保持模型的长度扩展能力。<br><br>（2）截断优势掩码（Truncated Advantage Mask）：在多阶段训练初期，由于上下文窗口限制，复杂问题的回答可能被截断。因此团队研究了两种处理窗口限制下截断样本的策略Adv-Mask Before（计算优势前排除截断样本）和Adv-Mask After（计算后将截断样本优势置零）。证明即使不屏蔽截断样本，模型也能有效适应并迅速提升性能，也证明多阶段训练框架的鲁棒性。<br><br>此外，在强化学习训练中还要保障模型的探索能力。<br><br>团队进行了三方面探索。<br><br>第一，高温度采样。采用τ=1.0（高于常见的0.6）维持更高群组内多样性，既保证足够正确样本提供学习信号，又允许模型探索更广泛解决路径。<br><br>第二，提升内在训练多样性。通过精细数据过滤、增加批量大小和减少数据重复使用，可以从源头上防止模型过早优化到单一输出方向，同时也保持较高熵值，避免局部最优。<br><br>第三，自适应熵控制。只有在熵值低于阈值时才提供熵增加鼓励，设定目标熵值并动态调整损失系数，同时最小化对正常训练轨迹的干扰。<br><br>最后在保障强化学习训练的稳定性，团队对损失函数进行优化。<br><br>第一，移除KL损失。研究中发现即使基于高质量SFT模型训练，KL损失仍限制性能提升。因此，除特定阶段外，团队在所有公开发布的Skywork-OR1系列模型中均未使用KL损失项，这使模型能够更充分地探索和优化推理能力。<br><br>第二，token级策略损失。移除了策略损失中的长度归一化项，并将损失在训练批次内的所有token上进行平均，以提升优化过程的一致性与稳定性。<br><br>（更多技术细节和实验对比可以参照技术博客<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fcapricious-hydrogen-41c.notion.site%2FSkywork-Open-Reaonser-Series-1d0bc9ae823a80459b46c149e4f51680" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a>，或继续关注后续发布的技术报告。）<br><br>在此训练策略下，Skywork-OR1-7B和Skywork-OR1-32B-Preview通用推理模型仍处于持续提升状态，本次开源是当前训练过程中性能最佳的checkpoint。<br><br>预计两周后，具备更全面能力提升及更强大推理能力的Skywork-OR1正式版本将与大家见面，同样全面开源。<br><br>Hugging Face单月下载量超7万  <br>自2023年以来，在全面拥抱AIGC后，昆仑万维一直坚持开源，推动技术平权。代表性动作包括：<br><br>2023年：开源百亿级大语言模型Skywork-13B系列及600GB高质量数据集。  <br>2024年：陆续开源数字智能体研发工具包AgentStudio、4000亿参数MoE超级模型、Skywork-MoE、 Skywork-RM/PRM，Skywork-o1。  <br>今年以来，开源的频率变得更高。第一季度开源动作包括：<br><br>面向AI短剧生成的视频生成模型SkyReels-V1：下载量周榜前十  <br>R1V视觉思维链推理模型：单月下载8.75k  <br>Skywork-OR1新系列：长思维链推理模型。  <br>不难发现，昆仑万维开源全面且彻底，同时兼顾产业需求。<br><br>一方面，它的基础模型布局非常全面，覆盖AIGC全领域，文生文、文生视频、文生音乐等。<br><br>另一方面，这些模型从底层设计上即考虑了实际落地的需求。提供更高性价比、更节省算力，如SkyReels-V1则是看到了垂直领域的落地前景，模型下载量迅速增长也验证了这一市场需求。<br><br>最关键的是，这些模型的开源程度也相当彻底，十分利于开发者使用。<br><br>在Hugging Face上，昆仑万维开源模型的下载量相当可观，累计上月下载量超过7万。【图6】  △部分展示  <br><br>如今，底层模型竞争日趋白热化，全球AI领域正以惊人的速度迭代演进，几乎每个月都有值得关注的模型发布，这种创新密度前所未有。<br><br>作为国内最早All in AIGC赛道的先行者之一，昆仑万维自2023年起便构建了全方位的前沿布局：从基础大模型到垂直应用，从技术研发到生态建设。尤其值得注意的是，昆仑万维持续为开发者社区提供高质量的模型和工具链，这种坚持普惠的技术理念也为其提供了独特竞争力。<br><br>当前，开源生态正展现出前所未有的活力。<br><br>这些开源创新正快速渗透到互联网、制造业、医疗、教育等领域，推动着AI技术真正实现规模化落地。在这一进程中，以昆仑万维为代表的开源践行者的每一步探索，都将深刻影响AI产业的发展轨迹。<br><br>据说Skywork-OR1正式版，也已经快马加鞭，即将对外发布。<br><br>Skywork开源系列（2025）传送门：<br><br>1、中文推理模型Skywork-OR1：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FSkyworkAI%2FSkywork-o1" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br><br>2、视觉思维链推理模型Skywork-R1V：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FSkyworkAI%2FSkywork-R1V" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br><br>3、AI短剧生成模型SkyReels-V1：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FSkyworkAI%2FSkyReels-V1" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1i0gl4ebqs8j30u00gln3e.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1i0gl4fd7pej30u00gw79u.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1i0gl4gxdbrj30u00dgajl.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3ly1i0gl4fu1zvj30u00hon20.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3ly1i0gl4dbvyfj30u00gm0vp.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3ly1i0gl4ha76pj30u00pm114.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

昆仑万维旗下天工团队推出Skywork-OR1系列开源大模型，其中32B参数版本（Skywork-OR1-32B）以仅1/20的参数量媲美千亿级DeepSeek-R1的推理能力，成为当前同规模最强中文开源模型。该系列包含3款模型：通用7B/32B版本及专注数学的7B专项模型，在AIME数学竞赛和LiveCodeBench代码测试中均达SOTA水平。关键技术包括GRPO强化学习、多阶段训练和高质量数据筛选，训练效率提升50%。所有模型权重、数据集和代码均开源，支持免费商用，Hugging Face月下载量超7万次。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T06:03:55Z
- **目录日期**: 2025-04-15
