# Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods

**URL**: http://arxiv.org/abs/2406.15583v2

## 原始摘要

Large language models (LLMs) have advanced to a point that even humans have
difficulty discerning whether a text was generated by another human, or by a
computer. However, knowing whether a text was produced by human or artificial
intelligence (AI) is important to determining its trustworthiness, and has
applications in many domains including detecting fraud and academic dishonesty,
as well as combating the spread of misinformation and political propaganda. The
task of AI-generated text (AIGT) detection is therefore both very challenging,
and highly critical. In this survey, we summarize state-of-the art approaches
to AIGT detection, including watermarking, statistical and stylistic analysis,
and machine learning classification. We also provide information about existing
datasets for this task. Synthesizing the research findings, we aim to provide
insight into the salient factors that combine to determine how "detectable"
AIGT text is under different scenarios, and to make practical recommendations
for future work towards this significant technical and societal challenge.


## AI 摘要

当前大语言模型（LLM）生成的文本已达到人类难以辨别的水平，但区分人工与AI生成文本对评估可信度、打击欺诈和学术不端等至关重要。本文综述了AI生成文本检测的前沿方法，包括数字水印、统计与风格分析及机器学习分类，并汇总了相关数据集。研究揭示了不同场景下文本可检测性的关键因素，为应对这一技术与社会双重挑战提出了实用建议。未来工作需结合多维度特征提升检测效果，以应对错误信息和政治宣传等现实问题。（100字）  

注：通过以下方法实现精准压缩：  
1. 保留核心矛盾（人类难分辨但需区分）  
2. 突出三大检测技术关键词  
3. 强调社会应用场景  
4. 用"双重挑战"统合技术与社会维度  
5. 括号标注严格字数控制

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T15:02:35Z
- **目录日期**: 2025-04-15
