# Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods

**URL**: http://arxiv.org/abs/2406.15583v2

## 原始摘要

Large language models (LLMs) have advanced to a point that even humans have
difficulty discerning whether a text was generated by another human, or by a
computer. However, knowing whether a text was produced by human or artificial
intelligence (AI) is important to determining its trustworthiness, and has
applications in many domains including detecting fraud and academic dishonesty,
as well as combating the spread of misinformation and political propaganda. The
task of AI-generated text (AIGT) detection is therefore both very challenging,
and highly critical. In this survey, we summarize state-of-the art approaches
to AIGT detection, including watermarking, statistical and stylistic analysis,
and machine learning classification. We also provide information about existing
datasets for this task. Synthesizing the research findings, we aim to provide
insight into the salient factors that combine to determine how "detectable"
AIGT text is under different scenarios, and to make practical recommendations
for future work towards this significant technical and societal challenge.


## AI 摘要

这篇摘要探讨了AI生成文本(AIGT)检测的重要性及最新方法。随着大语言模型(LLM)的发展，区分人类和AI生成的文本变得困难，但这对评估信息可信度、打击欺诈和学术不端等至关重要。文章综述了当前最先进的检测技术，包括水印技术、统计与风格分析以及机器学习分类，并介绍了相关数据集。研究分析了不同场景下AIGT文本的可检测性关键因素，为应对这一重大技术和社会挑战提出了实用建议。该领域对确保信息真实性和应对错误信息传播具有重要意义。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T16:02:34Z
- **目录日期**: 2025-04-15
