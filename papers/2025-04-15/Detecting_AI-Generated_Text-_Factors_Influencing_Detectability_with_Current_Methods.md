# Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods

**URL**: http://arxiv.org/abs/2406.15583v2

## 原始摘要

Large language models (LLMs) have advanced to a point that even humans have
difficulty discerning whether a text was generated by another human, or by a
computer. However, knowing whether a text was produced by human or artificial
intelligence (AI) is important to determining its trustworthiness, and has
applications in many domains including detecting fraud and academic dishonesty,
as well as combating the spread of misinformation and political propaganda. The
task of AI-generated text (AIGT) detection is therefore both very challenging,
and highly critical. In this survey, we summarize state-of-the art approaches
to AIGT detection, including watermarking, statistical and stylistic analysis,
and machine learning classification. We also provide information about existing
datasets for this task. Synthesizing the research findings, we aim to provide
insight into the salient factors that combine to determine how "detectable"
AIGT text is under different scenarios, and to make practical recommendations
for future work towards this significant technical and societal challenge.


## AI 摘要

当前大型语言模型（LLM）生成的文本已高度拟人化，使得区分人工与AI生成文本（AIGT）成为重要挑战。AIGT检测对确保信息可信度至关重要，涉及学术诚信、反欺诈和打击虚假信息等领域。现有方法包括数字水印、统计风格分析和机器学习分类，并已建立相关数据集。研究综合表明，AIGT的可检测性取决于多种因素，需针对不同场景优化方案。未来工作应继续探索技术与社会需求相结合的解决方案，以应对这一兼具技术难度和社会影响的重大课题。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T08:02:38Z
- **目录日期**: 2025-04-15
