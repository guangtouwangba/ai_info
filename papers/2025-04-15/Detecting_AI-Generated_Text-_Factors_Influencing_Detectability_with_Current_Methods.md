# Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods

**URL**: http://arxiv.org/abs/2406.15583v2

## 原始摘要

Large language models (LLMs) have advanced to a point that even humans have
difficulty discerning whether a text was generated by another human, or by a
computer. However, knowing whether a text was produced by human or artificial
intelligence (AI) is important to determining its trustworthiness, and has
applications in many domains including detecting fraud and academic dishonesty,
as well as combating the spread of misinformation and political propaganda. The
task of AI-generated text (AIGT) detection is therefore both very challenging,
and highly critical. In this survey, we summarize state-of-the art approaches
to AIGT detection, including watermarking, statistical and stylistic analysis,
and machine learning classification. We also provide information about existing
datasets for this task. Synthesizing the research findings, we aim to provide
insight into the salient factors that combine to determine how "detectable"
AIGT text is under different scenarios, and to make practical recommendations
for future work towards this significant technical and societal challenge.


## AI 摘要

当前大语言模型(LLM)生成的文本已达到人类难辨真伪的程度，这使得AI生成文本检测(AIGT)成为关键挑战。该领域主要采用水印技术、统计风格分析和机器学习分类等方法，并已建立相关数据集。研究重点在于分析不同场景下文本的可检测性特征，为应对这一技术与社会双重挑战提供实践建议。该技术对识别欺诈、学术不端和虚假信息传播具有重要意义。未来工作需要综合考量多方面因素，以提升检测效果。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T22:03:00Z
- **目录日期**: 2025-04-15
