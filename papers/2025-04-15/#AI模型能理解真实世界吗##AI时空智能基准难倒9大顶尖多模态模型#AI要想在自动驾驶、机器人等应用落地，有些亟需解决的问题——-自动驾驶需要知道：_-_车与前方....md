# #AI模型能理解真实世界吗##AI时空智能基准难倒9大顶尖多模态模型#AI要想在自动驾驶、机器人等应用落地，有些亟需解决的问题——-自动驾驶需要知道： - 车与前方...

**URL**: https://weibo.com/6105753431/Pnnrbt5K0

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23AI%E6%A8%A1%E5%9E%8B%E8%83%BD%E7%90%86%E8%A7%A3%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E5%90%97%23&amp;extparam=%23AI%E6%A8%A1%E5%9E%8B%E8%83%BD%E7%90%86%E8%A7%A3%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E5%90%97%23" data-hide=""><span class="surl-text">#AI模型能理解真实世界吗#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23AI%E6%97%B6%E7%A9%BA%E6%99%BA%E8%83%BD%E5%9F%BA%E5%87%86%E9%9A%BE%E5%80%929%E5%A4%A7%E9%A1%B6%E5%B0%96%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23AI%E6%97%B6%E7%A9%BA%E6%99%BA%E8%83%BD%E5%9F%BA%E5%87%86%E9%9A%BE%E5%80%929%E5%A4%A7%E9%A1%B6%E5%B0%96%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#AI时空智能基准难倒9大顶尖多模态模型#</span></a><br><br>AI要想在自动驾驶、机器人等应用落地，有些亟需解决的问题——<br><br>-自动驾驶需要知道：<br>        - 车与前方车辆的精确距离（米）<br>        - 行人横穿马路的速度（米/秒）<br>        - 拐弯时的安全车速（km/h）<br><br>-机器人操作则要求：<br>        - 判断目标物体的具体尺寸与位置（毫米级）<br>        - 评估物体之间的相对布局<br>        - 设计抓取路径、估算所需速度<br><br>换句话说，AI模型越来越强，但它们走出实验室，能真正理解这个三维、动态的物理世界吗？<br><br>对于这个问题，上海交通大学联合中国地质大学、南洋理工大学、智源研究院以及斯坦福大学的研究团队推出首个多模态大模型（MLLM）时空智能评测基准STI-Bench（Spatial-Temporal Intelligence Benchmark），向当前最先进的多模态大语言模型发起了关于精确空间时间理解的严峻挑战。<br><br>结果显示，即便是Gemini-2.5-Pro、GPT-4o、Claude-3.7-Sonnet、Qwen 2.5 VL等当前最强的多模态大模型，在需要定量分析真实世界空间关系和动态变化的任务上，表现并不尽人意。【图1】<br><br>与现有侧重语义的评测不同，STI-Bench直接采用真实世界视频作为输入，聚焦于精确、量化的时空理解，旨在评估模型在真实应用场景中的潜力。【图2】<br><br>数据来源包括300多个真实世界视频，覆盖三类典型场景：桌面操作（毫米级）、室内环境（厘米级）、户外场景（分米级）。【图3】<br><br>评测任务共八项，分属两个维度。<br><br>第一类是静态空间理解，包括：<br>（1）尺度度量，评估物体大小和物体之间的距离；<br>（2）空间关系，理解物体的相对位置关系；<br>（3）3D视频定位，预测物体在三维空间中的位置框。<br><br>第二类是动态时序理解，包括：<br>（4）位移与路径长度，判断物体运动距离；<br>（5）速度与加速度，分析物体运动的快慢及其变化趋势；<br>（6）自我中心方向，估计相机的旋转角度；<br>（7）轨迹描述，概括物体运动路径；<br>（8）姿态估计，识别相机或物体在运动过程中的姿态变化。<br><br>此外，该数据集还包含2000多对高质量问答（QA），所有问答基于精确标注计算真值，采用GPT-4o生成多样化问题与答案，并经过多轮人工审核与校准，确保问答内容准确、语言合理、且与对应场景的精度需求高度匹配。【图4】<br><br>研究团队对当前最先进的多模态模型进行了全面评测，包括最强的专有模型（GPT-4o、Gemini-2.0-Flash、Gemini-2.5-Pro、Claude-3.7-Sonnet）和知名开源模型（Qwen2.5-VL-72B、InternVL2.5-78B、VideoLLaMA 3等）。【图5】<br><br>评测结果令人感到担忧，表现最好的Qwen2.5-VL-72B和Gemini-2.5-Pro也仅不到42%的准确率，仅比随机猜测(20%)高一些，距离实际应用所需的可靠性还有天壤之别。【图6】<br><br>为了揭示大模型在空间-时间理解上失败的根本原因，研究者对Gemini-2.5-Pro在各个场景下各类任务的思考过程进行了详细错误分析，发现了三大核心瓶颈：【图7】<br><br>1. 定量空间属性不准确<br><br>模型往往难以通过单目视频准确估计视觉输入中物体的空间属性，如尺寸、距离，以及无法从视频中推断3D信息，影响了所有需要精确空间测量的任务。<br><br>2. 时间动态理解缺陷<br><br>模型在理解随时间变化的跨帧信息方面表现不佳，难以准确计算和描述运动特征如位移、速度和轨迹。尤其难以区分物体运动与相机运动，这些问题源于跨帧信息整合困难和物理先验的缺失。<br><br>3. 跨模态整合能力薄弱<br><br>模型无法有效结合理解文本指令与视觉内容，整合非视觉数据与视觉信息。这导致对时间约束的误解、给定初始条件等使用不当，以及结构化数据，如坐标、姿态等与视觉元素的正确关联，影响所有依赖多模态信息的任务。<br><br>这些问题直指当前MLLM在精准的空间-时间理解上的能力缺陷，也为未来研究指明了方向。<br><br>STI-Bench的结果清晰地揭示了当前多模态大模型在精确空间-时间理解方面的严重不足。只有当MLLM掌握了可靠、精确的空间-时间理解能力，它们才能在具身智能和自动驾驶等领域发挥真正的价值，迈出从虚拟世界到物理世界的关键一步。<br><br>STI-Bench的发布，为评估和改进MLLM的空间-时间理解能力提供了一个新的基准和“试金石”，有望引导研究人员更深入地探索解决方案。<br><br>目前，该项目的论文、代码、数据等已经开源——<br>论文链接： <a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fpdf%2F2503.23765" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>论文主页： <a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmira-sjtu.github.io%2FSTI-Bench.io%2F" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>Github： <a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FMIRA-SJTU%2FSTI-Bench" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>Huggingface： <a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhuggingface.co%2Fdatasets%2FMIRA-SJTU%2FSTI-Bench" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0hi99w6dtj30zk08u77z.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0hi9am0jij30zk0ieqlf.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0hi9abkkdj30k00l8dl1.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0hi9ad7ejj30s90k0gv1.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0hi9alokfj30zk0hb7ff.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0hi9b11ypj30zk0ji11n.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0hi9aditzj30ro0k0q6u.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

上海交通大学等机构发布首个多模态大模型时空智能评测基准STI-Bench，测试显示当前顶尖AI模型（如GPT-4o、Gemini-2.5-Pro）在真实世界时空理解任务中表现不佳，最高准确率仅42%。该基准基于300多个真实视频，评估8项时空任务，发现三大核心瓶颈：定量空间估计不准、动态时序理解缺陷、跨模态整合薄弱。研究揭示了AI在自动驾驶、机器人等需要精确物理世界理解的应用中存在重大技术障碍，为未来改进提供了明确方向。相关论文和数据集已开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T11:03:43Z
- **目录日期**: 2025-04-15
