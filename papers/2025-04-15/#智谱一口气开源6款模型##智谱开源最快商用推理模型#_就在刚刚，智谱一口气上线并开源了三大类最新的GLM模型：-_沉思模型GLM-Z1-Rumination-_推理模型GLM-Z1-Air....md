# #智谱一口气开源6款模型##智谱开源最快商用推理模型# 就在刚刚，智谱一口气上线并开源了三大类最新的GLM模型：- 沉思模型GLM-Z1-Rumination- 推理模型GLM-Z1-Air...

**URL**: https://weibo.com/6105753431/PnlNVFWip

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%99%BA%E8%B0%B1%E4%B8%80%E5%8F%A3%E6%B0%94%E5%BC%80%E6%BA%906%E6%AC%BE%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E6%99%BA%E8%B0%B1%E4%B8%80%E5%8F%A3%E6%B0%94%E5%BC%80%E6%BA%906%E6%AC%BE%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#智谱一口气开源6款模型#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%99%BA%E8%B0%B1%E5%BC%80%E6%BA%90%E6%9C%80%E5%BF%AB%E5%95%86%E7%94%A8%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E6%99%BA%E8%B0%B1%E5%BC%80%E6%BA%90%E6%9C%80%E5%BF%AB%E5%95%86%E7%94%A8%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#智谱开源最快商用推理模型#</span></a> <br><br>就在刚刚，智谱一口气上线并开源了三大类最新的GLM模型：<br><br>- 沉思模型GLM-Z1-Rumination<br>- 推理模型GLM-Z1-Air<br>- 基座模型GLM-4-Air-0414<br><br>若是以模型大小（9B和32B）来划分，更是可以细分为六款。<br><br>首先是两个9B大小的模型：<br><br>- GLM-4-9B-0414：主攻对话，序列长度介于32K到128K之间<br>- GLM-Z1-9B-0414：主攻推理，序列长度介于32K到128K之间<br><br>还有四个32B大小的模型，它们分别是：<br><br>- GLM-4-32B-Base-0414：基座模型，序列长度介于32K到128K之间<br>- GLM-4-32B-0414：主攻对话，序列长度介于32K到128K之间<br>- GLM-Z1-32B-0414：主攻推理，序列长度介于32K到128K之间<br>- GLM-Z1-32B-Rumination-0414：主攻推理，序列长度为128K<br><br>而随着一系列模型的开源，智谱也解锁了一项行业之最——<br><br>推理模型GLM-Z1-32B-0414做到了性能与DeepSeek-R1等顶尖模型相媲美的同时，实测推理速度可达200 tokens/秒。<br><br>如此速度，已然是目前国内商业模型中速度最快，而且它的高性价比版本价格也仅为DeepSeek-R1的1/30。<br><br>值得一提的是，本次开源的所有模型均采用宽松的MIT许可协议。<br><br>这就意味着上述的所有模型都可以免费用于商业用途、自由分发，为开发者提供了极大的使用和开发自由度。<br><br>那么这些开源模型的效果又如何？<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fu_AwV8KpFTXUqSmkZmmt-g" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">刚刚，智谱一口气开源6款模型，200 tokens/秒解锁商用速度之最 | 免费</span></a><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3ly1i0hbpuhw9kj30u00gpdqu.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1i0hbr1o5oaj30u00d443q.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

智谱AI近期开源了6款GLM系列模型，分为9B和32B两种规模，涵盖对话、推理和基座三大类。其中32B推理模型GLM-Z1-32B-0414性能对标DeepSeek-R1，推理速度达200 tokens/秒，号称国内最快商用推理模型，且成本仅为竞品的1/30。所有模型均采用MIT开源协议，支持免费商用和自由分发。主要型号包括GLM-4系列（对话优化）、GLM-Z1系列（推理优化）和GLM-Z1-Rumination（长序列推理），支持32K-128K上下文长度。此次开源显著提升了国产大模型的商用可用性。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-15T07:03:37Z
- **目录日期**: 2025-04-15
