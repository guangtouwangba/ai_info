# #GPT4o图像生成架构被破解了##GPT4o图像生成全面测评来了#GPT-4o图像生成架构被“破解”了！最近一阵，“万物皆可吉卜力”让GPT-4o的图像生成功能一炮而红，人们...

**URL**: https://weibo.com/6105753431/Pmtgfm1AZ

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23GPT4o%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%9E%B6%E6%9E%84%E8%A2%AB%E7%A0%B4%E8%A7%A3%E4%BA%86%23&amp;extparam=%23GPT4o%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%9E%B6%E6%9E%84%E8%A2%AB%E7%A0%B4%E8%A7%A3%E4%BA%86%23" data-hide=""><span class="surl-text">#GPT4o图像生成架构被破解了#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23GPT4o%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E5%85%A8%E9%9D%A2%E6%B5%8B%E8%AF%84%E6%9D%A5%E4%BA%86%23&amp;extparam=%23GPT4o%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E5%85%A8%E9%9D%A2%E6%B5%8B%E8%AF%84%E6%9D%A5%E4%BA%86%23" data-hide=""><span class="surl-text">#GPT4o图像生成全面测评来了#</span></a><br><br>GPT-4o图像生成架构被“破解”了！<br>最近一阵，“万物皆可吉卜力”让GPT-4o的图像生成功能一炮而红，人们随之好奇：<br>4o图像生成的架构底层逻辑到底是什么？GPT-4o究竟强在哪？存在哪些短板？<br>作为解答，北京大学、中山大学等多家科研机构共同推出GPT-ImgEval，首次系统评估了GPT-4o在图像生成上的真实表现。<br>这份量化评估基准不仅囊括了生成质量、编辑能力和知识推理，还尝试揭示GPT-4o背后的可能架构，还探讨了它生成图像的可检测性问题。【图1】<br>下面具体来看。<br><br>GPT-4o架构揭秘：可能使用了扩散+自回归混合方案<br>GPT-ImgEval团队尝试“反向破解”GPT-4o的图像生成架构。<br>研究团队在论文中提出了4种候选架构方案（见下图），尽管细节略有不同，但有一点是一致的：GPT-4o很可能采用的是自回归主干+扩散头的混合结构。<br>通俗来说，它的工作流程可能是这样的：文本或指令→ 自回归模块理解语义 → 生成中间视觉Token → 扩散模型将这些Token解码成图像。【图2】<br>当然，架构猜测不能仅靠想象。为此，研究团队设计了一套严谨的实证方法：<br>1. 先选取一组统一的文本提示（prompt），分别使用自回归模型（VAR）和扩散模型（Diffusion）各自生成1万张图像作为对比样本；<br>2. 利用这些图像训练一个二分类器，让它学会识别图像是“AR风格”还是“Diffusion风格”；<br>3. 然后，用同样的Prompt交给GPT-4o生成图像，将这些图像输入该分类器进行识别。<br>也就是说，整个过程中，提示词保持完全一致，只看不同模型生成的图像“长得像谁”，以此判断GPT-4o的生成方式更接近哪类结构。<br>结果很直接：GPT-4o生成的图像几乎全部被识别为“扩散风格”，这就从图像风格维度验证了GPT-4o的确可能用了扩散模型作为解码器。【图3】<br>除了对视觉解码器的分析，研究人员也深入探讨了视觉编码方式。他们指出，一些研究（如UniTok）认为基于向量量化（VQ）的编码器可能会削弱模型的语义理解能力。<br>因此，作者认为如果采用了pixel encoder，其大概率是连续（非VQ）的而不是离散（VQ）的，并基于此提出了四种可能的完整架构示意图。【图4】<br><br>三大维度全面评估GPT-4o图像能力<br>GPT-ImgEval聚焦三类核心任务，对GPT-4o进行了系统评估：<br>- 文本生成图像（GenEval）：通过对物体数量、颜色、位置、组合属性等细粒度维度进行测评，验证模型对文本的理解与图像的构造能力。<br>- 指令编辑图像（Reason-Edit）：模拟用户给出修改指令后，模型在保留图像语义基础上进行局部编辑的能力，如替换、删除、变色等。<br>- 基于世界知识的语义合成（WISE）：考察模型是否能将对世界常识、文化背景、科学原理等知识真正“显性化”为图像输出。<br>为了支持这一系统评估，研究团队开发了一套针对GPT-4o的自动化交互脚本，解决了当前该模型尚未开放图像生成API的现实问题。<br>这套脚本直接与GPT-4o网页界面交互，模拟真实用户行为：<br>- 自动输入提示词（Prompt）、点击提交<br>- 自动抓取生成图像并存储归档<br>- 每次请求会新开浏览器窗口，确保不同任务之间上下文不相互干扰<br>- 支持任务批量运行，可实现大规模、可重复的图像生成任务调度<br>最终，GPT-ImgEval的整体工作流如下图所示：【图5】<br>在文本生成图像（GenEval）任务中，GPT-4o取得了0.84的总得分，超越目前所有扩散类与自回归类图像生成模型。<br>尤其在以下几项中表现突出：数量控制（0.85）、颜色绑定（0.92）、空间位置（0.75）、属性组合（0.61）。【图6】<br>下图是一些GPT-4o使用GenEval基准中的prompt生图的具体例子：【图7】<br>而在图像编辑任务（Reason-Edit）中，GPT-4o得分高达0.929，领先第二名超过0.35，说明其在指令理解和局部控制上表现极其稳定。【图8】【图9】<br>在知识合成（WISE）任务中，GPT-4o同样大放异彩，多个子维度（生物、文化、物理等）得分均超过0.9，总分0.89，远高于当前开源模型（普遍在0.4~0.5之间）。<br>这说明GPT-4o具有强大的世界知识和推理能力，这应该是得益于GPT-4o这种统一多模态框架。【图10】【图11】<br><br>更多研究结论<br>GPT-4o vs Gemini 2.0 Flash：多轮编辑对比<br>研究团队还对GPT-4o与Google的Gemini 2.0 Flash进行了多轮图像编辑对比。<br>除了性能与架构机制，GPT-4o在实际的使用体验中也展现出了强劲的竞争力。研究团队对其与Google最新发布的 Gemini 2.0 Flash 进行了多轮编辑任务的实测对比：<br>- GPT-4o支持完整的多轮对话式编辑流程，上下文一致性强<br>- Gemini响应速度更快，但每轮需重新上传图像，缺乏连续性<br>- 在连续修改、复杂指令理解、图像语义保持方面，GPT-4o表现出更高的稳定性<br>从整体趋势来看，两者在编辑轮数增加后均出现一致性下降，但GPT-4o下降更缓，保持更稳。<br>GPT-4o与Gemini 2.0 Flash多轮编辑一致性对比如下图所示：【图12】<br>这一对比结果也进一步验证了：融合大模型语义理解能力的图像生成系统，在交互式创作任务中，正在展现出压倒性优势。<br><br>GPT-4o仍存五大问题，图像量化评估并非无解<br>研究团队总结出GPT-4o当前的五个常见生成难点：<br>1. 无法严格保持原图尺寸与边框比例，有时会自动裁切或缩放<br>2. 强制锐化，即使用户要求生成模糊图，也会被模型“优化”成高清<br>3. 编辑偏暖、全图色调变化，即使只修改小部分，可能全图色调甚至是全局都会被一定程度修改<br>4. 复杂场景失真，多人或人-物体交互场景易出现姿态不自然或结构错乱<br>5. 非英文文本支持较弱，如中文标识常出错，难以在复杂背景准确生成<br>这些问题不仅影响使用体验，也提示我们——GPT-4o仍在追求“自然感”与“精确控制”之间寻找平衡。【图13】<br><br>这些图像能被检测出来吗？<br>除了感知层面的观察和评估，研究团队进一步思考一个关键问题：GPT-4o生成的图像，是否真的可以“以假乱真”？<br>为此，研究者使用多个主流图像取证模型，对GPT-4o生成的图像进行了系统性评估。<br>结果显示，包括Effort、FakeVLM在内的多种检测器，对GPT-4o图像的识别准确率普遍超过95%，最高接近99.6%。【图14】<br>不仅仅停留在数值层面，研究团队还对量化评估成功的原因进行了机制层面的归因分析：<br>- GPT-4o可能在图像生成过程中引入了超分辨率模块，通过上采样插值导致明显伪影<br>- 模型有过度锐化与细节增强倾向，视觉效果虽然“精致”，却留下了被取证模型捕捉的痕迹<br>- 在用户未要求修改时，仍可能出现尺寸、色彩的隐性变化，破坏了图像一致性<br>- GPT-4o生成图像色调普遍偏暖，整体风格趋同，易被量化评估模型建立“风格识别模式”<br><br>可量化评估，并非弱点，而是AIGC安全设计的基线能力<br>研究团队认为，是否可量化评估，不应成为衡量生成模型能力强弱的标准，而应被视为评估其可控性与安全性的重要指标。<br>在未来的AIGC系统设计中，“逼真”固然重要，但“可识别”、“可追踪”同样不可或缺。GPT-4o生成图像中的伪影、色彩偏好等特征，也正是推动生成量化评估研究的重要突破口。<br>这也正是GPT-ImgEval的差异化亮点之一：不仅做量化评估，更从安全机制的角度进行深入诊断和前瞻探索。<br><br>GPT-4o很强，但“终局”远未到来<br>GPT-ImgEval不仅验证了GPT-4o在图像生成上的优势，更指出了它仍需突破的短板。尤其是在可控性、多语种处理、局部编辑稳定性等方面，仍有不少提升空间。<img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0amelbpkoj30zk0i2n2y.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0ameln7xqj30zk0f67ct.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0amektcswj30zk0efdom.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0amek14ocj30zk0a9gq1.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0amek3trnj30zk0ds4df.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0amelqs4oj30zk0g0n4m.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0amelyxrmj30x00k0wsn.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0amel6adhj30u30k0dmr.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0amelf2jkj30og0k0qju.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0amelvwrqj30uo0k0dpr.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0amelcywdj30nn0k0h0b.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0amelppvtj30zk0jntqj.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0amel1zapj30zk0fpdyl.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0amej40kaj30zk08ewia.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

北京大学、中山大学等机构联合发布的GPT-ImgEval研究揭示了GPT-4o图像生成的混合架构：采用自回归主干+扩散头的组合方案（分类器验证扩散风格占比99.6%）。测评显示，GPT-4o在文本生成（总分0.84）、指令编辑（0.929）和知识合成（0.89）三大任务中全面领先，但存在比例失真、强制锐化、多物体交互错乱等五大缺陷。检测实验表明，现有工具可95%以上识别其生成图像，主要因超分辨率伪影和风格趋同。研究强调可控性与安全性应成为AIGC核心指标。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-09T12:04:19Z
- **目录日期**: 2025-04-09
