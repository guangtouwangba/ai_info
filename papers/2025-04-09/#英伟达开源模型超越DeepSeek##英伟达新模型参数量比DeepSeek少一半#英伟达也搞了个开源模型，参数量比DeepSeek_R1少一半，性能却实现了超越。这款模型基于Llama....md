# #英伟达开源模型超越DeepSeek##英伟达新模型参数量比DeepSeek少一半#英伟达也搞了个开源模型，参数量比DeepSeek R1少一半，性能却实现了超越。这款模型基于Llama...

**URL**: https://weibo.com/6105753431/PmryDi25V

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%8B%B1%E4%BC%9F%E8%BE%BE%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B%E8%B6%85%E8%B6%8ADeepSeek%23&amp;extparam=%23%E8%8B%B1%E4%BC%9F%E8%BE%BE%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B%E8%B6%85%E8%B6%8ADeepSeek%23" data-hide=""><span class="surl-text">#英伟达开源模型超越DeepSeek#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%8B%B1%E4%BC%9F%E8%BE%BE%E6%96%B0%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E9%87%8F%E6%AF%94DeepSeek%E5%B0%91%E4%B8%80%E5%8D%8A%23&amp;extparam=%23%E8%8B%B1%E4%BC%9F%E8%BE%BE%E6%96%B0%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E9%87%8F%E6%AF%94DeepSeek%E5%B0%91%E4%B8%80%E5%8D%8A%23" data-hide=""><span class="surl-text">#英伟达新模型参数量比DeepSeek少一半#</span></a><br><br>英伟达也搞了个开源模型，参数量比DeepSeek R1少一半，性能却实现了超越。<br><br>这款模型基于Llama-3.1训练，名为Llama-3.1-Nemotron-Ultra-253B-v1，以下是该模型的亮点：<br><br>参数规模更小：Llama-3.1-Nemotron-Ultra的参数量为253B，相 ...<img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0affpb9lnj325x103nma.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0affq8ab9j30zk0jg7f5.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

英伟达发布开源大模型Llama-3.1-Nemotron-Ultra-253B-v1，基于Llama-3.1训练。该模型参数量为253B，比DeepSeek R1少一半，但性能实现超越。主要亮点包括更小的参数规模、更高的效率表现，以及开源可用的特性。模型名称中的"253B"直接体现了其参数规模，在保持高性能的同时显著降低了计算资源需求。这一进展展示了通过算法优化，可以在减少参数量的情况下实现模型性能提升的技术突破。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-09T09:03:51Z
- **目录日期**: 2025-04-09
