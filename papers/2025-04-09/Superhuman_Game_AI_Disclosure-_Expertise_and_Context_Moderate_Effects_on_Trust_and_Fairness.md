# Superhuman Game AI Disclosure: Expertise and Context Moderate Effects on Trust and Fairness

**URL**: http://arxiv.org/abs/2503.15514v2

## 原始摘要

As artificial intelligence surpasses human performance in select tasks,
disclosing superhuman capabilities poses distinct challenges for fairness,
accountability, and trust. However, the impact of such disclosures on diverse
user attitudes and behaviors remains unclear, particularly concerning potential
negative reactions like discouragement or overreliance. This paper investigates
these effects by utilizing Persona Cards: a validated, standardized set of
synthetic personas designed to simulate diverse user reactions and fairness
perspectives. We conducted an ethics board-approved study (N=32), utilizing
these personas to investigate how capability disclosure influenced behaviors
with a superhuman game AI in competitive StarCraft II scenarios. Our results
reveal transparency is double-edged: while disclosure could alleviate
suspicion, it also provoked frustration and strategic defeatism among novices
in cooperative scenarios, as well as overreliance in competitive contexts.
Experienced and competitive players interpreted disclosure as confirmation of
an unbeatable opponent, shifting to suboptimal goals. We release the Persona
Cards Dataset, including profiles, prompts, interaction logs, and protocols, to
foster reproducible research into human alignment AI design. This work
demonstrates that transparency is not a cure-all; successfully leveraging
disclosure to enhance trust and accountability requires careful tailoring to
user characteristics, domain norms, and specific fairness objectives.


## AI 摘要

研究表明，AI在特定任务中展示超人类能力时，透明度是一把双刃剑。通过《角色卡片》模拟工具对32人进行实验发现：披露AI超强能力虽能减少怀疑，但会引发新手在合作场景中的挫败感，或导致竞争环境下的过度依赖。经验玩家则可能因确认对手不可战胜而转向次优目标。该研究强调，透明度并非万能方案，需根据用户特征、领域规范和公平目标进行针对性设计。相关数据集已公开以促进可复现研究，说明有效披露需平衡信任建立与潜在负面反应。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-09T00:02:42Z
- **目录日期**: 2025-04-09
