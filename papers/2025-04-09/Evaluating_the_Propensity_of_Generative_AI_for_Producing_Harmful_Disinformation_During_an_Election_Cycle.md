# Evaluating the Propensity of Generative AI for Producing Harmful Disinformation During an Election Cycle

**URL**: http://arxiv.org/abs/2411.06120v6

## 原始摘要

Generative Artificial Intelligence offers a powerful tool for adversaries who
wish to engage in influence operations, such as the Chinese Spamouflage
operation and the Russian Internet Research Agency effort that both sought to
interfere with recent US election cycles. Therefore, this study seeks to
investigate the propensity of current generative AI models for producing
harmful disinformation during an election cycle. The probability that different
generative AI models produced disinformation when given adversarial prompts was
evaluated, in addition the associated harm. This allows for the expected harm
for each model to be computed and it was discovered that Copilot and Gemini
tied for the overall safest performance by realizing the lowest expected harm,
while GPT-4o produced the greatest rates of harmful disinformation, resulting
in much higher expected harm scores. The impact of disinformation category was
also investigated and Gemini was safest within the political category of
disinformation due to mitigation attempts made by developers during the
election, while Copilot was safest for topics related to health. Moreover,
characteristics of adversarial roles were discovered that led to greater
expected harm across all models. Finally, classification models were developed
that predicted disinformation production based on the conditions considered in
this study, which offers insight into factors important for predicting
disinformation production. Based on all of these insights, recommendations are
provided that seek to mitigate factors that lead to harmful disinformation
being produced by generative AI models. It is hoped that developers will use
these insights to improve future models.


## AI 摘要

这项研究评估了生成式AI模型在选举周期中产生有害虚假信息的倾向。研究发现，Copilot和Gemini总体安全性最佳，产生的预期危害最低；而GPT-4o产生的有害虚假信息最多，危害评分最高。不同模型在不同虚假信息类别中表现各异：Gemini在政治类最安全，Copilot在健康类最优。研究还识别了导致危害增加的对抗性特征，并开发了预测虚假信息生成的分类模型。基于这些发现，研究提出了减少生成式AI产生有害虚假信息的建议，希望开发者能利用这些见解改进未来模型。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-09T22:02:08Z
- **目录日期**: 2025-04-09
