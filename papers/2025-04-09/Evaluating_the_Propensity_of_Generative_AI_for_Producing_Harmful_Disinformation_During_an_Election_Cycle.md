# Evaluating the Propensity of Generative AI for Producing Harmful Disinformation During an Election Cycle

**URL**: http://arxiv.org/abs/2411.06120v6

## 原始摘要

Generative Artificial Intelligence offers a powerful tool for adversaries who
wish to engage in influence operations, such as the Chinese Spamouflage
operation and the Russian Internet Research Agency effort that both sought to
interfere with recent US election cycles. Therefore, this study seeks to
investigate the propensity of current generative AI models for producing
harmful disinformation during an election cycle. The probability that different
generative AI models produced disinformation when given adversarial prompts was
evaluated, in addition the associated harm. This allows for the expected harm
for each model to be computed and it was discovered that Copilot and Gemini
tied for the overall safest performance by realizing the lowest expected harm,
while GPT-4o produced the greatest rates of harmful disinformation, resulting
in much higher expected harm scores. The impact of disinformation category was
also investigated and Gemini was safest within the political category of
disinformation due to mitigation attempts made by developers during the
election, while Copilot was safest for topics related to health. Moreover,
characteristics of adversarial roles were discovered that led to greater
expected harm across all models. Finally, classification models were developed
that predicted disinformation production based on the conditions considered in
this study, which offers insight into factors important for predicting
disinformation production. Based on all of these insights, recommendations are
provided that seek to mitigate factors that lead to harmful disinformation
being produced by generative AI models. It is hoped that developers will use
these insights to improve future models.


## AI 摘要

这项研究评估了不同生成式AI模型在选举周期中产生有害虚假信息的倾向及其危害性。研究发现，Copilot和Gemini总体表现最安全，产生的预期危害最低；而GPT-4o产生的有害虚假信息最多，危害评分最高。不同模型在不同领域的表现各异：Gemini在政治类虚假信息方面最安全，Copilot则在健康话题上表现最佳。研究还识别了导致危害增加的对抗性特征，并开发了预测虚假信息产生的分类模型。最后提出了改进建议，希望开发者能利用这些发现优化未来模型，减少有害虚假信息的产生。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-09T17:02:25Z
- **目录日期**: 2025-04-09
