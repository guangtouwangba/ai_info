# #全程AI写的论文进顶会##首个AI科学家被顶会认可#嚯！完全由AI生成的论文，通过顶会ICLR workshop评审？！分数为6/7/6，已经超过平均人类接收门槛。论文是酱婶的...

**URL**: https://weibo.com/6105753431/PmtgetSop

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%85%A8%E7%A8%8BAI%E5%86%99%E7%9A%84%E8%AE%BA%E6%96%87%E8%BF%9B%E9%A1%B6%E4%BC%9A%23&amp;extparam=%23%E5%85%A8%E7%A8%8BAI%E5%86%99%E7%9A%84%E8%AE%BA%E6%96%87%E8%BF%9B%E9%A1%B6%E4%BC%9A%23" data-hide=""><span class="surl-text">#全程AI写的论文进顶会#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E9%A6%96%E4%B8%AAAI%E7%A7%91%E5%AD%A6%E5%AE%B6%E8%A2%AB%E9%A1%B6%E4%BC%9A%E8%AE%A4%E5%8F%AF%23&amp;extparam=%23%E9%A6%96%E4%B8%AAAI%E7%A7%91%E5%AD%A6%E5%AE%B6%E8%A2%AB%E9%A1%B6%E4%BC%9A%E8%AE%A4%E5%8F%AF%23" data-hide=""><span class="surl-text">#首个AI科学家被顶会认可#</span></a><br><br>嚯！完全由AI生成的论文，通过顶会ICLR workshop评审？！<br>分数为6/7/6，已经超过平均人类接收门槛。<br>论文是酱婶的。【图1】<br>整个通篇看下来，图表论据俱全，十分有模有样。【图2】<br>这篇论文，由首位AI科学家AI Scientist的2.0版本完成。<br>背后公司Sakana AI，是Transformer作者之一的Llion Jones的创业公司。<br>新版本2.0是一个通用端到端Agent系统，与原版本不同的是，它摆脱了对人工模版的依赖，能够自主生成假设、运行实验、分析数据并撰写科学论文，图表理解能力也更强。<br>它在ML领域中具有更强的泛化能力，并采用由实验管理Agent引导的渐进式代理树搜索（AgenticTreeSearch）。<br>就连它的GitHub开源代码库都是由大模型来编写。【图3】<br>AI生成论文通过顶会评审<br>首先来看这篇完全由AI生成的论文，官方透露了诸多细节。<br>这篇论文的标题为：《组合正则化：增强神经网络泛化的意外障碍》。论文中的提出了一种旨在增强神经网络组成泛化的组成正则化方法，进行了大量实验以评估其影响，并分析了算子复杂性对模型性能的影响，讨论了组成正则化没有产生预期效益的潜在原因。<br>当时ICLR workshop同意他们递交3篇AI生成的论文进行同行评审。<br>评审人员会被告知他们正在评审的论文可能是AI生成的（43篇论文中有3篇），但并不知道分配给他们的论文作者到底是不是AI。<br>SakanaAI准备的论文完全由AI端到端生成，没有经过人类任何修改——<br>AI Scientist-v2提出了科学假设，提出了测试假设的实验，编写和完善了进行这些实验的代码，运行实验，分析数据，将数据可视化为图表，并写下整个科学手稿的每一个字，从标题到最终参考文献，包括放置图表和所有格式。<br>整个过程，人类仅做的一个工作是，提供一个广泛的研究主题，最终他们挑选出了三篇排名前三论文（考虑到多样性和质量）提交给研讨会。【图4】<br>△团队为每篇生成的论文撰写了全面的评论<br>最终，在提交的三篇论文中，有两篇论文未达到接受标准。一篇论文的平均得分为 6.33（分别是6/6/7），在所有提交的论文中排名约 45%，高于人类平均接受门槛。【图5】<br>不过为了透明起见，这篇论文在同行评审之后被撤回，也不会在OpenReview公共论坛上发布，但是可以GitHub存储库中找到。<br>除此之外，他们发现AI Scientist偶尔也会犯一些引用错误。<br>比如将错误地将“基于 LSTM 的神经网络”归因于Goodfellow (2016)，而不是正确的作者Hochreiter和Schmidhuber (1997)。【图6】<br>而为了提高实验结果的科学准确性、可重复性和统计严谨性，他们鼓励AI Scientist重复其每个实验（已选入论文）数次。【图7】<br>首位AI科学家2.0<br>去年8月，首位AI Scientist横空出世，一出手就独立完成了10篇论文。现在的2.0生产的论文已经可以通过顶会同行评审。<br>值得一提的是，官方GitHub页面上，特别注明了两者的区别：AI Scientist-v2并不一定能写出比v1更好的论文，尤其是在有强大的起始模板可用的情况下。<br>v1遵循定义明确的模板，成功率较高，而v2则采用更广泛、更具探索性的方法，成功率较低。v1最适合具有明确目标和坚实基础的任务，而v2则专为开放式科学探索而设计。【图8】<br>AI Scientist-v2通过将树搜索与LLM工作流相结合，该工作流程由多个阶段组成，包括自动创意生成、实验执行、图表可视化、手稿撰写和审稿。【图9】<br>它采用代理树搜索（由实验进度管理器管理，跨越多个阶段）来生成和完善代码实现。随后的实验利用树搜索中表现最好的代码检查点（节点），对各种研究假设进行迭代测试。<br>Transformer作者之一创业公司<br>背后公司Sakana AI，Transformer作者之一Llion Jones（简称狮子哥）的创业公司。<br>他本硕毕业于伯明翰大学，在Delcam、油管、谷歌都工作过，谷歌是他待得最久的一家公司。<br>据FourWeekMBA介绍称，在他之前的工作经历中，“曾两度与谷歌的工作擦肩而过”。<br>第一次是他刚毕业找工作时，虽然投了谷歌伦敦软件工程师的岗位，并通过了两轮电话面试，但最终相比谷歌，他选择了位于英国的CAD/CAM软件公司Delcam。<br>值得一说的是，在拿下谷歌offer前，恰巧遇上2009年的经济危机，狮子哥找不到工作，好几个月都只能靠领取救济金勉强度日。<br>第二次是工作18个月后，他又接到了谷歌的招聘电话，询问他是否想重新申请，但他依旧没去谷歌，而是随后加入了YouTube。<br>在Youtube做三年软件工程师期间，他对人工智能产生兴趣，自学了Coursera的机器学习课程，并终于在2015年的时候加入谷歌研究院，担任里面的高级软件工程师。<br>也正是在此期间，他与其他七名作者一起发表了那篇著名的Transformer论文Attention Is Al lYou Need。<br>除此之外，狮子哥也在谷歌参与了不少研究，包括Prot Trans、Tensor2Tensor等。<br>之所以选择离开谷歌，是因为公司目前已经发展到一种规模，使得他无法继续进行自己想做的工作。<br>除了每天都在浪费精力排查其他人的bug，他还需要花时间从这家公司中找资源，试图获得访问某些数据的权限。<br>创业过后，Sakana AI的工作在有序推进。<br>去年8月，他们首次推出了AI科学家（AI Scientist）、AI审稿人项目。在这之前，还出过大模型合并进化算法，以及研究Tranformer内部信息流动。<br>此次作为AI Scientist的延续，依旧由Sakana AI、UBC、牛津合作完成。<br>合著者包括UBC的Cong Lu和Jeff Clune以及牛津大学的Chris Lu和Jakob Foerster，两位华人以及他们的导师参与。【图10】<br>Cong Lu，UBC（不列颠哥伦比亚大学）博士后研究员，导师是Jeff Clune。今年2月加入了DeepMind。<br>Cong曾在RGU（罗伯特戈登大学）就读，2019年在牛津大学拿下博士学位，他的主要研究方向是开放式强化学习和AI科学发现。<br>此前，他曾在Waymo和微软实习过。【图11】<br>Chris Lu，博士毕业前在Sakana AI实习了6个月。<br>他本科毕业于UC伯克利，博士毕业于牛津大学，导师是Jakob Foerster。去年10月毕业之后，去到了OpenAI。<br>Chris目前的重要研究方向，是将进化启发的技术应用于元学习和多智能体强化学习。<br>2022年夏天，他曾在DeepMind以研究科学家身份实习过。【图12】<br>虽然这次AI科学家已经可以生产出顶会级别的论文了，但这并不是他们的最终目的。<br>这次是顶级的机器学习会议，下次可能就是顶级科学期刊了。<br>比如Nature、Science啥的。【图13】<br>归根结底，研究团队认为最重要的不是人工智能科学与人类科学的比较，而是它的发现是否有助于人类繁荣，例如治愈疾病或扩展我们对宇宙规律的认识。<br>你觉得这个时刻什么时候会到来呢？<br>参考链接：<br>[1]<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fsakana.ai%2Fai-scientist-first-publication%2F%23importance-of-transparency-and-ethical-code-of-conduct" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>[2]<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FSakanaAI%2FAI-Scientist-ICLR2025-Workshop-Experiment%3Ftab%3Dreadme-ov-file" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>[3]<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FSakanaAI%2FAI-Scientist-v2" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>原文：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FP9vJ65OVemtZzfc1Kf9KAg" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0al4xmartj30nk0k079g.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0al4xv8g1j30tb0k0ahg.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0al4vowy9j30zk07a41s.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0al4xk99tj30zk0d0wlc.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0al4xihe8j30ml0k0tfr.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0al4xxcofj30zk0d545y.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0al4w4vpnj30zk091jvc.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0al4yb3kej30zk0g6wlr.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0al4xkkefj30ug0k0wl5.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0al4wxwkfj30zk0bcgpc.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0al4xaez8j30k00ka7ex.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0al4xs1b3j30k00qy126.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0al4wxdrgj30k00k116g.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

Sakana AI开发的AI Scientist 2.0系统首次实现完全由AI生成的论文通过顶会ICLR workshop评审（评分6/7/6，超人类平均接收标准）。该系统能自主完成从提出假设、实验设计、代码编写到论文撰写的全流程，仅需人类提供研究主题。论文《组合正则化：增强神经网络泛化的意外障碍》因透明性考虑最终被撤回，但展示了AI科研潜力。该系统由Transformer作者Llion Jones的创业公司研发，采用代理树搜索技术，相比模板化的v1版本更擅长开放式探索。团队表示最终目标是推动AI在自然科学领域的突破性发现。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-09T10:04:37Z
- **目录日期**: 2025-04-09
