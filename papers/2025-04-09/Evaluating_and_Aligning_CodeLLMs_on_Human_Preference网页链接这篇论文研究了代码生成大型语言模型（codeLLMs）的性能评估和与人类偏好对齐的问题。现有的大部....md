# Evaluating and Aligning CodeLLMs on Human Preference网页链接这篇论文研究了代码生成大型语言模型（codeLLMs）的性能评估和与人类偏好对齐的问题。现有的大部...

**URL**: https://weibo.com/1870858943/P58h85y3u

## 原始摘要

Evaluating and Aligning CodeLLMs on Human Preference<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fwww.aminer.cn%2Fpub%2F67565a4bae8580e7ff8e0fbd%2F%3Ff%3Dwb" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>这篇论文研究了代码生成大型语言模型（codeLLMs）的性能评估和与人类偏好对齐的问题。现有的大部分代码相关基准测试主要关注生成正确代码片段的能力，但忽略了与人类偏好的匹配。为此，论文提出了一种严格的人类策划的基准C ...<img style="" src="https://tvax4.sinaimg.cn/large/6f830abfly1hwmt504ez9j22bt17pnpd.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

这篇论文针对代码生成大语言模型(codeLLMs)提出了新评估方法，关注点从单纯代码正确性扩展到与人类偏好的对齐。研究者指出当前基准测试主要评估代码功能正确性，却忽视了代码可读性、风格等人类偏好因素。为此，论文开发了一个精心设计的人类标注基准CHP(Code Human Preference)，通过系统化评估框架来衡量codeLLMs在代码质量、可维护性等方面的表现。这项工作为提升AI生成代码的实际可用性提供了重要方向，强调了在代码生成任务中兼顾技术正确性和人类工程实践需求的必要性。(99字)

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-09T09:05:37Z
- **目录日期**: 2025-04-09
