# #李飞飞团队定世界模型新标杆##世界生成能力迎来统一评测#世界模型领域最新进展，要比拼“世界生成”了。李飞飞吴佳俊团队提出了全面评测基准WorldScore，涵盖了...

**URL**: https://weibo.com/6105753431/PmtgdCPKy

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%9D%8E%E9%A3%9E%E9%A3%9E%E5%9B%A2%E9%98%9F%E5%AE%9A%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B%E6%96%B0%E6%A0%87%E6%9D%86%23&amp;extparam=%23%E6%9D%8E%E9%A3%9E%E9%A3%9E%E5%9B%A2%E9%98%9F%E5%AE%9A%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B%E6%96%B0%E6%A0%87%E6%9D%86%23" data-hide=""><span class="surl-text">#李飞飞团队定世界模型新标杆#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%B8%96%E7%95%8C%E7%94%9F%E6%88%90%E8%83%BD%E5%8A%9B%E8%BF%8E%E6%9D%A5%E7%BB%9F%E4%B8%80%E8%AF%84%E6%B5%8B%23&amp;extparam=%23%E4%B8%96%E7%95%8C%E7%94%9F%E6%88%90%E8%83%BD%E5%8A%9B%E8%BF%8E%E6%9D%A5%E7%BB%9F%E4%B8%80%E8%AF%84%E6%B5%8B%23" data-hide=""><span class="surl-text">#世界生成能力迎来统一评测#</span></a><br><br>世界模型领域最新进展，要比拼“世界生成”了。<br>李飞飞吴佳俊团队提出了全面评测基准WorldScore，涵盖了三大类评估指标，动态静态都有涉及，其数据集中包含了3000个测试样例。<br>并且，WorldScore将3D场景生成、4D场景生成和视频生成三类模型的评估，统一到了一起。【图1】<br>利用WorldScore基准，团队对一共19款模型进行了全面评估。<br>评估的结果揭示了当前世界生成技术面临的相机控制能力不足、长序列世界生成困难等主要挑战，为模型研究人员提供了重要参考。<br>正如网友所评价，从单一场景到整体世界构建的转变，需要这样的基准来对研究做出指导。【图2】<br>3D/4D/视频生成统一评测<br>研究团队认为，之前的基准测试（例如 VBench）仅能评估单个场景的生成能力，远未达到“世界”生成的层次。【图3】<br>并且以前的基准测试仅考虑视频模型，但世界生成模型还包括3D和4D方法，而WorldScore可以对所有这些模型进行统一评估。<br>WorldScore将世界生成任务分解成一系列连续的下一场景生成任务，每个任务由三个关键组成部分定义：<br>当前场景：包含一张场景图像和对应的文本描述；<br>下一场景；<br>布局：一系列相机矩阵定义的相机轨迹，以及描述相机如何移动的文本说明。【图4】<br>数据集方面，WorldScore包含了3000个测试样例，其中2000个用于评估静态世界生成能力，1000个用于评估动态世界生成能力。<br>静态世界生成数据涵盖了10个场景类别，包括5类室内场景（餐饮空间、居住空间、通道、公共空间、工作空间）和5类室外场景（城市、郊区、水域景观、陆地景观、绿色景观）。<br>动态世界数据则包含了5种不同类型的运动：关节运动、可变形运动、流体运动、刚体运动和多物体运动。<br>每个测试样例都有两个版本——真实风格和艺术风格，以评估模型在不同视觉域的表现。【图5】<br>所涉及的指标则包括了可控性、质量和动态评估（静态场景不涉及此项）三个大类。<br>其中可控性评估，具体又包括了三项指标：<br>相机控制能力：通过计算生成视频中相机运动与指定轨迹的偏差来评估，具体计算尺度不变的旋转误差和平移误差，然后取其几何平均值；<br>物体控制能力：使用开放集物体检测模型检查指定物体是否出现在生成场景中，从文本提示中提取1-2个关键物体描述，计算检测到这些物体的成功率；<br>内容一致性：使用CLIPScore评估生成场景与完整文本描述的语义匹配程度。<br>质量评估，涵盖了四项内容：<br>3D一致性：使用DROID-SLAM估计每帧的密集深度图，计算连续帧之间可见像素的重投影误差，评估场景几何结构的稳定性；<br>光度一致性：通过计算连续帧之间的光流来评估外观和纹理的稳定性，使用平均端点误差（AEPE）来量化不稳定的视觉表现；<br>风格一致性：计算第一帧和最后一帧Gram矩阵之间的F范数差异，评估风格保持程度；<br>主观质量：结合CLIP-IQA+和CLIP Aesthetic两个自动评估指标（该组合经过200人的人类研究验证最接近人类感知）。<br>动态评估则包含三个方面：<br>运动准确性：比较指定运动区域内外的光流，评估运动是否出现在正确位置；<br>运动幅度：通过估计连续帧之间的光流大小来评估生成大幅度运动的能力；<br>运动平滑性：使用视频帧插值模型生成平滑过渡作为参考，评估生成视频的时间连续性。【图6】<br>最终，所有评估指标都经过线性归一化处理到0-100区间，并通过计算控制和质量维度各指标的算术平均值得到WorldScore-Static得分。<br>在此基础上，再加入动态维度的三项指标成绩，就得到了WorldScore-Dynamic评分。<br>3D模型更擅长静态，视频模型动态效果更好<br>利用WorldScore，研究团队对19款不同类型模型的世界生成能力进行了评测，包括2款闭源模型和17款开源模型。【图7】<br>评测结果显示，在静态世界生成方面，3D场景生成模型展现出明显优势。其中WonderWorld和LucidDreamer分别以72.69分和70.40分位居榜首，远超表现最好的视频模型CogVideoX-I2V的62.15分。<br>但在动态世界生成方面，则是视频模型展现出了较强的实力，开源模型CogVideoX-I2V以59.12分的成绩领先。【图8】<br>在不同场景类型的测试中，视频模型在室内场景表现相对较好，但在室外场景生成时与3D模型的差距明显扩大。<br>同时，序列长度对模型性能有显著影响——所有模型在短序列任务上表现尚可，但视频模型在处理长序列时性能显著下降，而3D模型则相对稳定。<br>此外，研究者还对比了T2V和I2V两类视频模型的特点。结果表明，T2V模型在控制性和动态生成能力方面较强，更容易实现大幅度的相机运动。<br>相比之下，I2V模型倾向于保持输入图像的视角，虽然生成质量较高，但相机运动相对保守。<br>作者简介<br>本文的两名共同一作均来自吴佳俊团队，分别是硕士生段皞一（Haoyi Duan）和博士生俞洪兴（Hong-Xing Koven Yu）。<br>段皞一是浙江大学2023届优秀毕业生，还获得了竺院荣誉学位，本科期间在周钊教授的指导下研究多模态学习。【图9】<br>俞洪兴本科和和硕士均就读于中山大学，硕士期间导师是郑伟诗教授（现任中山大学计算机学院副院长）。<br>俞洪兴的主要研究方向是物理场景理解、动力学模型与仿真，以及3D/4D视觉生成。【图10】<br>目前，两人正在进行密切合作。<br>今年入选CVPR HighLight的单图生成交互式3D场景模型WonderWorld，也是两人共同一作。【图11】<br>除了两名共同一作和吴佳俊以及李飞飞之外，斯坦福硕士生Sirui (Ariel) Chen也参与了WorldScore的工作。【图12】原文链接：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FDWvA47PguoHMdsfyc-ITBw" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">李飞飞团队提出世界模型基准：“世界生成”能力迎来统一评测，3D/4D/视频模型同台PK</span></a><br>论文地址：<br><a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2504.00983" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0algwpuf2j30wn0k01ct.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0algweq28j30zk0j9tha.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0algul11tj30mv0k0dpk.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0algwuduqj30zk0hln1w.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0algvlwlsj30r40k0au0.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0algvrfeoj30zk0f7jz4.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0algvx1kjj30ri0k07be.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0algwf5tbj30wy0k014g.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0algtt4t0j30k00k013m.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0algu5kkzj30k00k0woo.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0algtyoirj30zk08v7af.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0algtkwcbj30zk07kta9.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

李飞飞和吴佳俊团队提出世界模型评测基准WorldScore，统一评估3D/4D/视频生成模型的"世界生成"能力。该基准包含3000个测试样例，涵盖静态和动态场景，从可控性、质量和动态三个维度设置10项指标。评测19款模型后发现：3D模型在静态场景表现更优（最高72.69分），而视频模型擅长动态生成（最高59.12分）。研究揭示了当前技术存在相机控制不足、长序列生成困难等挑战。该工作为从单一场景到整体世界构建的研究提供了首个统一评估框架，相关论文已发布于arXiv。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-09T11:04:24Z
- **目录日期**: 2025-04-09
