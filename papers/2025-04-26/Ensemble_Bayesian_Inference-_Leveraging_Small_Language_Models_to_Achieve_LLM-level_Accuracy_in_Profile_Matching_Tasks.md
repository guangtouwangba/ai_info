# Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks

**URL**: http://arxiv.org/abs/2504.17685v1

## 原始摘要

This study explores the potential of small language model(SLM) ensembles to
achieve accuracy comparable to proprietary large language models (LLMs). We
propose Ensemble Bayesian Inference (EBI), a novel approach that applies
Bayesian estimation to combine judgments from multiple SLMs, allowing them to
exceed the performance limitations of individual models. Our experiments on
diverse tasks(aptitude assessments and consumer profile analysis in both
Japanese and English) demonstrate EBI's effectiveness. Notably, we analyze
cases where incorporating models with negative Lift values into ensembles
improves overall performance, and we examine the method's efficacy across
different languages. These findings suggest new possibilities for constructing
high-performance AI systems with limited computational resources and for
effectively utilizing models with individually lower performance. Building on
existing research on LLM performance evaluation, ensemble methods, and
open-source LLM utilization, we discuss the novelty and significance of our
approach.


## AI 摘要

本研究提出了一种名为"集成贝叶斯推理(EBI)"的新方法，通过贝叶斯估计整合多个小型语言模型(SLM)的判断，使其性能超越单个模型，达到与专有大型语言模型(LLM)相当的准确度。实验证明，EBI在多种任务(包括日英双语的能力评估和消费者画像分析)中表现优异。研究发现，即使集成包含性能较差的模型(负提升值)，整体性能仍能提升，且该方法适用于不同语言。这为在有限计算资源下构建高性能AI系统，以及有效利用低性能模型提供了新思路。研究建立在现有LLM评估、集成方法和开源LLM利用的基础上，具有创新意义。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-26T20:01:46Z
- **目录日期**: 2025-04-26
