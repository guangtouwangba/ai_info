# COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents

**URL**: http://arxiv.org/abs/2505.23720v1

## 原始摘要

This paper considers a contextual bandit problem involving multiple agents,
where a learner sequentially observes the contexts and the agent's reported
arms, and then selects the arm that maximizes the system's overall reward.
Existing work in contextual bandits assumes that agents truthfully report their
arms, which is unrealistic in many real-life applications. For instance,
consider an online platform with multiple sellers; some sellers may
misrepresent product quality to gain an advantage, such as having the platform
preferentially recommend their products to online users. To address this
challenge, we propose an algorithm, COBRA, for contextual bandit problems
involving strategic agents that disincentivize their strategic behavior without
using any monetary incentives, while having incentive compatibility and a
sub-linear regret guarantee. Our experimental results also validate the
different performance aspects of our proposed algorithm.


## AI 摘要

这篇论文研究了一个涉及多个智能体的上下文赌博机问题，其中学习者需要观察上下文和智能体报告的臂（选择），然后选择最大化系统整体奖励的臂。现有研究假设智能体会如实报告，但这在现实中不成立（如卖家可能虚报产品质量以获得推荐优势）。为此，作者提出了COBRA算法，在不使用金钱激励的情况下，通过机制设计抑制智能体的策略性行为，同时保证激励相容性和次线性遗憾。实验验证了算法的有效性。该研究解决了传统模型忽略的策略性欺骗问题，具有实际应用价值。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-30T08:02:03Z
- **目录日期**: 2025-05-30
