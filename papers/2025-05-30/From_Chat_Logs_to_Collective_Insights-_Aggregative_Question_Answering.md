# From Chat Logs to Collective Insights: Aggregative Question Answering

**URL**: http://arxiv.org/abs/2505.23765v1

## 原始摘要

Conversational agents powered by large language models (LLMs) are rapidly
becoming integral to our daily interactions, generating unprecedented amounts
of conversational data. Such datasets offer a powerful lens into societal
interests, trending topics, and collective concerns. Yet, existing approaches
typically treat these interactions as independent and miss critical insights
that could emerge from aggregating and reasoning across large-scale
conversation logs. In this paper, we introduce Aggregative Question Answering,
a novel task requiring models to reason explicitly over thousands of
user-chatbot interactions to answer aggregative queries, such as identifying
emerging concerns among specific demographics. To enable research in this
direction, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative
questions derived from 182,330 real-world chatbot conversations. Experiments
show that existing methods either struggle to reason effectively or incur
prohibitive computational costs, underscoring the need for new approaches
capable of extracting collective insights from large-scale conversational data.


## AI 摘要

本文提出了一种新任务——聚合问答(Aggregative Question Answering)，旨在通过分析大规模用户与AI助手的对话数据来挖掘群体性见解。研究者构建了包含182,330条真实对话和6,027个聚合问题的WildChat-AQA基准测试，发现现有方法要么推理能力不足，要么计算成本过高。该研究强调了开发新方法的重要性，以从海量对话数据中有效提取社会兴趣、热点话题和群体关切等集体洞察。这项工作为利用大语言模型生成的海量对话数据进行社会分析开辟了新方向。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-30T13:09:43Z
- **目录日期**: 2025-05-30
