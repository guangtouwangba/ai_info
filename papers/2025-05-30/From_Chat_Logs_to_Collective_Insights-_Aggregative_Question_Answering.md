# From Chat Logs to Collective Insights: Aggregative Question Answering

**URL**: http://arxiv.org/abs/2505.23765v1

## 原始摘要

Conversational agents powered by large language models (LLMs) are rapidly
becoming integral to our daily interactions, generating unprecedented amounts
of conversational data. Such datasets offer a powerful lens into societal
interests, trending topics, and collective concerns. Yet, existing approaches
typically treat these interactions as independent and miss critical insights
that could emerge from aggregating and reasoning across large-scale
conversation logs. In this paper, we introduce Aggregative Question Answering,
a novel task requiring models to reason explicitly over thousands of
user-chatbot interactions to answer aggregative queries, such as identifying
emerging concerns among specific demographics. To enable research in this
direction, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative
questions derived from 182,330 real-world chatbot conversations. Experiments
show that existing methods either struggle to reason effectively or incur
prohibitive computational costs, underscoring the need for new approaches
capable of extracting collective insights from large-scale conversational data.


## AI 摘要

大型语言模型驱动的对话代理正快速融入日常生活，生成前所未有的海量对话数据。这些数据能揭示社会兴趣、热点话题和集体关切，但现有方法通常将对话视为独立事件，错失了通过聚合分析获取深层洞见的机会。本文提出"聚合问答"新任务，要求模型显式推理数千条用户-聊天机器人对话以回答聚合查询（如识别特定人群的新兴关切）。为此，研究者构建了WildChat-AQA基准数据集，包含182,330条真实对话衍生的6,027个聚合问题。实验表明现有方法存在推理不足或计算成本过高的问题，亟需开发能从海量对话中提取集体洞见的新方法。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-30T21:00:52Z
- **目录日期**: 2025-05-30
