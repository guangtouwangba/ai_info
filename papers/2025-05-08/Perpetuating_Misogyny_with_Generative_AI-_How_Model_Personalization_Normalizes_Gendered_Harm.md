# Perpetuating Misogyny with Generative AI: How Model Personalization Normalizes Gendered Harm

**URL**: http://arxiv.org/abs/2505.04600v1

## 原始摘要

Open-source text-to-image (TTI) pipelines have become dominant in the
landscape of AI-generated visual content, driven by technological advances that
enable users to personalize models through adapters tailored to specific tasks.
While personalization methods such as LoRA offer unprecedented creative
opportunities, they also facilitate harmful practices, including the generation
of non-consensual deepfakes and the amplification of misogynistic or
hypersexualized content. This study presents an exploratory sociotechnical
analysis of CivitAI, the most active platform for sharing and developing
open-source TTI models. Drawing on a dataset of more than 40 million
user-generated images and over 230,000 models, we find a disproportionate rise
in not-safe-for-work (NSFW) content and a significant number of models intended
to mimic real individuals. We also observe a strong influence of internet
subcultures on the tools and practices shaping model personalizations and
resulting visual media. In response to these findings, we contextualize the
emergence of exploitative visual media through feminist and constructivist
perspectives on technology, emphasizing how design choices and community
dynamics shape platform outcomes. Building on this analysis, we propose
interventions aimed at mitigating downstream harm, including improved content
moderation, rethinking tool design, and establishing clearer platform policies
to promote accountability and consent.


## AI 摘要

开源文本生成图像(TTI)技术快速发展，使CivitAI等平台成为个性化AI模型分享中心。研究分析该平台4000万用户生成图像和23万模型发现：NSFW内容激增，大量模型用于模仿真人，网络亚文化深刻影响模型定制实践。从女性主义和技术建构主义视角看，平台设计和社区动态助长了剥削性视觉内容。研究者建议采取改进内容审核、优化工具设计、明确平台政策等措施，以增强问责制和知情同意，减少技术滥用风险。该研究揭示了AI生成内容平台面临的社会伦理挑战。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-08T16:01:43Z
- **目录日期**: 2025-05-08
