# Perpetuating Misogyny with Generative AI: How Model Personalization Normalizes Gendered Harm

**URL**: http://arxiv.org/abs/2505.04600v1

## 原始摘要

Open-source text-to-image (TTI) pipelines have become dominant in the
landscape of AI-generated visual content, driven by technological advances that
enable users to personalize models through adapters tailored to specific tasks.
While personalization methods such as LoRA offer unprecedented creative
opportunities, they also facilitate harmful practices, including the generation
of non-consensual deepfakes and the amplification of misogynistic or
hypersexualized content. This study presents an exploratory sociotechnical
analysis of CivitAI, the most active platform for sharing and developing
open-source TTI models. Drawing on a dataset of more than 40 million
user-generated images and over 230,000 models, we find a disproportionate rise
in not-safe-for-work (NSFW) content and a significant number of models intended
to mimic real individuals. We also observe a strong influence of internet
subcultures on the tools and practices shaping model personalizations and
resulting visual media. In response to these findings, we contextualize the
emergence of exploitative visual media through feminist and constructivist
perspectives on technology, emphasizing how design choices and community
dynamics shape platform outcomes. Building on this analysis, we propose
interventions aimed at mitigating downstream harm, including improved content
moderation, rethinking tool design, and establishing clearer platform policies
to promote accountability and consent.


## AI 摘要

该研究对开源文本生成图像（TTI）平台CivitAI进行了社会技术分析，发现平台上存在大量不适宜工作场所（NSFW）的内容和模仿真实人物的模型，同时互联网亚文化对模型个性化工具和实践有显著影响。研究从女权主义和建构主义视角探讨了剥削性视觉内容的产生，指出平台设计选择和社区动态影响了内容走向。为减少潜在危害，研究建议加强内容审核、改进工具设计并制定更清晰的平台政策，以促进责任和用户同意。研究基于超过4000万用户生成图片和23万多个模型的数据集展开。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-08T13:10:26Z
- **目录日期**: 2025-05-08
