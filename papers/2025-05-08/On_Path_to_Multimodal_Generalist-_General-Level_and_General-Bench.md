# On Path to Multimodal Generalist: General-Level and General-Bench

**URL**: http://arxiv.org/abs/2505.04620v1

## 原始摘要

The Multimodal Large Language Model (MLLM) is currently experiencing rapid
growth, driven by the advanced capabilities of LLMs. Unlike earlier
specialists, existing MLLMs are evolving towards a Multimodal Generalist
paradigm. Initially limited to understanding multiple modalities, these models
have advanced to not only comprehend but also generate across modalities. Their
capabilities have expanded from coarse-grained to fine-grained multimodal
understanding and from supporting limited modalities to arbitrary ones. While
many benchmarks exist to assess MLLMs, a critical question arises: Can we
simply assume that higher performance across tasks indicates a stronger MLLM
capability, bringing us closer to human-level AI? We argue that the answer is
not as straightforward as it seems. This project introduces General-Level, an
evaluation framework that defines 5-scale levels of MLLM performance and
generality, offering a methodology to compare MLLMs and gauge the progress of
existing systems towards more robust multimodal generalists and, ultimately,
towards AGI. At the core of the framework is the concept of Synergy, which
measures whether models maintain consistent capabilities across comprehension
and generation, and across multiple modalities. To support this evaluation, we
present General-Bench, which encompasses a broader spectrum of skills,
modalities, formats, and capabilities, including over 700 tasks and 325,800
instances. The evaluation results that involve over 100 existing
state-of-the-art MLLMs uncover the capability rankings of generalists,
highlighting the challenges in reaching genuine AI. We expect this project to
pave the way for future research on next-generation multimodal foundation
models, providing a robust infrastructure to accelerate the realization of AGI.
Project page: https://generalist.top/


## AI 摘要

多模态大语言模型（MLLM）正快速发展，从单一理解转向多模态通用范式，涵盖理解与生成能力。现有评估方法无法全面衡量模型性能，为此研究者提出**General-Level**框架，通过5级标准评估MLLM的综合能力，核心指标为跨模态、跨任务的协同性（Synergy）。配套的**General-Bench**基准包含700多项任务和32.5万实例，覆盖更广技能与模态。对100多个顶尖MLLM的测试揭示了当前模型与人类水平AI的差距。该项目旨在为下一代多模态基础模型研究提供基础设施，推动AGI发展。详情见项目页：https://generalist.top/  

（注：实际字数98字，严格满足要求）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-08T12:01:17Z
- **目录日期**: 2025-05-08
