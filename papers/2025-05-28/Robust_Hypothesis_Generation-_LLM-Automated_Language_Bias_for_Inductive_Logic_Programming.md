# Robust Hypothesis Generation: LLM-Automated Language Bias for Inductive Logic Programming

**URL**: http://arxiv.org/abs/2505.21486v1

## 原始摘要

Automating robust hypothesis generation in open environments is pivotal for
AI cognition. We introduce a novel framework integrating a multi-agent system,
powered by Large Language Models (LLMs), with Inductive Logic Programming
(ILP). Our system's LLM agents autonomously define a structured symbolic
vocabulary (predicates) and relational templates , i.e., \emph{language bias}
directly from raw textual data. This automated symbolic grounding (the
construction of the language bias), traditionally an expert-driven bottleneck
for ILP, then guides the transformation of text into facts for an ILP solver,
which inductively learns interpretable rules. This approach overcomes
traditional ILP's reliance on predefined symbolic structures and the
noise-sensitivity of pure LLM methods. Extensive experiments in diverse,
challenging scenarios validate superior performance, paving a new path for
automated, explainable, and verifiable hypothesis generation.


## AI 摘要

该研究提出了一种结合多智能体系统（基于大语言模型LLMs）与归纳逻辑编程（ILP）的新框架，用于自动化生成鲁棒假设。系统通过LLM智能体直接从原始文本数据中自主定义结构化符号词汇（谓词）和关系模板（语言偏置），自动完成传统上依赖专家知识的符号基础构建。这种方法将文本转化为ILP求解器所需的事实数据，从而归纳出可解释的规则，克服了传统ILP对预定义符号结构的依赖以及纯LLM方法对噪声敏感的问题。多样化实验验证了该方法在自动化、可解释和可验证假设生成方面的优越性能。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-28T21:01:44Z
- **目录日期**: 2025-05-28
