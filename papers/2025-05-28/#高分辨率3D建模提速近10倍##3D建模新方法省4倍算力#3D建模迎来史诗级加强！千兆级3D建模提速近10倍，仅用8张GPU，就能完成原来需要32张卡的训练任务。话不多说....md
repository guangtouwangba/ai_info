# #高分辨率3D建模提速近10倍##3D建模新方法省4倍算力#3D建模迎来史诗级加强！千兆级3D建模提速近10倍，仅用8张GPU，就能完成原来需要32张卡的训练任务。话不多说...

**URL**: https://weibo.com/6105753431/PtURjkdaA

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E9%AB%98%E5%88%86%E8%BE%A8%E7%8E%873D%E5%BB%BA%E6%A8%A1%E6%8F%90%E9%80%9F%E8%BF%9110%E5%80%8D%23&amp;extparam=%23%E9%AB%98%E5%88%86%E8%BE%A8%E7%8E%873D%E5%BB%BA%E6%A8%A1%E6%8F%90%E9%80%9F%E8%BF%9110%E5%80%8D%23" data-hide=""><span class="surl-text">#高分辨率3D建模提速近10倍#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%233D%E5%BB%BA%E6%A8%A1%E6%96%B0%E6%96%B9%E6%B3%95%E7%9C%814%E5%80%8D%E7%AE%97%E5%8A%9B%23&amp;extparam=%233D%E5%BB%BA%E6%A8%A1%E6%96%B0%E6%96%B9%E6%B3%95%E7%9C%814%E5%80%8D%E7%AE%97%E5%8A%9B%23" data-hide=""><span class="surl-text">#3D建模新方法省4倍算力#</span></a><br><br>3D建模迎来史诗级加强！<br><br>千兆级3D建模提速近10倍，仅用8张GPU，就能完成原来需要32张卡的训练任务。<br><br>话不多说，先看一下3D建模效果：【图2】【图3】。如果这么看效果不直观，那就来和其他方法做一下对比：【图4】<br><br>可以看到，和前几列的Trellis、Hunyuan-2.0等方法相比，新方法细节更突出，镂空部分都有模有样，堪称“模玩”级别。<br><br>不卖关子，这就是南京大学、DreamTech等团队，联合推出的Direct3D-S2，它用全新的“空间稀疏注意力（SSA）”机制，把原本又慢又吃显存的高分辨率3D生成任务，来了个大提速——最高能带来3.9倍前向加速和9.6倍反向加速。<br><br>这套方案关键在于三大设计：<br><br>- 空间稀疏注意力SSA：把3D体素按空间划分，分别用压缩模块提取全局信息、选择模块聚焦重点区域、窗口模块整合局部细节，最后用门控机制整合三路信息。相比常规Transformer注意力机制，前向速度提升3.9×，反向提升9.6×，效率大幅飞跃；<br><br>- 稀疏SDF VAE结构：VAE在输入、隐变量和输出层都保持稀疏格式，避免格式转换造成的信息损耗，训练过程更稳定，几何表达也更精准；<br><br>- 高分辨率训练更轻量：原来想训练256³分辨率模型要32张GPU，现在1024³只要8张卡，训练门槛直接降一个量级，让普通实验室也能搞超高精度3D生成。<br><br>它采用的流程也很清晰：【图5】【图6】<br><br>先用SS-VAE把3D Signed Distance Function（SDF，带有距离信息的体素）压缩成稀疏潜变量，再用带SSA机制的SS-DiT（扩散Transformer）从图像出发生成稀疏SDF，最后提取出高质量的3D网格。整个流程端到端打通，自动适配多分辨率训练，支持从256³一路训练到1024³。<br><br>测试表明，Direct3D-S2不仅在速度和显存占用上压倒老牌方法，还在多个主流评测指标上拿下最佳，包括ULIP-2、Uni3D和OpenShape。<br><br>此外，Direct3D-S2的用户主观评分也更高，图像一致性得分达到4.21，整体质量4.17，非常适合游戏、VR、工业建模等实际应用。<br><br>目前项目官网已经上线详细展示，代码将于5月30日正式开源。<br><br>现在可以先试试他们的在线Demo：huggingface.co/spaces/wushuang98/Direct3D-S2-v1.0-demo，体验一下用图片直接生成精细3D模型的感觉。<br><br>项目主页：nju-3dv.github.io/projects/Direct3D-S2/<img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1v8smewvlj31jk0u0qv5.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1v8stfm4zg30qk0ccu13.gif" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1v8srw9nhg30qk0cckjp.gif" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1v8sx1ycmj323k2sx1l0.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i1v8suc08xj30zk0icqil.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1v8svdu0xj30zk0lzdtf.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

南京大学与DreamTech团队联合推出Direct3D-S2，通过创新的"空间稀疏注意力(SSA)"机制，显著提升高分辨率3D建模效率。该方法在保持细节精度的同时，实现前向加速3.9倍、反向加速9.6倍，仅需8张GPU即可完成原需32张卡的1024³分辨率训练。其核心采用SSA模块优化计算、稀疏SDF VAE结构保持信息完整性，在ULIP-2等评测中表现最优，用户评分达4.2分。项目支持从256³到1024³的多分辨率训练，适用于游戏/VR等领域，代码将于5月30日开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-28T08:02:59Z
- **目录日期**: 2025-05-28
