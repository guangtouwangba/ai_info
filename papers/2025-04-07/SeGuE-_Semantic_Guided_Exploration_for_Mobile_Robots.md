# SeGuE: Semantic Guided Exploration for Mobile Robots

**URL**: http://arxiv.org/abs/2504.03629v1

## 原始摘要

The rise of embodied AI applications has enabled robots to perform complex
tasks which require a sophisticated understanding of their environment. To
enable successful robot operation in such settings, maps must be constructed so
that they include semantic information, in addition to geometric information.
In this paper, we address the novel problem of semantic exploration, whereby a
mobile robot must autonomously explore an environment to fully map both its
structure and the semantic appearance of features. We develop a method based on
next-best-view exploration, where potential poses are scored based on the
semantic features visible from that pose. We explore two alternative methods
for sampling potential views and demonstrate the effectiveness of our framework
in both simulation and physical experiments. Automatic creation of high-quality
semantic maps can enable robots to better understand and interact with their
environments and enable future embodied AI applications to be more easily
deployed.


## AI 摘要

本文提出了一种新型的语义探索方法，使移动机器人能自主探索环境，同时构建包含几何和语义信息的地图。该方法基于"最佳下一视点"策略，根据潜在视点可见的语义特征进行评分。研究探索了两种替代性视点采样方法，并通过仿真和物理实验验证了框架的有效性。高质量的语义地图自动创建有助于机器人更好地理解和与环境互动，促进具身AI应用的部署。该技术为需要复杂环境理解的机器人任务提供了解决方案，推动了具身AI在现实场景中的应用。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-07T08:01:08Z
- **目录日期**: 2025-04-07
