# Towards deployment-centric multimodal AI beyond vision and language

**URL**: http://arxiv.org/abs/2504.03603v1

## 原始摘要

Multimodal artificial intelligence (AI) integrates diverse types of data via
machine learning to improve understanding, prediction, and decision-making
across disciplines such as healthcare, science, and engineering. However, most
multimodal AI advances focus on models for vision and language data, while
their deployability remains a key challenge. We advocate a deployment-centric
workflow that incorporates deployment constraints early to reduce the
likelihood of undeployable solutions, complementing data-centric and
model-centric approaches. We also emphasise deeper integration across multiple
levels of multimodality and multidisciplinary collaboration to significantly
broaden the research scope beyond vision and language. To facilitate this
approach, we identify common multimodal-AI-specific challenges shared across
disciplines and examine three real-world use cases: pandemic response,
self-driving car design, and climate change adaptation, drawing expertise from
healthcare, social science, engineering, science, sustainability, and finance.
By fostering multidisciplinary dialogue and open research practices, our
community can accelerate deployment-centric development for broad societal
impact.


## AI 摘要

多模态人工智能（AI）通过整合多种数据类型提升跨领域理解与决策，但目前研究主要集中于视觉和语言模型，且部署仍是关键挑战。作者提出以部署为中心的工作流程，早期纳入部署限制，结合数据和模型优化方法，以提高方案可行性。同时强调深化多模态多层次整合及跨学科协作，突破视觉与语言的局限。研究通过疫情响应、自动驾驶和气候变化三个案例，探讨跨学科共通的挑战，涵盖医疗、工程、金融等领域。倡导开放研究和跨学科对话，以加速可部署AI的发展，扩大社会影响力。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-07T14:01:43Z
- **目录日期**: 2025-04-07
