# #264页Agent论文##一篇论文把智能体拆成人脑模型#一篇264页的顶级机构联合综述，把AI Agent拆成了人脑复刻计划。近日，来自Google DeepMind、微软、斯坦福、Meta...

**URL**: https://weibo.com/6105753431/PmasBrcnI

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23264%E9%A1%B5Agent%E8%AE%BA%E6%96%87%23&amp;extparam=%23264%E9%A1%B5Agent%E8%AE%BA%E6%96%87%23" data-hide=""><span class="surl-text">#264页Agent论文#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%B8%80%E7%AF%87%E8%AE%BA%E6%96%87%E6%8A%8A%E6%99%BA%E8%83%BD%E4%BD%93%E6%8B%86%E6%88%90%E4%BA%BA%E8%84%91%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E4%B8%80%E7%AF%87%E8%AE%BA%E6%96%87%E6%8A%8A%E6%99%BA%E8%83%BD%E4%BD%93%E6%8B%86%E6%88%90%E4%BA%BA%E8%84%91%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#一篇论文把智能体拆成人脑模型#</span></a><br><br>一篇264页的顶级机构联合综述，把AI Agent拆成了人脑复刻计划。<br><br>近日，来自Google DeepMind、微软、斯坦福、MetaGPT团队等机构，系统梳理了“基础智能体”（Foundation Agents）的发展现状。<br><br>研究团队试图回答一个核心问题：如何让AI像人一样思考、学习、决策，甚至合作？<br><br>从这个目标出发，论文提出了一种“类人架构”，试图从人脑的角度重新定义Agent的构造方式。<br><br>这篇文章中，Agent被划分为多个仿人模块——<br><br>-感知系统（Perception）<br>-认知系统（Cognition）<br>-世界模型（World Model）<br>-情绪系统（Emotion）<br>-记忆系统（Memory）<br>-行动系统（Action）<br><br>每个模块各司其职，协同运作，模拟人类在现实世界中的感知与反应。<br><br>文章还指出了AI与人类相比，仍存在的几大短板：<br><br>-缺失情绪：AI无法真正体验愤怒、快乐、同理心，只能模拟行为，缺乏真实感受；<br><br>-记忆不稳定：当前模型的上下文窗口类似短期记忆，而长期记忆依赖RAG（Retrieval-Augmented Generation）或知识图谱等外部插件，这些机制仍面临遗忘、信息不准确、无法实时更新等问题；<br><br>-世界模型简陋：人类可凭直觉与经验推演未来，AI目前主要依靠大量数据进行统计性预测，缺乏真正的因果推理能力。<br><br>此外，Agent若想变得更强，不能只靠外部喂数据，必须具备“自我优化”能力。研究者提出了多种自演化机制：<br><br>-通过AutoML或大语言模型自身进行提示词优化（Prompt Tuning）；<br><br>-结合在线与离线训练，实现边工作边学习；<br><br>-工具学习（Tool Learning）：让Agent掌握并使用新工具以拓展能力边界。<br><br>文中还提出了几大主要的AI安全问题：<br><br>-如何防止幻觉（Hallucination）？<br><br>-如何抵御越狱式攻击（Prompt Injection）？<br><br>-如何避免Agent被滥用于操纵人类、侵犯隐私？<br><br>为此，论文引入了“超级对齐”（Superalignment）和“安全尺度法则”（Safety Scaling Laws）等新概念：模型越强，安全监管就越要提前准备、提前介入。<br><br>这篇综述强调，当前的大语言模型只是推动Agent发展的“引擎”。<br><br>要让AI真正具备人类级别的智能，还需要将感知、记忆、情绪、动机、行动等多个子系统整合起来，并持续迭代进化，而人脑就是最好的蓝图。<br><br>感兴趣的小伙伴可以点击：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhuggingface.co%2Fpapers%2F2504.01990" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i08bybfebpj30qs0xchck.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i08bycdr9uj30sk0l1n7v.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i08bye7cpwj30qu0h2tey.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i08byfvdw1j30r90oq15c.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

这篇264页的综述论文由Google DeepMind、微软等顶级机构联合发表，提出了"基础智能体"(Foundation Agents)的类人架构框架。研究团队将AI Agent拆解为仿人模块：感知、认知、世界模型、情绪、记忆和行动系统，旨在让AI具备类似人类的思考决策能力。论文指出当前AI在情绪体验、记忆稳定性和因果推理等方面仍存在短板，并提出了自优化机制和安全问题解决方案。作者强调，要实现人类级智能，需要整合多个子系统并持续迭代，而人脑结构为此提供了最佳参考模型。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-07T12:03:54Z
- **目录日期**: 2025-04-07
