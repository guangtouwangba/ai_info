# Contextual Agent Security: A Policy for Every Purpose

**URL**: http://arxiv.org/abs/2501.17070v3

## 原始摘要

Judging an action's safety requires knowledge of the context in which the
action takes place. To human agents who act in various contexts, this may seem
obvious: performing an action such as email deletion may or may not be
appropriate depending on the email's content, the goal (e.g., to erase
sensitive emails or to clean up trash), and the type of email address (e.g.,
work or personal). Unlike people, computational systems have often had only
limited agency in limited contexts. Thus, manually crafted policies and user
confirmation (e.g., smartphone app permissions or network access control
lists), while imperfect, have sufficed to restrict harmful actions. However,
with the upcoming deployment of generalist agents that support a multitude of
tasks (e.g., an automated personal assistant), we argue that we must rethink
security designs to adapt to the scale of contexts and capabilities of these
systems. As a first step, this paper explores contextual security in the domain
of agents and proposes contextual agent security (Conseca), a framework to
generate just-in-time, contextual, and human-verifiable security policies.


## AI 摘要

本文探讨了在通用智能代理（如自动化个人助手）时代，传统基于手动策略和用户确认的安全设计已无法适应多任务场景下的复杂情境。作者提出"情境代理安全"（Conseca）框架，通过动态生成即时、情境相关且可人工验证的安全策略，解决行动安全性判断的上下文依赖问题。该研究强调，随着AI系统应用场景的扩展，必须重新设计安全机制以适应其多样化的能力和使用环境，确保像邮件删除等操作能根据内容、目的和账户类型等具体情境做出恰当的安全决策。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-19T02:27:17Z
- **目录日期**: 2025-04-19
