# Readable Twins of Unreadable Models

**URL**: http://arxiv.org/abs/2504.13150v1

## 原始摘要

Creating responsible artificial intelligence (AI) systems is an important
issue in contemporary research and development of works on AI. One of the
characteristics of responsible AI systems is their explainability. In the
paper, we are interested in explainable deep learning (XDL) systems. On the
basis of the creation of digital twins of physical objects, we introduce the
idea of creating readable twins (in the form of imprecise information flow
models) for unreadable deep learning models. The complete procedure for
switching from the deep learning model (DLM) to the imprecise information flow
model (IIFM) is presented. The proposed approach is illustrated with an example
of a deep learning classification model for image recognition of handwritten
digits from the MNIST data set.


## AI 摘要

本文探讨了构建可解释深度学习(XDL)系统的方法，提出为不可读的深度学习模型创建"可读孪生体"的概念。研究者通过建立物理对象的数字孪生，开发了将深度学习模型(DLM)转换为不精确信息流模型(IIFM)的完整流程。这种方法旨在提高AI系统的可解释性，使其更负责任。研究以MNIST手写数字识别的深度学习分类模型为例，展示了如何实现从DLM到IIFM的转换。该方案为解决深度学习模型"黑箱"问题提供了新思路，有助于构建更透明、更可信的AI系统。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-19T23:01:10Z
- **目录日期**: 2025-04-19
