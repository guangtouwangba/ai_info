# #自回归重出江湖##0.5B也能卷图像生成#自回归模型这条老路，在图像生成领域也能通往新世界？复旦视觉与学习实验室和字节Seed团队，推出的SimpleAR，用最传统的“...

**URL**: https://weibo.com/6105753431/PnZKap8Te

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%87%AA%E5%9B%9E%E5%BD%92%E9%87%8D%E5%87%BA%E6%B1%9F%E6%B9%96%23&amp;extparam=%23%E8%87%AA%E5%9B%9E%E5%BD%92%E9%87%8D%E5%87%BA%E6%B1%9F%E6%B9%96%23" data-hide=""><span class="surl-text">#自回归重出江湖#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%230.5B%E4%B9%9F%E8%83%BD%E5%8D%B7%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%23&amp;extparam=%230.5B%E4%B9%9F%E8%83%BD%E5%8D%B7%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%23" data-hide=""><span class="surl-text">#0.5B也能卷图像生成#</span></a><br><br>自回归模型这条老路，在图像生成领域也能通往新世界？<br><br>复旦视觉与学习实验室和字节Seed团队，推出的SimpleAR，用最传统的“Next-token prediction”方式，在0.5B参数规模下做到了1024分辨率图像生成，还打出了文生图的新成绩。<br><br>这波尝试不依赖任何外挂文本编码器，而是用一个纯粹的decoder-only Transformer，同时处理文本和图像token，做到跨模态的高效对齐。<br><br>性能方面，SimpleAR不仅在GenEval上达成0.59的优异分数，还超越了同参数规模的SDv2.1和LlamaGen。虽然在1.5B规模上距离Infinity还有差距，但研究者认为关键在于训练数据和视觉tokenizer的局限，尚有优化空间。<br><br>效率也不含糊。搭配vLLM部署后，生成1024图像只需13.55秒，并通过推断采样进一步压缩生成步数，性能与速度兼顾，甚至在某些点上比MaskGIT还有优势。详情请见： <a href="https://weibo.com/ttarticle/p/show?id=2309405157188904812848" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">纯自回归图像生成模型开源来了，复旦联手字节seed共同捍卫自回归</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0m81u7svqj30pc0e9adi.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

复旦大学与字节Seed团队合作开发的SimpleAR模型，采用纯自回归Transformer架构，仅用0.5B参数就实现了1024分辨率图像生成。该模型通过统一处理文本和图像token实现跨模态对齐，无需外挂文本编码器。在GenEval评测中取得0.59分，超越同规模SDv2.1和LlamaGen。配合vLLM部署后生成仅需13.55秒，通过采样优化进一步压缩步数。研究指出当前限制主要来自训练数据和视觉tokenizer，仍有提升空间。这项工作证明传统自回归方法在图像生成领域仍具竞争力。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-19T16:02:56Z
- **目录日期**: 2025-04-19
