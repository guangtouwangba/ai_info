# COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents

**URL**: http://arxiv.org/abs/2505.23720v1

## 原始摘要

This paper considers a contextual bandit problem involving multiple agents,
where a learner sequentially observes the contexts and the agent's reported
arms, and then selects the arm that maximizes the system's overall reward.
Existing work in contextual bandits assumes that agents truthfully report their
arms, which is unrealistic in many real-life applications. For instance,
consider an online platform with multiple sellers; some sellers may
misrepresent product quality to gain an advantage, such as having the platform
preferentially recommend their products to online users. To address this
challenge, we propose an algorithm, COBRA, for contextual bandit problems
involving strategic agents that disincentivize their strategic behavior without
using any monetary incentives, while having incentive compatibility and a
sub-linear regret guarantee. Our experimental results also validate the
different performance aspects of our proposed algorithm.


## AI 摘要

本文提出了一种针对多智能体情境赌博问题的算法COBRA，解决了现有研究中假设智能体诚实报告行为的局限性。在现实场景（如电商平台）中，智能体可能虚报信息以获取优势。COBRA无需货币激励即可抑制策略性行为，同时保证激励兼容性和次线性遗憾界。实验验证了该算法的各项性能表现。该研究为存在策略性智能体的情境赌博问题提供了实用解决方案。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-31T04:03:02Z
- **目录日期**: 2025-05-31
