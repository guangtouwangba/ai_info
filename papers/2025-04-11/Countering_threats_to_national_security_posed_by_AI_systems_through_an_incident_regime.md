# Countering threats to national security posed by AI systems through an incident regime

**URL**: http://arxiv.org/abs/2503.19887v2

## 原始摘要

Recent progress in AI capabilities has heightened concerns that AI systems
could pose a threat to national security, for example, by making it easier for
malicious actors to perform cyberattacks on critical national infrastructure,
or through loss of control of autonomous AI systems. In parallel, federal
legislators in the US have proposed nascent 'AI incident regimes' to identify
and counter similar threats. In this paper, we consolidate these two trends and
present a proposal for a legally mandated post-deployment AI incident regime
that aims to counter potential national security threats from AI systems. We
start the paper by introducing the concept of 'security-critical' to describe
doctors that pose extreme risks to national security, before arguing that
'security-critical' describes civilian nuclear power, aviation, life science
dual-use research of concern, and frontier AI development. We then present in
detail our AI incident regime proposal, justifying each component of the
proposal by demonstrating its similarity to US domestic incident regimes in
other 'security-critical' sectors. Finally, we sketch a hypothetical scenario
where our proposed AI incident regime deals with an AI cyber incident. Our
proposed AI incident regime is split into three phases. The first phase
revolves around a novel operationalization of what counts as an 'AI incident'
and we suggest that AI providers must create a 'national security case' before
deploying a frontier AI system. The second and third phases spell out that AI
providers should notify a government agency about incidents, and that the
government agency should be involved in amending AI providers' security and
safety procedures, in order to counter future threats to national security.


## AI 摘要

本文提出建立针对AI系统的"部署后事故应对机制"，以应对AI技术发展带来的国家安全威胁。作者首先定义"安全关键领域"（如核能、航空、生命科学和前沿AI开发），并借鉴美国现有行业事故处理机制，设计了三阶段AI事故应对方案：1)部署前沿AI系统前需提交"国家安全论证"并明确事故定义；2)AI供应商须向政府机构报告事故；3)政府机构参与修订安全规程以预防未来威胁。最后通过模拟AI网络攻击场景验证该机制的有效性，旨在通过法律强制手段降低AI系统对国家安全的风险。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-11T02:28:49Z
- **目录日期**: 2025-04-11
