# #7B小模型写好学术论文##AI引用论文不再胡编乱造#学术写作通常需要花费大量精力查询文献引用，而以ChatGPT、GPT-4等为代表的通用大语言模型（LLM）虽然能够生成...

**URL**: https://weibo.com/6105753431/PmLeF5BjY

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%237B%E5%B0%8F%E6%A8%A1%E5%9E%8B%E5%86%99%E5%A5%BD%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%23&amp;extparam=%237B%E5%B0%8F%E6%A8%A1%E5%9E%8B%E5%86%99%E5%A5%BD%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%23" data-hide=""><span class="surl-text">#7B小模型写好学术论文#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23AI%E5%BC%95%E7%94%A8%E8%AE%BA%E6%96%87%E4%B8%8D%E5%86%8D%E8%83%A1%E7%BC%96%E4%B9%B1%E9%80%A0%23&amp;extparam=%23AI%E5%BC%95%E7%94%A8%E8%AE%BA%E6%96%87%E4%B8%8D%E5%86%8D%E8%83%A1%E7%BC%96%E4%B9%B1%E9%80%A0%23" data-hide=""><span class="surl-text">#AI引用论文不再胡编乱造#</span></a><br><br>学术写作通常需要花费大量精力查询文献引用，而以ChatGPT、GPT-4等为代表的通用大语言模型（LLM）虽然能够生成流畅文本，但经常出现“引用幻觉”（Citation Hallucination），即模型凭空捏造文献引用。这种现象严重影响了学术论文的可信度与专业性。<br>现在，加拿大滑铁卢大学与卡内基梅隆大学的华人研究团队，提出了一种名为 ScholarCopilot 的智能学术写作大模型框架，专门针对学术场景，致力于精准地生成带有准确引用的学术文本。【图1】<br>ScholarCopilot与传统方法的区别【图2】<br>传统的检索增强生成（Retrieval-Augmented Generation, RAG）方法采用“先检索、再生成”的静态流程，这种方式存在以下问题：<br>检索与生成过程相互独立，容易导致意图不匹配；<br>无法根据上下文需求动态调整引用策略，影响引用准确性。<br>针对这些局限性，ScholarCopilot提出了一种“边生成、边检索”的动态机制：<br>在生成文本时，模型动态地判断何时需要引用文献，并生成一个特殊的检索信号（[RET]）；<br>随后实时检索学术数据库中的相关文献，将检索到的内容融入后续生成过程；<br>通过联合优化生成任务和检索任务，提升引用的准确度与相关性。<br>简单来说，ScholarCopilot的写作方式更接近人类真实的写作习惯：平时正常撰写论文内容，当需要引用文献时再主动检索相关文献的BibTeX信息插入引用，随后继续撰写下文。同时，模型在撰写后续内容时，也会参考已插入的引用文献，确保生成的文本与引用内容紧密相关。<br>ScholarCopilot的性能表现<br>研究团队以阿里云近期发布的Qwen-2.5-7B模型为基础，使用了50万篇arXiv论文进行训练，并在多个维度上进行了性能评估：<br>引用检索准确性（Top-1 accuracy）达到40.1%，显著超过现有的检索模型：【图3】<br>E5-Mistral-7B-Instruct（15.0%）<br>BM25（9.8%）<br>论文生成质量方面（包括相关性、连贯性、学术严谨性、完整性和创新性），综合得分为16.2（满分25），高于参数量更大的Qwen-2.5-72B-Instruct模型（15.8）和Qwen-2.5-7B-Instruct模型（13.9）。【图4】<br>在一项由10位拥有平均4.2年学术写作经验的学生（5名博士、4名硕士、1名本科生）参与的真人评测中：<br>ScholarCopilot在引用质量上的用户偏好率达到100%；<br>整体实用性偏好率超过70%。【图5】<br>ScholarCopilot的不足与未来方向<br>尽管取得了显著进步，ScholarCopilot仍存在一些局限性。通过上述用户调研，受访者提出了以下几点改进建议：<br>内容生成更全面：<br>模型在生成内容的丰富性与信息全面性方面仍需进一步提升；<br>创新性不足：<br>目前模型在生成创新性想法和研究问题方面表现一般，还有较大改进空间。<br>此外，受访者还建议未来版本可考虑：<br>与主流学术写作平台（如Overleaf）进行更紧密的整合；<br>支持分章节独立生成和任意光标位置的文本预测功能。<br>研究团队表示，这些反馈意见为后续开发提供了明确的改进方向。<br>后续展望<br>ScholarCopilot研究团队希望通过不断优化模型性能、扩展检索数据库和改进用户交互体验，让研究人员在学术写作中能更专注于研究本身，而非繁琐的文献检索与引用管理。<br>当前相关论文、代码与模型已经公开发布，感兴趣的读者可自行了解详细信息，进一步体验与评估该模型的实际表现：<br>论文链接：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fpdf%2F2504.00824" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>项目网站：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Ftiger-ai-lab.github.io%2FScholarCopilot%2F" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0cuaw76dzj30zk0a40w7.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0cuaye9j3j30zk0b4qaz.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0cub4kcxbj30zk0hfgtf.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i0cuayikvqj30zk0b7wkb.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0cub419ixj30zk0gotk8.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

加拿大滑铁卢大学与卡内基梅隆大学团队开发了ScholarCopilot框架，基于7B参数模型（Qwen-2.5-7B），通过"边生成边检索"的动态机制解决大模型学术引用造假问题。该模型在50万篇arXiv论文上训练，引用检索准确率达40.1%，生成质量（16.2/25分）优于72B大模型。用户测试显示其引用质量偏好率100%，整体实用性超70%。当前局限包括内容全面性和创新性不足，未来计划优化模型性能并与Overleaf等平台深度整合。论文和代码已开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-11T10:03:38Z
- **目录日期**: 2025-04-11
