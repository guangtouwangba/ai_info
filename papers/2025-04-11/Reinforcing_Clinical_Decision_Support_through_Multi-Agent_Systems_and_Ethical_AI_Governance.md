# Reinforcing Clinical Decision Support through Multi-Agent Systems and Ethical AI Governance

**URL**: http://arxiv.org/abs/2504.03699v2

## 原始摘要

In the age of data-driven medicine, it is paramount to include explainable
and ethically managed artificial intelligence in explaining clinical decision
support systems to achieve trustworthy and effective patient care. The focus of
this paper is on a new architecture of a multi-agent system for clinical
decision support that uses modular agents to analyze laboratory results, vital
signs, and the clinical context and then integrates these results to drive
predictions and validate outcomes. We describe our implementation with the eICU
database to run lab-analysis-specific agents, vitals-only interpreters, and
contextual reasoners and then run the prediction module and a validation agent.
Everything is a transparent implementation of business logic, influenced by the
principles of ethical AI governance such as Autonomy, Fairness, and
Accountability. It provides visible results that this agent-based framework not
only improves on interpretability and accuracy but also on reinforcing trust in
AI-assisted decisions in an intensive care setting.


## AI 摘要

本文提出了一种基于多智能体系统的临床决策支持架构，通过模块化智能体分别分析实验室结果、生命体征和临床背景，并整合结果进行预测和验证。该框架采用eICU数据库实现，包含实验室分析、生命体征解读和背景推理等专门智能体，以及预测模块和验证智能体。系统遵循伦理AI治理原则（自主性、公平性、问责制），采用透明业务逻辑实现。研究表明，该智能体框架不仅提高了可解释性和准确性，还增强了重症监护环境中对AI辅助决策的信任度，实现了可信赖的患者护理。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-11T12:02:17Z
- **目录日期**: 2025-04-11
