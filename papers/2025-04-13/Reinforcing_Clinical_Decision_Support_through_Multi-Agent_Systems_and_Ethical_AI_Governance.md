# Reinforcing Clinical Decision Support through Multi-Agent Systems and Ethical AI Governance

**URL**: http://arxiv.org/abs/2504.03699v2

## 原始摘要

In the age of data-driven medicine, it is paramount to include explainable
and ethically managed artificial intelligence in explaining clinical decision
support systems to achieve trustworthy and effective patient care. The focus of
this paper is on a new architecture of a multi-agent system for clinical
decision support that uses modular agents to analyze laboratory results, vital
signs, and the clinical context and then integrates these results to drive
predictions and validate outcomes. We describe our implementation with the eICU
database to run lab-analysis-specific agents, vitals-only interpreters, and
contextual reasoners and then run the prediction module and a validation agent.
Everything is a transparent implementation of business logic, influenced by the
principles of ethical AI governance such as Autonomy, Fairness, and
Accountability. It provides visible results that this agent-based framework not
only improves on interpretability and accuracy but also on reinforcing trust in
AI-assisted decisions in an intensive care setting.


## AI 摘要

这篇论文提出了一种新型多智能体临床决策支持系统架构，采用模块化智能体分别分析实验室结果、生命体征和临床背景，然后整合结果进行预测和验证。基于eICU数据库的实现表明，该框架遵循自主性、公平性和问责制等伦理AI原则，通过透明业务逻辑提高了可解释性和准确性。在重症监护场景中，这种基于智能体的方法不仅增强了AI辅助决策的性能，还显著提升了医疗人员对AI系统的信任度。研究强调了在数据驱动医疗时代，可解释且符合伦理的人工智能对实现可信赖患者护理的重要性。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-13T00:25:55Z
- **目录日期**: 2025-04-13
