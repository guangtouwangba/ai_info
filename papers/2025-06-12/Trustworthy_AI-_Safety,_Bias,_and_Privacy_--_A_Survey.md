# Trustworthy AI: Safety, Bias, and Privacy -- A Survey

**URL**: http://arxiv.org/abs/2502.10450v2

## 原始摘要

The capabilities of artificial intelligence systems have been advancing to a
great extent, but these systems still struggle with failure modes,
vulnerabilities, and biases. In this paper, we study the current state of the
field, and present promising insights and perspectives regarding concerns that
challenge the trustworthiness of AI models. In particular, this paper
investigates the issues regarding three thrusts: safety, privacy, and bias,
which hurt models' trustworthiness. For safety, we discuss safety alignment in
the context of large language models, preventing them from generating toxic or
harmful content. For bias, we focus on spurious biases that can mislead a
network. Lastly, for privacy, we cover membership inference attacks in deep
neural networks. The discussions addressed in this paper reflect our own
experiments and observations.


## AI 摘要

这篇论文探讨了当前人工智能系统在可信度方面的三大挑战：安全性、隐私和偏见。在安全性方面，研究聚焦于如何让大语言模型避免生成有害内容；关于偏见，主要分析了误导神经网络的伪相关性偏差；隐私部分则讨论了深度神经网络中的成员推理攻击风险。这些发现基于作者团队的实验和观察，反映了AI系统虽能力强大但仍存在的关键缺陷，为提升AI可信度提供了重要视角。研究强调了解决这些问题的紧迫性，以推动更可靠、公平且安全的人工智能发展。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-12T16:02:14Z
- **目录日期**: 2025-06-12
