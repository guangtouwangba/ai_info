# Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy

**URL**: http://arxiv.org/abs/2506.09958v1

## 原始摘要

Medical Visual Question Answering (MedVQA) is a promising field for
developing clinical decision support systems, yet progress is often limited by
the available datasets, which can lack clinical complexity and visual
diversity. To address these gaps, we introduce Kvasir-VQA-x1, a new,
large-scale dataset for gastrointestinal (GI) endoscopy. Our work significantly
expands upon the original Kvasir-VQA by incorporating 159,549 new
question-answer pairs that are designed to test deeper clinical reasoning. We
developed a systematic method using large language models to generate these
questions, which are stratified by complexity to better assess a model's
inference capabilities. To ensure our dataset prepares models for real-world
clinical scenarios, we have also introduced a variety of visual augmentations
that mimic common imaging artifacts. The dataset is structured to support two
main evaluation tracks: one for standard VQA performance and another to test
model robustness against these visual perturbations. By providing a more
challenging and clinically relevant benchmark, Kvasir-VQA-x1 aims to accelerate
the development of more reliable and effective multimodal AI systems for use in
clinical settings. The dataset is fully accessible and adheres to FAIR data
principles, making it a valuable resource for the wider research community.
Code and data: https://github.com/Simula/Kvasir-VQA-x1 and
https://huggingface.co/datasets/SimulaMet/Kvasir-VQA-x1


## AI 摘要

Kvasir-VQA-x1是一个新的大规模胃肠内窥镜视觉问答数据集，包含159,549个新问答对，旨在测试更深入的临床推理能力。该数据集通过大语言模型系统生成分层复杂度的临床问题，并引入模拟常见成像伪影的视觉增强，以提升模型在真实临床场景中的鲁棒性。支持两个评估方向：标准VQA性能和抗视觉干扰能力测试。该数据集遵循FAIR原则，为开发可靠的多模态临床AI系统提供更具挑战性的基准。数据与代码已开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-12T22:01:47Z
- **目录日期**: 2025-06-12
