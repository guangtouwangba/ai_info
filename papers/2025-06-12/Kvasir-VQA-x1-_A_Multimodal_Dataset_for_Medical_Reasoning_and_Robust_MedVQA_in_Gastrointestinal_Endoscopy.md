# Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy

**URL**: http://arxiv.org/abs/2506.09958v1

## 原始摘要

Medical Visual Question Answering (MedVQA) is a promising field for
developing clinical decision support systems, yet progress is often limited by
the available datasets, which can lack clinical complexity and visual
diversity. To address these gaps, we introduce Kvasir-VQA-x1, a new,
large-scale dataset for gastrointestinal (GI) endoscopy. Our work significantly
expands upon the original Kvasir-VQA by incorporating 159,549 new
question-answer pairs that are designed to test deeper clinical reasoning. We
developed a systematic method using large language models to generate these
questions, which are stratified by complexity to better assess a model's
inference capabilities. To ensure our dataset prepares models for real-world
clinical scenarios, we have also introduced a variety of visual augmentations
that mimic common imaging artifacts. The dataset is structured to support two
main evaluation tracks: one for standard VQA performance and another to test
model robustness against these visual perturbations. By providing a more
challenging and clinically relevant benchmark, Kvasir-VQA-x1 aims to accelerate
the development of more reliable and effective multimodal AI systems for use in
clinical settings. The dataset is fully accessible and adheres to FAIR data
principles, making it a valuable resource for the wider research community.
Code and data: https://github.com/Simula/Kvasir-VQA-x1 and
https://huggingface.co/datasets/SimulaMet/Kvasir-VQA-x1


## AI 摘要

研究人员推出了Kvasir-VQA-x1，这是一个针对胃肠道内窥镜的大规模医学视觉问答数据集，包含159,549个新问答对，旨在测试更深入的临床推理能力。该数据集通过大语言模型生成分层复杂度的临床问题，并引入模拟常见成像伪影的视觉增强，以评估模型在真实临床场景中的表现。Kvasir-VQA-x1支持标准VQA性能和模型鲁棒性两个评估方向，遵循FAIR数据原则，为开发更可靠的多模态AI临床决策系统提供了具有挑战性的基准。数据集已在GitHub和HuggingFace平台开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-12T16:01:56Z
- **目录日期**: 2025-06-12
