# Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy

**URL**: http://arxiv.org/abs/2506.09958v1

## 原始摘要

Medical Visual Question Answering (MedVQA) is a promising field for
developing clinical decision support systems, yet progress is often limited by
the available datasets, which can lack clinical complexity and visual
diversity. To address these gaps, we introduce Kvasir-VQA-x1, a new,
large-scale dataset for gastrointestinal (GI) endoscopy. Our work significantly
expands upon the original Kvasir-VQA by incorporating 159,549 new
question-answer pairs that are designed to test deeper clinical reasoning. We
developed a systematic method using large language models to generate these
questions, which are stratified by complexity to better assess a model's
inference capabilities. To ensure our dataset prepares models for real-world
clinical scenarios, we have also introduced a variety of visual augmentations
that mimic common imaging artifacts. The dataset is structured to support two
main evaluation tracks: one for standard VQA performance and another to test
model robustness against these visual perturbations. By providing a more
challenging and clinically relevant benchmark, Kvasir-VQA-x1 aims to accelerate
the development of more reliable and effective multimodal AI systems for use in
clinical settings. The dataset is fully accessible and adheres to FAIR data
principles, making it a valuable resource for the wider research community.
Code and data: https://github.com/Simula/Kvasir-VQA-x1 and
https://huggingface.co/datasets/SimulaMet/Kvasir-VQA-x1


## AI 摘要

研究人员推出了Kvasir-VQA-x1数据集，这是一个针对胃肠道内窥镜的大规模医学视觉问答数据集。该数据集在原有基础上新增了159,549个测试临床深度推理的问题-答案对，通过大语言模型系统生成并按复杂度分层。数据集引入了模拟常见成像伪影的视觉增强，支持标准VQA性能和模型鲁棒性两个评估方向。Kvasir-VQA-x1旨在推动临床环境中更可靠有效的多模态AI系统发展，遵循FAIR数据原则并完全开放访问。数据集和代码已发布于GitHub和Hugging Face平台。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-12T14:02:14Z
- **目录日期**: 2025-06-12
