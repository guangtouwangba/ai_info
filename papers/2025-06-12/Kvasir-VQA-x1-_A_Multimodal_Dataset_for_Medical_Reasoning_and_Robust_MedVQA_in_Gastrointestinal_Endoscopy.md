# Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy

**URL**: http://arxiv.org/abs/2506.09958v1

## 原始摘要

Medical Visual Question Answering (MedVQA) is a promising field for
developing clinical decision support systems, yet progress is often limited by
the available datasets, which can lack clinical complexity and visual
diversity. To address these gaps, we introduce Kvasir-VQA-x1, a new,
large-scale dataset for gastrointestinal (GI) endoscopy. Our work significantly
expands upon the original Kvasir-VQA by incorporating 159,549 new
question-answer pairs that are designed to test deeper clinical reasoning. We
developed a systematic method using large language models to generate these
questions, which are stratified by complexity to better assess a model's
inference capabilities. To ensure our dataset prepares models for real-world
clinical scenarios, we have also introduced a variety of visual augmentations
that mimic common imaging artifacts. The dataset is structured to support two
main evaluation tracks: one for standard VQA performance and another to test
model robustness against these visual perturbations. By providing a more
challenging and clinically relevant benchmark, Kvasir-VQA-x1 aims to accelerate
the development of more reliable and effective multimodal AI systems for use in
clinical settings. The dataset is fully accessible and adheres to FAIR data
principles, making it a valuable resource for the wider research community.
Code and data: https://github.com/Simula/Kvasir-VQA-x1 and
https://huggingface.co/datasets/SimulaMet/Kvasir-VQA-x1


## AI 摘要

研究人员推出了Kvasir-VQA-x1数据集，这是一个针对胃肠道内窥镜的大规模医学视觉问答数据集。该数据集在原有基础上新增了159,549个问题-答案对，旨在测试更深入的临床推理能力。通过使用大语言模型系统生成分层复杂度的问题，并引入模拟常见成像伪影的视觉增强，该数据集支持标准VQA性能和模型鲁棒性评估。Kvasir-VQA-x1提供了更具挑战性和临床相关性的基准，可促进临床环境中多模态AI系统的开发。该数据集遵循FAIR数据原则，已公开可用。代码和数据见GitHub和Hugging Face链接。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-12T17:02:17Z
- **目录日期**: 2025-06-12
