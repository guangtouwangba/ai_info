# #AI生成30帧视频只需一秒##微软推出高效视频生成框架#视频生成现在都快这个程度了？在A100上用310M模型，实现每秒超30帧自回归视频生成！比如在《我的世界》中，...

**URL**: https://weibo.com/6105753431/PwaHrugO9

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23AI%E7%94%9F%E6%88%9030%E5%B8%A7%E8%A7%86%E9%A2%91%E5%8F%AA%E9%9C%80%E4%B8%80%E7%A7%92%23&amp;extparam=%23AI%E7%94%9F%E6%88%9030%E5%B8%A7%E8%A7%86%E9%A2%91%E5%8F%AA%E9%9C%80%E4%B8%80%E7%A7%92%23" data-hide=""><span class="surl-text">#AI生成30帧视频只需一秒#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BE%AE%E8%BD%AF%E6%8E%A8%E5%87%BA%E9%AB%98%E6%95%88%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%A1%86%E6%9E%B6%23&amp;extparam=%23%E5%BE%AE%E8%BD%AF%E6%8E%A8%E5%87%BA%E9%AB%98%E6%95%88%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%A1%86%E6%9E%B6%23" data-hide=""><span class="surl-text">#微软推出高效视频生成框架#</span></a><br><br>视频生成现在都快这个程度了？<br><br>在A100上用310M模型，实现每秒超30帧自回归视频生成！<br><br>比如在《我的世界》中，下面每个视频在NVIDIA A100 GPU上生成只需约0.48秒。<br><br>这就是微软研究院与北大联合发布的新框架——Next-Frame Diffusion (NFD)。<br><br>通过实现帧内并行采样，帧间自回归的方式，NFD让视频生成在保持较高生成质量的同时，生成效率大幅提升。<br><br>或许不久之后的游戏，就是玩家直接跟模型交互打游戏了，无需通过传统的游戏引擎。<br><br>那么具体是如何做到的？咱们来扒一扒：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1dEhcwTw6WcLcvmNoXJhEA" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">每秒生成超30帧视频，支持实时交互！自回归视频生成新框架刷新生成效率</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i2cdlakd8ig30hs0ad4qq.gif" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i2cdlap5njg30hs0adnpe.gif" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i2cdlah2czg30hs0adqv5.gif" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i2cdmiblkag30hs0adb29.gif" referrerpolicy="no-referrer"><br><br>

## AI 摘要

微软研究院与北京大学联合推出新型视频生成框架Next-Frame Diffusion (NFD)，实现了AI视频生成效率的重大突破。该框架采用帧内并行采样和帧间自回归技术，在NVIDIA A100 GPU上仅需0.48秒即可生成30帧视频（每秒超30帧），同时保持较高生成质量。这一突破性进展为实时交互式视频生成开辟了新可能，未来或可直接通过AI模型而非传统游戏引擎进行游戏交互。目前该技术已在《我的世界》等场景中展示出卓越性能。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-12T04:05:32Z
- **目录日期**: 2025-06-12
