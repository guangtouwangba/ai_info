# #何恺明新作给扩散模型加正则化##将扩散模型与表征学习结合#扩散模型风头正盛，何恺明最新论文也与此相关。研究的是如何把扩散模型和表征学习联系起来——给扩散...

**URL**: https://weibo.com/6105753431/Pwd35F5Zv

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%BD%95%E6%81%BA%E6%98%8E%E6%96%B0%E4%BD%9C%E7%BB%99%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%8A%A0%E6%AD%A3%E5%88%99%E5%8C%96%23&amp;extparam=%23%E4%BD%95%E6%81%BA%E6%98%8E%E6%96%B0%E4%BD%9C%E7%BB%99%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%8A%A0%E6%AD%A3%E5%88%99%E5%8C%96%23" data-hide=""><span class="surl-text">#何恺明新作给扩散模型加正则化#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%B0%86%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E4%B8%8E%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0%E7%BB%93%E5%90%88%23&amp;extparam=%23%E5%B0%86%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E4%B8%8E%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0%E7%BB%93%E5%90%88%23" data-hide=""><span class="surl-text">#将扩散模型与表征学习结合#</span></a><br><br>扩散模型风头正盛，何恺明最新论文也与此相关。<br><br>研究的是如何把扩散模型和表征学习联系起来——<br><br>给扩散模型加上“整理收纳”功能，使其内部特征更加有序，从而生成效果更加自然逼真的图片。【图1】<br><br>具体来说，论文提出了Dispersive Loss——一种即插即用的正则化方法。<br><br>核心思想是，在模型输出的标准回归损失（如去噪）外，引入一个目标函数，用于对模型的中间表示进行正则化。<br><br>这有点类似于对比学习中的排斥效应。但相较于对比学习，其独特的优势在于：<br><br>- 无需正样本对，避免了对比学习中的复杂性； <br>- 具有高度通用性，可以直接应用于现有扩散模型，不需要修改模型结构；<br>- 计算开销低，几乎不增加额外的计算成本；<br>- 与原始损失兼容，不干扰扩散模型原有的回归训练目标，易于在现有框架中集成<br><br>一起来看论文细节：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjjxYNTbdlT5VO05hQMxkkQ" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">何恺明新作：给扩散模型加正则化，无需预训练无需数据增强，超简单实现性能提升</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i2cojis3a1j30xg0c440f.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i2cojk5pzpj30ng0cudio.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

何恺明最新研究提出了一种名为Dispersive Loss的正则化方法，用于改进扩散模型。该方法通过在模型训练过程中对中间特征表示施加约束，使内部特征更加有序，从而提升生成图像的质量。相比对比学习，该方法无需正样本对、计算成本低、通用性强，可直接应用于现有扩散模型而不改变结构。实验表明，这种简单即插即用的正则化方法能有效提升模型性能，且不干扰原有训练目标。研究将扩散模型与表征学习结合，为生成模型优化提供了新思路。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-12T22:02:52Z
- **目录日期**: 2025-06-12
