# PhySense: Principle-Based Physics Reasoning Benchmarking for Large Language Models

**URL**: http://arxiv.org/abs/2505.24823v1

## 原始摘要

Large language models (LLMs) have rapidly advanced and are increasingly
capable of tackling complex scientific problems, including those in physics.
Despite this progress, current LLMs often fail to emulate the concise,
principle-based reasoning characteristic of human experts, instead generating
lengthy and opaque solutions. This discrepancy highlights a crucial gap in
their ability to apply core physical principles for efficient and interpretable
problem solving. To systematically investigate this limitation, we introduce
PhySense, a novel principle-based physics reasoning benchmark designed to be
easily solvable by experts using guiding principles, yet deceptively difficult
for LLMs without principle-first reasoning. Our evaluation across multiple
state-of-the-art LLMs and prompt types reveals a consistent failure to align
with expert-like reasoning paths, providing insights for developing AI systems
with efficient, robust and interpretable principle-based scientific reasoning.


## AI 摘要

大型语言模型(LLMs)在解决复杂科学问题方面取得进展，但仍难以像人类专家那样进行简洁、基于原理的推理。为此，研究者开发了PhySense基准测试，专门评估模型基于物理原理的推理能力。测试显示，当前最先进的LLMs普遍无法像专家那样运用核心原理进行高效、可解释的问题求解，往往产生冗长且不透明的解决方案。这一发现揭示了LLMs在科学推理方面的关键局限，为开发具有高效、稳健和可解释性的基于原理的AI科学推理系统提供了重要见解。(99字)

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-03T01:29:45Z
- **目录日期**: 2025-06-03
