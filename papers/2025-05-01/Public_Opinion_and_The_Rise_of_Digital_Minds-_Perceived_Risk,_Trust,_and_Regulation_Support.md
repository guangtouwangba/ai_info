# Public Opinion and The Rise of Digital Minds: Perceived Risk, Trust, and Regulation Support

**URL**: http://arxiv.org/abs/2504.21849v1

## 原始摘要

Governance institutions must respond to societal risks, including those posed
by generative AI. This study empirically examines how public trust in
institutions and AI technologies, along with perceived risks, shape preferences
for AI regulation. Using the nationally representative 2023 Artificial
Intelligence, Morality, and Sentience (AIMS) survey, we assess trust in
government, AI companies, and AI technologies, as well as public support for
regulatory measures such as slowing AI development or outright bans on advanced
AI. Our findings reveal broad public support for AI regulation, with risk
perception playing a significant role in shaping policy preferences.
Individuals with higher trust in government favor regulation, while those with
greater trust in AI companies and AI technologies are less inclined to support
restrictions. Trust in government and perceived risks significantly predict
preferences for both soft (e.g., slowing development) and strong (e.g., banning
AI systems) regulatory interventions. These results highlight the importance of
public opinion in AI governance. As AI capabilities advance, effective
regulation will require balancing public concerns about risks with trust in
institutions. This study provides a foundational empirical baseline for
policymakers navigating AI governance and underscores the need for further
research into public trust, risk perception, and regulatory strategies in the
evolving AI landscape.


## AI 摘要

这项研究基于2023年人工智能、道德与感知（AIMS）调查，探讨公众对AI监管的偏好。结果显示，公众普遍支持AI监管，风险认知是影响政策偏好的关键因素。信任政府的个体更倾向支持监管，而信任AI公司和技术的个体则更反对限制措施。政府信任度和风险感知能显著预测对软性（如放缓发展）和强硬（如禁止AI系统）监管措施的支持程度。研究表明，有效的AI治理需平衡公众风险担忧与机构信任，为政策制定者提供了重要参考，并强调需进一步研究公众信任、风险认知与监管策略。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-01T05:01:11Z
- **目录日期**: 2025-05-01
