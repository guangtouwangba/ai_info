# Public Opinion and The Rise of Digital Minds: Perceived Risk, Trust, and Regulation Support

**URL**: http://arxiv.org/abs/2504.21849v1

## 原始摘要

Governance institutions must respond to societal risks, including those posed
by generative AI. This study empirically examines how public trust in
institutions and AI technologies, along with perceived risks, shape preferences
for AI regulation. Using the nationally representative 2023 Artificial
Intelligence, Morality, and Sentience (AIMS) survey, we assess trust in
government, AI companies, and AI technologies, as well as public support for
regulatory measures such as slowing AI development or outright bans on advanced
AI. Our findings reveal broad public support for AI regulation, with risk
perception playing a significant role in shaping policy preferences.
Individuals with higher trust in government favor regulation, while those with
greater trust in AI companies and AI technologies are less inclined to support
restrictions. Trust in government and perceived risks significantly predict
preferences for both soft (e.g., slowing development) and strong (e.g., banning
AI systems) regulatory interventions. These results highlight the importance of
public opinion in AI governance. As AI capabilities advance, effective
regulation will require balancing public concerns about risks with trust in
institutions. This study provides a foundational empirical baseline for
policymakers navigating AI governance and underscores the need for further
research into public trust, risk perception, and regulatory strategies in the
evolving AI landscape.


## AI 摘要

这项研究基于2023年AIMS全国性调查数据，探讨公众对AI监管的偏好。结果显示，公众普遍支持AI监管，风险认知是影响监管偏好的关键因素：信任政府的群体更倾向支持监管，而信任AI公司和技术的群体则更反对限制措施。政府信任度和风险感知能显著预测公众对"软性"(如放缓发展)和"强硬"(如禁止系统)监管措施的支持程度。研究表明，有效的AI治理需要平衡公众风险担忧与机构信任，为政策制定者提供了重要参考依据，并指出未来需进一步研究公众信任、风险认知与监管策略的动态关系。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-01T18:01:23Z
- **目录日期**: 2025-05-01
