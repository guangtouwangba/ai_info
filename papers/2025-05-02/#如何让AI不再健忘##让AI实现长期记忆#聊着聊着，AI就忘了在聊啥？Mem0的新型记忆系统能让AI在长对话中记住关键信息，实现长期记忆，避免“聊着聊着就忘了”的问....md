# #如何让AI不再健忘##让AI实现长期记忆#聊着聊着，AI就忘了在聊啥？Mem0的新型记忆系统能让AI在长对话中记住关键信息，实现长期记忆，避免“聊着聊着就忘了”的问...

**URL**: https://weibo.com/6105753431/PpFHibYKn

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%A6%82%E4%BD%95%E8%AE%A9AI%E4%B8%8D%E5%86%8D%E5%81%A5%E5%BF%98%23&amp;extparam=%23%E5%A6%82%E4%BD%95%E8%AE%A9AI%E4%B8%8D%E5%86%8D%E5%81%A5%E5%BF%98%23" data-hide=""><span class="surl-text">#如何让AI不再健忘#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%A9AI%E5%AE%9E%E7%8E%B0%E9%95%BF%E6%9C%9F%E8%AE%B0%E5%BF%86%23&amp;extparam=%23%E8%AE%A9AI%E5%AE%9E%E7%8E%B0%E9%95%BF%E6%9C%9F%E8%AE%B0%E5%BF%86%23" data-hide=""><span class="surl-text">#让AI实现长期记忆#</span></a><br><br>聊着聊着，AI就忘了在聊啥？<br><br>Mem0的新型记忆系统能让AI在长对话中记住关键信息，实现长期记忆，避免“聊着聊着就忘了”的问题。<br><br>虽然大语言模型能生成连贯回复，但固定上下文窗口限制了它们在长时间多轮对话中保持一致性。<br><br>这导致AI会忘记用户偏好、重复提问或与之前确认的事实矛盾，严重影响体验。<br><br>虽然像GPT-4、Claude 3.7和Gemini等模型扩展了上下文长度，但这也并没有真正解决问题，全上下文方法需要处理大量无关信息，增加了计算负担。<br><br>Mem0通过动态提取、整合和检索对话中的关键信息，解决了大语言模型的记忆持久性问题。它能选择性存储重要内容，并在需要时精准检索，类似人类记忆过程。【图1】<br><br>此外，进阶版Mem0g还通过图结构记忆，增强了对复杂关系的建模能力。<br><br>接下来，一起看看这是怎么做到的：<br><br>1. Mem0：基于密集语言编码的记忆系统，采用提取+更新的双阶段架构实现高效对话记忆管理【图2】<br>  - 提取阶段：系统接收一对消息（当前消息和前一条消息），结合对话总结和最近消息序列，通过LLM提取关键信息。<br>  - 更新阶段：系统评估提取的信息与现有记忆的一致性，并通过LLM确定是添加、更新、删除还是忽略这些信息。<br>  - 通过这种方式，Mem0形成轻量化但高响应的记忆存储（单对话仅占7K token）<br><br>2. Mem0g：Mem0的增强版本，通过图结构记忆建模复杂关系【图3】<br>  - 在Mem0的基础上，Mem0g将记忆表示为带标签的有向图，节点代表实体，边代表关系。<br>  - 提取阶段：使用LLM将对话消息转换为实体和关系三元组。<br>  - 更新阶段：通过冲突检测和解决机制，将新信息整合到现有图结构中。<br>  - 检索阶段：采用基于实体和语义三元组的双重检索策略，以处理不同类型的问题。<br><br>基准测试的结果也十分优秀：<br>- 在LOCOMO基准测试中，Mem0单跳和多跳问题上表现卓越，Mem0g在时序推理和开放域问答中领先。【图4】<br><br>- 两套系统与六类记忆系统基线进行了对比评估：Mem0g获得了68.44%的最佳综合LLM-as-a-Judge（J）分数，性能提升7-28%，延迟降低91%。【图5】<br><br>- Mem0延迟最低，Mem0g在速度和效率方面远超其他图结构或RAG系统，完美适配实时场景。【图6】<br><br>Mem0和Mem0g为长期LLM智能体提供了可扩展的记忆架构，对教育/企业/医疗等需要长期记忆的领域来说相当有用。<br><br>附录中还提供了prompt模版，也可以看看～【图7】<br><br>论文地址：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2504.19413" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>项目主页：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmem0.ai%2Fresearch" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>开源仓库：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2Fmem0ai%2Fmem0%2Ftree%2Fmain%2Fevaluation" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0yyz7j3w1j30zw0vk1kx.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0yyz9vd1rj30xi0ebwhw.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0yyzf9z7rj30xw0bdtbk.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0yyzq073aj30ub0msqa8.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i0yz00zismj30ub0msqa8.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i0yyzswunkj31220f0gu5.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i0yyzuq5jcj30m60gvtc1.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

Mem0是一种新型AI记忆系统，通过动态提取、整合和检索关键信息解决大语言模型的"健忘"问题。其采用提取+更新的双阶段架构，仅用7K token存储单对话核心内容。进阶版Mem0g引入图结构记忆，用实体关系三元组建模复杂信息。测试显示：Mem0g在LOCOMO基准上综合性能提升7-28%，延迟降低91%，特别适合教育/医疗等需长期记忆的场景。相比传统全上下文方法，该系统能选择性存储重要信息，显著提升对话一致性并降低计算负担。论文、项目和代码均已开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-02T04:03:27Z
- **目录日期**: 2025-05-02
