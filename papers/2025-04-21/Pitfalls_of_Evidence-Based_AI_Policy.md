# Pitfalls of Evidence-Based AI Policy

**URL**: http://arxiv.org/abs/2502.09618v4

## 原始摘要

Nations across the world are working to govern AI. However, from a technical
perspective, there is uncertainty and disagreement on the best way to do this.
Meanwhile, recent debates over AI regulation have led to calls for
"evidence-based AI policy" which emphasize holding regulatory action to a high
evidentiary standard. Evidence is of irreplaceable value to policymaking.
However, holding regulatory action to too high an evidentiary standard can lead
to systematic neglect of certain risks. In historical policy debates (e.g.,
over tobacco ca. 1965 and fossil fuels ca. 1985) "evidence-based policy"
rhetoric is also a well-precedented strategy to downplay the urgency of action,
delay regulation, and protect industry interests. Here, we argue that if the
goal is evidence-based AI policy, the first regulatory objective must be to
actively facilitate the process of identifying, studying, and deliberating
about AI risks. We discuss a set of 15 regulatory goals to facilitate this and
show that Brazil, Canada, China, the EU, South Korea, the UK, and the USA all
have substantial opportunities to adopt further evidence-seeking policies.


## AI 摘要

各国正努力制定AI监管政策，但技术上仍存在分歧。近期"循证AI政策"呼声渐高，强调高标准证据支持监管。然而，过度依赖证据标准可能导致系统性风险忽视——历史上烟草(1965)和化石燃料(1985)争议就曾以"循证"为由拖延监管。研究指出，真正的循证政策应优先推动AI风险的识别、研究和审议，并提出15项具体监管目标。分析显示，巴西、加拿大、中国、欧盟、韩国、英国和美国都需加强证据导向的政策制定。关键是在防范风险与促进发展间取得平衡。(98字)

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-21T15:02:42Z
- **目录日期**: 2025-04-21
