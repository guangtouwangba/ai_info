# Pitfalls of Evidence-Based AI Policy

**URL**: http://arxiv.org/abs/2502.09618v4

## 原始摘要

Nations across the world are working to govern AI. However, from a technical
perspective, there is uncertainty and disagreement on the best way to do this.
Meanwhile, recent debates over AI regulation have led to calls for
"evidence-based AI policy" which emphasize holding regulatory action to a high
evidentiary standard. Evidence is of irreplaceable value to policymaking.
However, holding regulatory action to too high an evidentiary standard can lead
to systematic neglect of certain risks. In historical policy debates (e.g.,
over tobacco ca. 1965 and fossil fuels ca. 1985) "evidence-based policy"
rhetoric is also a well-precedented strategy to downplay the urgency of action,
delay regulation, and protect industry interests. Here, we argue that if the
goal is evidence-based AI policy, the first regulatory objective must be to
actively facilitate the process of identifying, studying, and deliberating
about AI risks. We discuss a set of 15 regulatory goals to facilitate this and
show that Brazil, Canada, China, the EU, South Korea, the UK, and the USA all
have substantial opportunities to adopt further evidence-seeking policies.


## AI 摘要

当前全球各国正努力制定AI治理政策，但技术上仍存在不确定性和分歧。近期关于AI监管的讨论强调"循证政策"，要求监管行动基于高标准证据。虽然证据对决策至关重要，但过高的证据标准可能导致系统性忽视某些风险。历史上（如1965年烟草、1985年化石燃料争议），"循证政策"常被用作拖延监管、保护行业利益的策略。本文主张，要实现真正的循证AI政策，首要监管目标应是积极促进AI风险的识别、研究和审议。作者提出15项监管建议，并指出巴西、加拿大、中国、欧盟等主要国家均需加强证据收集政策。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-21T12:02:49Z
- **目录日期**: 2025-04-21
