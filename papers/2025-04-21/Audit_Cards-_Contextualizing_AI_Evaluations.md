# Audit Cards: Contextualizing AI Evaluations

**URL**: http://arxiv.org/abs/2504.13839v1

## 原始摘要

AI governance frameworks increasingly rely on audits, yet the results of
their underlying evaluations require interpretation and context to be
meaningfully informative. Even technically rigorous evaluations can offer
little useful insight if reported selectively or obscurely. Current literature
focuses primarily on technical best practices, but evaluations are an
inherently sociotechnical process, and there is little guidance on reporting
procedures and context. Through literature review, stakeholder interviews, and
analysis of governance frameworks, we propose "audit cards" to make this
context explicit. We identify six key types of contextual features to report
and justify in audit cards: auditor identity, evaluation scope, methodology,
resource access, process integrity, and review mechanisms. Through analysis of
existing evaluation reports, we find significant variation in reporting
practices, with most reports omitting crucial contextual information such as
auditors' backgrounds, conflicts of interest, and the level and type of access
to models. We also find that most existing regulations and frameworks lack
guidance on rigorous reporting. In response to these shortcomings, we argue
that audit cards can provide a structured format for reporting key claims
alongside their justifications, enhancing transparency, facilitating proper
interpretation, and establishing trust in reporting.


## AI 摘要

当前AI治理框架依赖审计，但评估结果需要结合背景信息才能有效解读。现有研究多关注技术标准，却忽视了审计作为社会技术过程的特性，缺乏对报告流程和背景的指导。为此，研究者提出"审计卡片"方案，通过文献分析、利益相关者访谈和框架研究，确定了六类必须披露的核心背景信息：审计者身份、评估范围、方法、资源权限、流程完整性和复核机制。分析显示，现有审计报告普遍缺失关键背景（如审计者资质、利益冲突、模型访问权限），且监管框架缺乏报告规范。审计卡片通过结构化呈现核心主张及其依据，可提升透明度并建立信任。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-21T13:07:13Z
- **目录日期**: 2025-04-21
