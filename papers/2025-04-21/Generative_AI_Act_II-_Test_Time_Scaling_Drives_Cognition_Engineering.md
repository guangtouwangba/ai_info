# Generative AI Act II: Test Time Scaling Drives Cognition Engineering

**URL**: http://arxiv.org/abs/2504.13828v1

## 原始摘要

The first generation of Large Language Models - what might be called "Act I"
of generative AI (2020-2023) - achieved remarkable success through massive
parameter and data scaling, yet exhibited fundamental limitations in knowledge
latency, shallow reasoning, and constrained cognitive processes. During this
era, prompt engineering emerged as our primary interface with AI, enabling
dialogue-level communication through natural language. We now witness the
emergence of "Act II" (2024-present), where models are transitioning from
knowledge-retrieval systems (in latent space) to thought-construction engines
through test-time scaling techniques. This new paradigm establishes a
mind-level connection with AI through language-based thoughts. In this paper,
we clarify the conceptual foundations of cognition engineering and explain why
this moment is critical for its development. We systematically break down these
advanced approaches through comprehensive tutorials and optimized
implementations, democratizing access to cognition engineering and enabling
every practitioner to participate in AI's second act. We provide a regularly
updated collection of papers on test-time scaling in the GitHub Repository:
https://github.com/GAIR-NLP/cognition-engineering


## AI 摘要

这篇摘要指出，生成式AI的发展经历了两个阶段：第一代大语言模型（2020-2023）通过大规模参数和数据扩展取得显著成功，但存在知识滞后、浅层推理等局限，主要依赖提示工程进行交互。当前进入"第二幕"（2024起），模型正从潜在空间的知识检索系统转变为通过测试时扩展技术构建的思维引擎，实现基于语言的思维层面连接。作者阐述了认知工程的概念基础和发展时机，通过教程和优化实现系统解析这些先进方法，使更多从业者能参与AI第二阶段的创新。相关论文合集已在GitHub开源。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-21T04:01:41Z
- **目录日期**: 2025-04-21
