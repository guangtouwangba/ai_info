# Readable Twins of Unreadable Models

**URL**: http://arxiv.org/abs/2504.13150v1

## 原始摘要

Creating responsible artificial intelligence (AI) systems is an important
issue in contemporary research and development of works on AI. One of the
characteristics of responsible AI systems is their explainability. In the
paper, we are interested in explainable deep learning (XDL) systems. On the
basis of the creation of digital twins of physical objects, we introduce the
idea of creating readable twins (in the form of imprecise information flow
models) for unreadable deep learning models. The complete procedure for
switching from the deep learning model (DLM) to the imprecise information flow
model (IIFM) is presented. The proposed approach is illustrated with an example
of a deep learning classification model for image recognition of handwritten
digits from the MNIST data set.


## AI 摘要

本文探讨了构建可解释的深度学习系统(XDL)以促进负责任AI发展的问题。作者提出通过创建"可读孪生体"（不精确信息流模型IIFM）来解释不可读的深度学习模型(DLM)，并详细介绍了从DLM转换到IIFM的完整流程。该方法以MNIST手写数字识别的深度学习分类模型为例进行了验证。这一研究为提升AI系统的可解释性提供了新思路，通过建立数字孪生与信息流模型之间的对应关系，使原本难以理解的深度学习模型变得可解释，从而推动负责任AI的发展。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-21T01:28:41Z
- **目录日期**: 2025-04-21
