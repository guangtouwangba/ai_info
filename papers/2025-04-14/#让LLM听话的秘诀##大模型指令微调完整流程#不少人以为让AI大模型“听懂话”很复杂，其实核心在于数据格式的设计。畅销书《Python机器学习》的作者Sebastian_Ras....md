# #让LLM听话的秘诀##大模型指令微调完整流程#不少人以为让AI大模型“听懂话”很复杂，其实核心在于数据格式的设计。畅销书《Python机器学习》的作者Sebastian Ras...

**URL**: https://weibo.com/6105753431/PnepAtkHq

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AE%A9LLM%E5%90%AC%E8%AF%9D%E7%9A%84%E7%A7%98%E8%AF%80%23&amp;extparam=%23%E8%AE%A9LLM%E5%90%AC%E8%AF%9D%E7%9A%84%E7%A7%98%E8%AF%80%23" data-hide=""><span class="surl-text">#让LLM听话的秘诀#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B%23&amp;extparam=%23%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B%23" data-hide=""><span class="surl-text">#大模型指令微调完整流程#</span></a><br><br>不少人以为让AI大模型“听懂话”很复杂，其实核心在于数据格式的设计。<br><br>畅销书《Python机器学习》的作者Sebastian Raschka，用一个小型的decoder-only预训练模型，演示了如何通过instruction fine-tuning（指令微调）让模型变成一个更“听话”的个人助理。【视频】<br><br>Sebastian解释道，预训练模型更像是“会说话的大脑”，但不具备“听从指令”的能力。<br><br>而通过指令微调，模型才能理解任务语境并进行准确执行，这是从基础语言理解迈向解决任务的关键一步。<br><br>视频的主要内容包括以下几个方面：<br><br>1、指令微调的原理：与预训练阶段的无目标预测不同，指令微调通过“监督学习”方式，明确告诉模型该如何根据用户指令生成期望的输出。它的目标是让模型从“语言理解”进化为“任务执行”。<br><br>2、设计训练数据：训练数据采用JSON格式，每条记录包括instruction（任务说明）、input（输入，可为空）和output（预期输出），例如：<br><br>（确定以下单词的正确拼写）{ "instruction": "Identify the correct spelling of the following word", "input": "definately", "output": "definitely" }<br><br>这样的数据只有1100条，但在普通的CPU或GPU上训练仅需几分钟，操作门槛很低。<br><br>3、Prompt格式选择：模型本身并不直接读取JSON格式数据，而是处理纯文本形式的prompt，因此需要先将数据转换。常见的prompt风格有：<br><br>- Alpaca风格：结构清晰，带有“Instruction”、“Input”、“Response”标签，适合教学和理解；<br>- Phi风格：格式紧凑，把instruction和input合并，节省token，更适用于实际部署；<br>- 使用格式转换函数format_input()可以自动处理不同结构和空输入等特殊情况。<br><br>4、 训练细节：<br><br>- 动态padding：根据每个batch中最长样本动态调整，节省资源；<br>- Loss masking：只对response部分计算loss，忽略prompt部分；<br>- 文本结尾处理：避免模型生成无关或混乱的token。<br><br>5、模型评估方式：与传统分类模型不同，指令模型的输出可能有多个“合理答案”。因此评估标准更灵活，如BLEU、ROUGE等文本相似度指标，或直接进行人工评估。<br><br>值得注意的是，我们日常在LLM里输入的内容，其实后台已被系统转成了结构化prompt，只是用户看不到而已。<br><br>这就是为什么prompt也成了一门“玄学”：每家模型厂（OpenAI、Meta、Google）都有自己的一套格式转换风格，而越清晰、越自然的prompt，转换格式后，效果也越好。<br><br>下面是视频时间戳：<br>00:00 7.2准备用于监督指令微调的数据集<br>15:37 7.3将数据组织成训练批次<br>39:17 7.4为指令数据集创建数据加载器<br>46:44 7.5加载预训练的 LLM<br>54:25 7.6使用指令数据对 LLM 进行微调<br>1:14:20 7.7提取和保存响应<br>1:23:56 7.8评估微调后的 LLM<br><br>感兴趣的小伙伴可以点击：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2Frasbt%2FLLMs-from-scratch%2Ftree%2Fmain%2Fch07" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a> <a href="https://video.weibo.com/show?fid=1034:5155347971899415" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_video_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">量子位的微博视频</span></a><br clear="both"><div style="clear: both"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/006Fd7o3ly1i0geky3ni7j30zk0k0wfz.jpg" style="width: 100%"><source src="https://f.video.weibocdn.com/o0/0ys1Hygslx08nt0O9CX60104120kzzbA0E080.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1744628555&amp;ssig=neY3gV%2FNzu&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/wZm26BA9lx08nt0LxDao01041209K4yt0E040.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1744628555&amp;ssig=LfOBte%2Bpwb&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/t8xTNPQ5lx08nt0GVcJa01041205Pvkl0E030.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1744628555&amp;ssig=%2Fc5LkSKt8S&amp;KID=unistore,video"><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5155347971899415" target="_blank" rel="noopener noreferrer">微博视频</a>观看。</p></video>

## AI 摘要

该微博介绍了如何通过指令微调(instruction fine-tuning)让大语言模型(LLM)更好地理解并执行任务。核心要点包括：1)指令微调通过结构化数据(instruction/input/output)将模型从语言理解提升为任务执行；2)训练数据仅需1100条JSON格式样本，在普通CPU/GPU上几分钟即可完成；3)prompt格式选择影响效果，常见有Alpaca(教学用)和Phi(部署用)两种风格；4)训练采用动态padding和loss masking等技术优化效率。作者Sebastian Raschka通过小型模型演示了完整流程，强调数据格式设计是让AI"听话"的关键。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-14T10:03:38Z
- **目录日期**: 2025-04-14
