# Dynamic Epistemic Friction in Dialogue

**URL**: http://arxiv.org/abs/2506.10934v1

## 原始摘要

Recent developments in aligning Large Language Models (LLMs) with human
preferences have significantly enhanced their utility in human-AI collaborative
scenarios. However, such approaches often neglect the critical role of
"epistemic friction," or the inherent resistance encountered when updating
beliefs in response to new, conflicting, or ambiguous information. In this
paper, we define dynamic epistemic friction as the resistance to epistemic
integration, characterized by the misalignment between an agent's current
belief state and new propositions supported by external evidence. We position
this within the framework of Dynamic Epistemic Logic (Van Benthem and Pacuit,
2011), where friction emerges as nontrivial belief-revision during the
interaction. We then present analyses from a situated collaborative task that
demonstrate how this model of epistemic friction can effectively predict belief
updates in dialogues, and we subsequently discuss how the model of belief
alignment as a measure of epistemic resistance or friction can naturally be
made more sophisticated to accommodate the complexities of real-world dialogue
scenarios.


## AI 摘要

该研究探讨了大型语言模型（LLM）与人类偏好对齐时忽视的"认知摩擦"问题，即面对新信息时更新信念的内在阻力。作者提出"动态认知摩擦"概念，定义为智能体当前信念与外部证据支持的新命题之间的错位导致的认知整合阻力，并将其置于动态认知逻辑框架下分析。通过协作任务实验，该模型能有效预测对话中的信念更新。研究还讨论了如何将信念对齐作为认知阻力/摩擦的度量，以更复杂地适应现实对话场景的复杂性。这一理论为改进人机协作中的信念更新机制提供了新视角。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-15T17:03:17Z
- **目录日期**: 2025-06-15
