# #多模态长文本理解有综合标准了##46款模型无一攻克128K难关#多模态长文本理解有综合性的评判标准了！来自香港科技大学、腾讯西雅图AI Lab、爱丁堡大学、Miniml.A...

**URL**: https://weibo.com/6105753431/PtaLto3pc

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%A4%9A%E6%A8%A1%E6%80%81%E9%95%BF%E6%96%87%E6%9C%AC%E7%90%86%E8%A7%A3%E6%9C%89%E7%BB%BC%E5%90%88%E6%A0%87%E5%87%86%E4%BA%86%23&amp;extparam=%23%E5%A4%9A%E6%A8%A1%E6%80%81%E9%95%BF%E6%96%87%E6%9C%AC%E7%90%86%E8%A7%A3%E6%9C%89%E7%BB%BC%E5%90%88%E6%A0%87%E5%87%86%E4%BA%86%23" data-hide=""><span class="surl-text">#多模态长文本理解有综合标准了#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%2346%E6%AC%BE%E6%A8%A1%E5%9E%8B%E6%97%A0%E4%B8%80%E6%94%BB%E5%85%8B128K%E9%9A%BE%E5%85%B3%23&amp;extparam=%2346%E6%AC%BE%E6%A8%A1%E5%9E%8B%E6%97%A0%E4%B8%80%E6%94%BB%E5%85%8B128K%E9%9A%BE%E5%85%B3%23" data-hide=""><span class="surl-text">#46款模型无一攻克128K难关#</span></a><br><br>多模态长文本理解有综合性的评判标准了！<br><br>来自香港科技大学、腾讯西雅图AI Lab、爱丁堡大学、Miniml.AI、英伟达的研究者联合提出了MMLongBench，旨在全面评估多模态模型的长文本理解能力。【图1】<br><br>随着多模态大模型的单次推理的文本窗口快速提升，长上下文视觉-语言模型（Long-Context Vision-Language Models; LCVLMs）应运而生，使模型能够在单次推理中处理数百张图像与较长的交错文本。<br><br>但当前，由于评估多模态长文本的基准测试稀缺，现有的测试集仅关注单个任务，比如大海捞针或者长文档问答。目前尚不清楚现有的模型在长上下文环境下的综合表现，具体在哪些任务上存在短板，以及它们对不同输入长度变化的适应能力究竟如何。<br><br>MMLongBench覆盖5大类型任务的16个不同的数据集，包含13,331个长文本样本，涵盖Visual RAG、大海捞针 (needle-in-a-haystack)、many-shot in-context learning、长文档摘要和长文档VQA。同时，丰富的任务设计兼顾了多样的图像类型，既包括自然图像（如实景照片），也涵盖了各类合成图像（如diffusion生成的图片和PDF文档截图）。<br><br>该数据集还提供了跨模态长度控制：使用image patch和text token来计算上下文长度，严格标准化8K/16K/32K/64K/128K输入长度。<br><br>其评测数据集以及评测代码现已全部开源。<br><br>作者对46个领先的多模态大语言模型进行基准测试，其中包括Gemini-2.5-Pro、Claude-3.7-Sonnet、GPT-4o和Qwen2.5-VL-72B。<br><br>结果显示，无论闭源还是开源模型，在长上下文视觉-语言任务上都面临较大挑战，仍有巨大的提升空间。<br><br>此外，进一步的错误分析表明，(1) OCR能力和 (2) 跨模态检索能力仍然是当前LCVLMs在处理长文本时的瓶颈。<br><br>了解更多，欢迎点击：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FeOUvlVVMu_XPKbFa3IX_Nw" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">多模态长文本理解测评首发：46款模型无一攻克128K难关</span></a><br><br>论文：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2505.10610" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>主页：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fzhaowei-wang-nlp.github.io%2FMMLongBench-page%2F" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>代码：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FEdinburghNLP%2FMMLongBench" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>数据集：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhuggingface.co%2Fdatasets%2FZhaoweiWang%2FMMLongBench" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1i1plb74yq5j30ta0cqn0s.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

香港科技大学、腾讯等机构联合推出首个多模态长文本理解综合评测基准MMLongBench，包含5类任务16个数据集（13,331样本），标准化8K-128K输入长度。测试46款主流模型（包括Gemini-2.5-Pro、GPT-4o等）发现：所有模型均未攻克128K难关，OCR和跨模态检索是主要瓶颈。该基准填补了多模态长文本评估空白，已开源数据集与代码。研究显示当前模型在长上下文视觉-语言任务上仍有显著提升空间。论文及资源链接已发布。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-23T20:03:41Z
- **目录日期**: 2025-05-23
