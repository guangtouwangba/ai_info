# Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework

**URL**: http://arxiv.org/abs/2505.17019v1

## 原始摘要

Metaphorical comprehension in images remains a critical challenge for AI
systems, as existing models struggle to grasp the nuanced cultural, emotional,
and contextual implications embedded in visual content. While multimodal large
language models (MLLMs) excel in basic Visual Question Answer (VQA) tasks, they
struggle with a fundamental limitation on image implication tasks: contextual
gaps that obscure the relationships between different visual elements and their
abstract meanings. Inspired by the human cognitive process, we propose Let
Androids Dream (LAD), a novel framework for image implication understanding and
reasoning. LAD addresses contextual missing through the three-stage framework:
(1) Perception: converting visual information into rich and multi-level textual
representations, (2) Search: iteratively searching and integrating cross-domain
knowledge to resolve ambiguity, and (3) Reasoning: generating context-alignment
image implication via explicit reasoning. Our framework with the lightweight
GPT-4o-mini model achieves SOTA performance compared to 15+ MLLMs on English
image implication benchmark and a huge improvement on Chinese benchmark,
performing comparable with the GPT-4o model on Multiple-Choice Question (MCQ)
and outperforms 36.7% on Open-Style Question (OSQ). Additionally, our work
provides new insights into how AI can more effectively interpret image
implications, advancing the field of vision-language reasoning and human-AI
interaction. Our project is publicly available at
https://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep.


## AI 摘要

AI系统在理解图像隐喻方面仍面临挑战，现有模型难以把握视觉内容中蕴含的文化、情感和上下文含义。为解决这一问题，研究者提出了"Let Androids Dream (LAD)"框架，模仿人类认知过程，通过三阶段处理：感知(将视觉信息转化为多层次文本表示)、搜索(整合跨领域知识消除歧义)和推理(生成上下文对齐的图像含义)。实验表明，LAD框架配合轻量级GPT-4o-mini模型在英文图像理解基准测试中超越15+多模态大模型，在中文测试中表现显著提升，在开放式问题上甚至优于GPT-4o模型36.7%。该研究为AI理解图像隐喻提供了新思路。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-23T03:18:53Z
- **目录日期**: 2025-05-23
