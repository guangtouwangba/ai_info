# SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding

**URL**: http://arxiv.org/abs/2505.17012v1

## 原始摘要

Multimodal large language models (MLLMs) have achieved impressive success in
question-answering tasks, yet their capabilities for spatial understanding are
less explored. This work investigates a critical question: do existing MLLMs
possess 3D spatial perception and understanding abilities? Concretely, we make
the following contributions in this paper: (i) we introduce VGBench, a
benchmark specifically designed to assess MLLMs for visual geometry perception,
e.g., camera pose and motion estimation; (ii) we propose SpatialScore, the most
comprehensive and diverse multimodal spatial understanding benchmark to date,
integrating VGBench with relevant data from the other 11 existing datasets.
This benchmark comprises 28K samples across various spatial understanding
tasks, modalities, and QA formats, along with a carefully curated challenging
subset, SpatialScore-Hard; (iii) we develop SpatialAgent, a novel multi-agent
system incorporating 9 specialized tools for spatial understanding, supporting
both Plan-Execute and ReAct reasoning paradigms; (iv) we conduct extensive
evaluations to reveal persistent challenges in spatial reasoning while
demonstrating the effectiveness of SpatialAgent. We believe SpatialScore will
offer valuable insights and serve as a rigorous benchmark for the next
evolution of MLLMs.


## AI 摘要

本文提出VGBench和SpatialScore两个基准测试，用于评估多模态大语言模型(MLLM)的3D空间感知能力。SpatialScore整合了12个数据集共28K样本，涵盖多种空间理解任务和模态，并包含高难度子集SpatialScore-Hard。同时开发了SpatialAgent多智能体系统，配备9种专用工具，支持两种推理范式。实验表明当前MLLM在空间推理方面仍存在挑战，而SpatialAgent表现优异。该研究为MLLM的空间理解能力提供了系统评估框架，将推动下一代模型的发展。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-23T21:01:24Z
- **目录日期**: 2025-05-23
