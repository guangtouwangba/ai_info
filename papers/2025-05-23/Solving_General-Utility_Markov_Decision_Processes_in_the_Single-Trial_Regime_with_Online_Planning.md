# Solving General-Utility Markov Decision Processes in the Single-Trial Regime with Online Planning

**URL**: http://arxiv.org/abs/2505.15782v1

## 原始摘要

In this work, we contribute the first approach to solve infinite-horizon
discounted general-utility Markov decision processes (GUMDPs) in the
single-trial regime, i.e., when the agent's performance is evaluated based on a
single trajectory. First, we provide some fundamental results regarding policy
optimization in the single-trial regime, investigating which class of policies
suffices for optimality, casting our problem as a particular MDP that is
equivalent to our original problem, as well as studying the computational
hardness of policy optimization in the single-trial regime. Second, we show how
we can leverage online planning techniques, in particular a Monte-Carlo tree
search algorithm, to solve GUMDPs in the single-trial regime. Third, we provide
experimental results showcasing the superior performance of our approach in
comparison to relevant baselines.


## AI 摘要

本研究首次提出了解决无限时域折扣通用效用马尔可夫决策过程(GUMDP)单次试验优化问题的方法。首先分析了单次试验场景下的策略优化基础理论，包括最优策略类别、问题转化及计算复杂度。其次提出利用在线规划技术（特别是蒙特卡洛树搜索算法）求解该问题。实验结果表明，该方法显著优于现有基线模型。该研究填补了GUMDP在单次试验场景下的理论空白，并提供了有效的计算解决方案。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-23T01:29:30Z
- **目录日期**: 2025-05-23
