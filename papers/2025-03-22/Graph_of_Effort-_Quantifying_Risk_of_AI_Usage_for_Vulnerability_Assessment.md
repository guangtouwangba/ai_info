# Graph of Effort: Quantifying Risk of AI Usage for Vulnerability Assessment

**URL**: http://arxiv.org/abs/2503.16392v1

## 原始摘要

With AI-based software becoming widely available, the risk of exploiting its
capabilities, such as high automation and complex pattern recognition, could
significantly increase. An AI used offensively to attack non-AI assets is
referred to as offensive AI.
  Current research explores how offensive AI can be utilized and how its usage
can be classified. Additionally, methods for threat modeling are being
developed for AI-based assets within organizations. However, there are gaps
that need to be addressed. Firstly, there is a need to quantify the factors
contributing to the AI threat. Secondly, there is a requirement to create
threat models that analyze the risk of being attacked by AI for vulnerability
assessment across all assets of an organization. This is particularly crucial
and challenging in cloud environments, where sophisticated infrastructure and
access control landscapes are prevalent. The ability to quantify and further
analyze the threat posed by offensive AI enables analysts to rank
vulnerabilities and prioritize the implementation of proactive countermeasures.
  To address these gaps, this paper introduces the Graph of Effort, an
intuitive, flexible, and effective threat modeling method for analyzing the
effort required to use offensive AI for vulnerability exploitation by an
adversary. While the threat model is functional and provides valuable support,
its design choices need further empirical validation in future work.


## AI 摘要

随着基于AI的软件广泛应用，利用其高自动化和复杂模式识别能力进行攻击的风险显著增加。这种用于攻击非AI资产的AI被称为“进攻性AI”。当前研究探讨了进攻性AI的利用方式及其分类，并开发了针对组织内AI资产的威胁建模方法。然而，仍需量化AI威胁因素，并创建威胁模型以评估组织所有资产被AI攻击的风险，尤其是在复杂的云环境中。本文提出“努力图”（Graph of Effort），一种直观灵活的威胁建模方法，用于分析对手利用进攻性AI进行漏洞利用所需的努力。该方法需进一步实证验证。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-03-22T22:01:58Z
- **目录日期**: 2025-03-22
