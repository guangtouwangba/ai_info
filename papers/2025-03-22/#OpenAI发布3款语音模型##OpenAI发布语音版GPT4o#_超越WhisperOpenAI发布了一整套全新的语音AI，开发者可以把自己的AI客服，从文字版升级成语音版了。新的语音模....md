# #OpenAI发布3款语音模型##OpenAI发布语音版GPT4o# 超越WhisperOpenAI发布了一整套全新的语音AI，开发者可以把自己的AI客服，从文字版升级成语音版了。新的语音模...

**URL**: https://weibo.com/6105753431/PjzE31xe9

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23OpenAI%E5%8F%91%E5%B8%833%E6%AC%BE%E8%AF%AD%E9%9F%B3%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23OpenAI%E5%8F%91%E5%B8%833%E6%AC%BE%E8%AF%AD%E9%9F%B3%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#OpenAI发布3款语音模型#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23OpenAI%E5%8F%91%E5%B8%83%E8%AF%AD%E9%9F%B3%E7%89%88GPT4o%23&amp;extparam=%23OpenAI%E5%8F%91%E5%B8%83%E8%AF%AD%E9%9F%B3%E7%89%88GPT4o%23" data-hide=""><span class="surl-text">#OpenAI发布语音版GPT4o#</span></a> 超越Whisper<br><br>OpenAI发布了一整套全新的语音AI，开发者可以把自己的AI客服，从文字版升级成语音版了。<br><br>新的语音模型包括语音转文字（STT）的GPT-4o-transcribe和GPT-4o-mini-transcribe，以及文字转语音（TTS）的GPT-4o-mini-TTS。<br><br>相比之前的Whisper，新模型识别更精准，语音更自然，还支持自由调节，AI“说话”变得更有情绪了。<br><br>所谓自由调节，指的是模型可以随意调整语气、语调、节奏。<br><br>开发者可以让它“像个疯狂科学家”、“像温柔的客服”，或是“像新闻主播”，让我们听听【视频1】感受一下。<br><br>这些不同语气的Demo网址是OpenAI.fm，用户可以在线体验不同语音风格，或是输入文本，随意调整AI的“个性化”表达。【图2】<br><br>语音识别方面，GPT-4o-transcribe在100多种语言上表现优于Whisper，识别错误率（WER）降到2%-7%，这已经接近了人类的听写水平。<br><br>以后，会议记录、字幕生成、客服等场景的识别能力将大幅提升，误听、乱编问题进一步减少。<br><br>更重要的是，开发者可以用不到10行代码，把文本AI升级成能听、能说的语音助手了，让原本的文字版AI客服，升级成直接和用户对话的AI客服！<br><br>定价方面，新模型延续了Whisper的价格策略：<br><br>• GPT-4o-transcribe：每分钟0.6美分（高精度转录）<br><br>• GPT-4o-mini-transcribe：每分钟0.3美分（更便宜，适合大规模转录）<br><br>• GPT-4o-mini-TTS：每分钟1美分（超高性价比语音合成）<br><br>未来，个性化AI助手、智能客服、语音学习、播客、有声书等领域，或将因此迎来全面升级与变革。<img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1hzolxlahc6j318k0c2aaj.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1hzolv1mzjcj30zk0mcq8o.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3ly1hzolxmbo3pj30zk0k0gmh.jpg" referrerpolicy="no-referrer"><br><br><br clear="both"><div style="clear: both"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/006Fd7o3ly1hzolxlcriej318k0c2aaj.jpg" style="width: 100%"><source src="https://f.video.weibocdn.com/o0/hCLcz5SVlx08mQDZdZm0010412001UTe0E010.mp4?label=mp4_hd&amp;template=1604x434.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1742626958&amp;ssig=hmSnQc81Db&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/U3wqhtMXlx08mQDZmQOY010412001gh40E010.mp4?label=mp4_ld&amp;template=1328x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1742626958&amp;ssig=Tuu2QTS0E7&amp;KID=unistore,video"><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5146651396866072" target="_blank" rel="noopener noreferrer">微博视频</a>观看。</p></video>

## AI 摘要

OpenAI发布了三款新的语音模型，包括语音转文字的GPT-4o-transcribe和GPT-4o-mini-transcribe，以及文字转语音的GPT-4o-mini-TTS。这些模型在语音识别和合成方面表现优于之前的Whisper模型，支持多语言识别，错误率低至2%-7%，接近人类水平。新模型还允许自由调节语气、语调和节奏，使AI语音更具情感和个性化。开发者可以用不到10行代码将文本AI升级为语音助手，适用于会议记录、字幕生成、客服等场景。定价策略延续Whisper，每分钟0.3至1美分。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-03-22T06:03:51Z
- **目录日期**: 2025-03-22
