# A Measure Based Generalizable Approach to Understandability

**URL**: http://arxiv.org/abs/2503.21615v2

## 原始摘要

Successful agent-human partnerships require that any agent generated
information is understandable to the human, and that the human can easily steer
the agent towards a goal. Such effective communication requires the agent to
develop a finer-level notion of what is understandable to the human.
State-of-the-art agents, including LLMs, lack this detailed notion of
understandability because they only capture average human sensibilities from
the training data, and therefore afford limited steerability (e.g., requiring
non-trivial prompt engineering).
  In this paper, instead of only relying on data, we argue for developing
generalizable, domain-agnostic measures of understandability that can be used
as directives for these agents. Existing research on understandability measures
is fragmented, we survey various such efforts across domains, and lay a
cognitive-science-rooted groundwork for more coherent and domain-agnostic
research investigations in future.


## AI 摘要

本文探讨了人机协作中信息可理解性的重要性，指出当前AI系统（包括大语言模型）仅依赖训练数据中的平均人类认知，缺乏细粒度的可理解性评估，导致可操控性有限。作者主张开发通用、领域无关的可理解性度量标准作为AI指导，而非仅依赖数据。通过综述跨领域相关研究，本文以认知科学为基础，为未来更系统、领域无关的可理解性研究奠定了基础。核心观点是：提升AI的可理解性和可操控性需要超越数据驱动，建立普适性评估框架。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-24T03:17:32Z
- **目录日期**: 2025-04-24
