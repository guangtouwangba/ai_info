# A Measure Based Generalizable Approach to Understandability

**URL**: http://arxiv.org/abs/2503.21615v2

## 原始摘要

Successful agent-human partnerships require that any agent generated
information is understandable to the human, and that the human can easily steer
the agent towards a goal. Such effective communication requires the agent to
develop a finer-level notion of what is understandable to the human.
State-of-the-art agents, including LLMs, lack this detailed notion of
understandability because they only capture average human sensibilities from
the training data, and therefore afford limited steerability (e.g., requiring
non-trivial prompt engineering).
  In this paper, instead of only relying on data, we argue for developing
generalizable, domain-agnostic measures of understandability that can be used
as directives for these agents. Existing research on understandability measures
is fragmented, we survey various such efforts across domains, and lay a
cognitive-science-rooted groundwork for more coherent and domain-agnostic
research investigations in future.


## AI 摘要

本文探讨了人机协作中智能体生成信息的可理解性问题。当前主流智能体（包括大语言模型）仅依赖训练数据中的平均人类认知水平，缺乏精细化的可理解性评估能力，导致人工引导困难。作者主张开发通用、领域无关的可理解性衡量标准，而非仅依赖数据驱动。通过跨领域研究综述，本文整合了现有碎片化的可理解性测量方法，并基于认知科学为未来更系统、领域通用的研究奠定了基础。这一工作旨在提升智能体生成信息的可理解性和人工引导效率，减少对复杂提示工程的依赖。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-24T05:02:11Z
- **目录日期**: 2025-04-24
