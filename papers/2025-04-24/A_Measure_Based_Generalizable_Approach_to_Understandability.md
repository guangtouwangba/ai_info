# A Measure Based Generalizable Approach to Understandability

**URL**: http://arxiv.org/abs/2503.21615v2

## 原始摘要

Successful agent-human partnerships require that any agent generated
information is understandable to the human, and that the human can easily steer
the agent towards a goal. Such effective communication requires the agent to
develop a finer-level notion of what is understandable to the human.
State-of-the-art agents, including LLMs, lack this detailed notion of
understandability because they only capture average human sensibilities from
the training data, and therefore afford limited steerability (e.g., requiring
non-trivial prompt engineering).
  In this paper, instead of only relying on data, we argue for developing
generalizable, domain-agnostic measures of understandability that can be used
as directives for these agents. Existing research on understandability measures
is fragmented, we survey various such efforts across domains, and lay a
cognitive-science-rooted groundwork for more coherent and domain-agnostic
research investigations in future.


## AI 摘要

本文探讨了提升人机协作效率的关键在于让AI生成的信息更易被人类理解，并便于人类引导AI达成目标。当前包括大语言模型在内的先进AI系统仅基于训练数据捕捉人类平均认知水平，缺乏细粒度的可理解性评估，导致可引导性受限（如依赖复杂提示工程）。作者主张开发通用、领域无关的可理解性度量标准作为AI指导原则，而非仅依赖数据。通过梳理跨领域碎片化研究，本文以认知科学为基础，为未来构建更统一、领域无关的可理解性研究框架奠定基础。（100字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-24T20:02:06Z
- **目录日期**: 2025-04-24
