# A Measure Based Generalizable Approach to Understandability

**URL**: http://arxiv.org/abs/2503.21615v2

## 原始摘要

Successful agent-human partnerships require that any agent generated
information is understandable to the human, and that the human can easily steer
the agent towards a goal. Such effective communication requires the agent to
develop a finer-level notion of what is understandable to the human.
State-of-the-art agents, including LLMs, lack this detailed notion of
understandability because they only capture average human sensibilities from
the training data, and therefore afford limited steerability (e.g., requiring
non-trivial prompt engineering).
  In this paper, instead of only relying on data, we argue for developing
generalizable, domain-agnostic measures of understandability that can be used
as directives for these agents. Existing research on understandability measures
is fragmented, we survey various such efforts across domains, and lay a
cognitive-science-rooted groundwork for more coherent and domain-agnostic
research investigations in future.


## AI 摘要

本文探讨了人类与AI代理有效合作的关键在于信息可理解性和人类对代理的可引导性。现有AI（如大语言模型）仅依赖训练数据中的平均人类认知，缺乏细粒度可理解性评估，导致引导困难（如依赖复杂提示工程）。作者主张开发通用、领域无关的可理解性衡量标准作为代理指导原则，而非仅依赖数据。通过梳理跨领域碎片化研究，本文以认知科学为基础，为未来更系统、领域无关的可理解性研究奠定基础，旨在提升人机协作中的沟通效率和代理可控性。（100字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-24T12:02:18Z
- **目录日期**: 2025-04-24
