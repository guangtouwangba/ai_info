# #清华面壁开源新模型##0.5B拿下端侧模型新SOTA#端侧性价比之王，清华大学和面壁智能团队开源新模型——MiniCPM 4，提供8B、0.5B两种参数规模，仅使用同级别开源...

**URL**: https://weibo.com/6105753431/PvU9ow64l

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E6%B8%85%E5%8D%8E%E9%9D%A2%E5%A3%81%E5%BC%80%E6%BA%90%E6%96%B0%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E6%B8%85%E5%8D%8E%E9%9D%A2%E5%A3%81%E5%BC%80%E6%BA%90%E6%96%B0%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#清华面壁开源新模型#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%230.5B%E6%8B%BF%E4%B8%8B%E7%AB%AF%E4%BE%A7%E6%A8%A1%E5%9E%8B%E6%96%B0SOTA%23&amp;extparam=%230.5B%E6%8B%BF%E4%B8%8B%E7%AB%AF%E4%BE%A7%E6%A8%A1%E5%9E%8B%E6%96%B0SOTA%23" data-hide=""><span class="surl-text">#0.5B拿下端侧模型新SOTA#</span></a><br><br>端侧性价比之王，清华大学和面壁智能团队开源新模型——<br><br>MiniCPM 4，提供8B、0.5B两种参数规模，仅使用同级别开源模型22%的训练开销，就达到了同级别最优性能。【图1】<br><br>MiniCPM4-8B是开源首个开源的原生稀疏模型，5%的极高稀疏度加持，让长文本、深思考在端侧真正跑起来。<br><br>在MMLU、CEval、MATH500、HumanEval等基准测试中，以仅22%的训练开销，性能比肩 Qwen-3-8B，超越Gemma-3-12B。<br><br>MiniCPM4-0.5B在性能上，也展现出以小博大——在MMLU、CEval、BBH、HumanEval等基准测试中，MiniCPM4.0 -0.5B性能超越同级的Qwen-3-0.6B、Llama 3.2、Gemma3，并通过原生QAT技术实现几乎不掉点的int4量化以及600Token/s的极速推理速度。<br><br>在常见端侧芯片，比如Jetson AGX Orin与RTX 4090上，MiniCPM 4可实现长文本处理的5倍常规加速与极限场景下的百倍加速。<br><br>请看VCR【视频2】<br><br>目前团队已公开发布技术报告，该模型在模型架构、推理系统、数据治理与训练算法四个层面进行了系统级创新。【图3】<br><br>以下是技术详情：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_d8yEfpkaqULxir6M3Wo2Q" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">0.5B以小搏大拿下端侧模型新SOTA：4090可跑，长文本处理5倍常规加速丨清华&amp;面壁开源</span></a><br><br>Github链接：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2Fopenbmb%2Fminicpm" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a> <br>技术报告链接：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FOpenBMB%2FMiniCPM%2Fblob%2Fmain%2Freport%2FMiniCPM_4_Technical_Report.pdf" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a> <br>Huggingface链接：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fopenbmb%2Fminicpm-4-6841ab29d180257e940baa9b" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a> <br>Model Scope链接：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fwww.modelscope.cn%2Fcollections%2FMiniCPM-4-ec015560e8c84d" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3ly1i2ad36abvpj30zk0ezn40.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3ly1i2ad3ivo8jj31hc0u0aat.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3ly1i2ad1vskdnj30zk0mm484.jpg" referrerpolicy="no-referrer"><br><br><br clear="both"><div style="clear: both"></div><video controls="controls" poster="https://tvax2.sinaimg.cn/orj480/006Fd7o3ly1i2ad3jc6erj31hc0u0aat.jpg" style="width: 100%"><source src="https://f.video.weibocdn.com/o0/3uCJEUyclx08oVZzQqE8010412007U7I0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1749600139&amp;ssig=sWhQOYDeir&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/zoT9hGOnlx08oVZziCeA010412003NXM0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1749600139&amp;ssig=t1IwflLF1C&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/GMWtLHtjlx08oVZyU3Di010412002iP40E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1749600139&amp;ssig=Ia0CQdKnu2&amp;KID=unistore,video"><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5176039651868706" target="_blank" rel="noopener noreferrer">微博视频</a>观看。</p></video>

## AI 摘要

清华大学与面壁智能团队开源了MiniCPM 4系列端侧模型，包含8B和0.5B两种参数规模。该模型以仅22%的训练开销达到同级别最优性能，其中8B版本是首个开源的原生稀疏模型，支持高效长文本处理；0.5B版本在多项基准测试中超越同级模型，并实现极速推理（600Token/s）。在端侧芯片（如Jetson AGX Orin）上，长文本处理速度提升5倍，极限场景加速达百倍。技术报告详述了模型架构、推理系统等四方面创新，相关资源已发布于GitHub、Hugging Face等平台。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-10T23:03:14Z
- **目录日期**: 2025-06-10
