# Visual Graph Arena: Evaluating Visual Conceptualization of Vision and Multimodal Large Language Models

**URL**: http://arxiv.org/abs/2506.06242v1

## 原始摘要

Recent advancements in multimodal large language models have driven
breakthroughs in visual question answering. Yet, a critical gap persists,
`conceptualization'-the ability to recognize and reason about the same concept
despite variations in visual form, a basic ability of human reasoning. To
address this challenge, we introduce the Visual Graph Arena (VGA), a dataset
featuring six graph-based tasks designed to evaluate and improve AI systems'
capacity for visual abstraction. VGA uses diverse graph layouts (e.g.,
Kamada-Kawai vs. planar) to test reasoning independent of visual form.
Experiments with state-of-the-art vision models and multimodal LLMs reveal a
striking divide: humans achieved near-perfect accuracy across tasks, while
models totally failed on isomorphism detection and showed limited success in
path/cycle tasks. We further identify behavioral anomalies suggesting
pseudo-intelligent pattern matching rather than genuine understanding. These
findings underscore fundamental limitations in current AI models for visual
understanding. By isolating the challenge of representation-invariant
reasoning, the VGA provides a framework to drive progress toward human-like
conceptualization in AI visual models. The Visual Graph Arena is available at:
\href{https://vga.csail.mit.edu/}{vga.csail.mit.edu}


## AI 摘要

该研究介绍了视觉图竞技场(VGA)数据集，包含6个基于图的任务，用于评估AI系统在视觉抽象概念化方面的能力。研究发现，人类在各项任务中表现近乎完美，而当前最先进的视觉模型和多模态大语言模型在图同构检测上完全失败，在路径/循环任务中表现有限。结果表明AI系统存在伪智能模式匹配而非真正理解的问题，凸显了现有模型在视觉概念化方面的根本局限。VGA通过分离表征不变推理的挑战，为推进AI视觉模型实现类人概念化提供了框架。数据集已公开：vga.csail.mit.edu

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-06-10T01:28:45Z
- **目录日期**: 2025-06-10
