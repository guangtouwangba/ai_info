# Revisiting Adversarial Perception Attacks and Defense Methods on Autonomous Driving Systems

**URL**: http://arxiv.org/abs/2505.11532v2

## 原始摘要

Autonomous driving systems (ADS) increasingly rely on deep learning-based
perception models, which remain vulnerable to adversarial attacks. In this
paper, we revisit adversarial attacks and defense methods, focusing on road
sign recognition and lead object detection and prediction (e.g., relative
distance). Using a Level-2 production ADS, OpenPilot by Comma$.$ai, and the
widely adopted YOLO model, we systematically examine the impact of adversarial
perturbations and assess defense techniques, including adversarial training,
image processing, contrastive learning, and diffusion models. Our experiments
highlight both the strengths and limitations of these methods in mitigating
complex attacks. Through targeted evaluations of model robustness, we aim to
provide deeper insights into the vulnerabilities of ADS perception systems and
contribute guidance for developing more resilient defense strategies.


## AI 摘要

本文研究了自动驾驶系统（ADS）中基于深度学习的感知模型对抗攻击的脆弱性及防御方法。以Comma.ai的OpenPilot（L2级ADS）和YOLO模型为例，分析了对抗扰动对路标识别和前方物体检测/预测（如相对距离）的影响，并评估了对抗训练、图像处理、对比学习和扩散模型等防御技术的效果。实验揭示了这些方法在抵御复杂攻击时的优势与局限。通过针对性评估模型鲁棒性，研究旨在深入理解ADS感知系统的漏洞，并为开发更有效的防御策略提供指导。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-26T19:02:05Z
- **目录日期**: 2025-05-26
