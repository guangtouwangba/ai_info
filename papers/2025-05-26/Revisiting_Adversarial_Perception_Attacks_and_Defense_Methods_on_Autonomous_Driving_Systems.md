# Revisiting Adversarial Perception Attacks and Defense Methods on Autonomous Driving Systems

**URL**: http://arxiv.org/abs/2505.11532v2

## 原始摘要

Autonomous driving systems (ADS) increasingly rely on deep learning-based
perception models, which remain vulnerable to adversarial attacks. In this
paper, we revisit adversarial attacks and defense methods, focusing on road
sign recognition and lead object detection and prediction (e.g., relative
distance). Using a Level-2 production ADS, OpenPilot by Comma$.$ai, and the
widely adopted YOLO model, we systematically examine the impact of adversarial
perturbations and assess defense techniques, including adversarial training,
image processing, contrastive learning, and diffusion models. Our experiments
highlight both the strengths and limitations of these methods in mitigating
complex attacks. Through targeted evaluations of model robustness, we aim to
provide deeper insights into the vulnerabilities of ADS perception systems and
contribute guidance for developing more resilient defense strategies.


## AI 摘要

本文研究了自动驾驶系统(ADS)中基于深度学习的感知模型面临的对抗攻击问题，重点关注道路标志识别和前方物体检测预测(如相对距离)。通过使用Comma.ai的OpenPilot系统和YOLO模型，系统评估了对抗扰动的影响，并测试了对抗训练、图像处理、对比学习和扩散模型等防御方法。实验揭示了这些方法在应对复杂攻击时的优缺点。研究旨在深入理解ADS感知系统的脆弱性，为开发更具韧性的防御策略提供指导。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-26T20:02:14Z
- **目录日期**: 2025-05-26
