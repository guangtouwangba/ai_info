# Embracing Contradiction: Theoretical Inconsistency Will Not Impede the Road of Building Responsible AI Systems

**URL**: http://arxiv.org/abs/2505.18139v1

## 原始摘要

This position paper argues that the theoretical inconsistency often observed
among Responsible AI (RAI) metrics, such as differing fairness definitions or
tradeoffs between accuracy and privacy, should be embraced as a valuable
feature rather than a flaw to be eliminated. We contend that navigating these
inconsistencies, by treating metrics as divergent objectives, yields three key
benefits: (1) Normative Pluralism: Maintaining a full suite of potentially
contradictory metrics ensures that the diverse moral stances and stakeholder
values inherent in RAI are adequately represented. (2) Epistemological
Completeness: The use of multiple, sometimes conflicting, metrics allows for a
more comprehensive capture of multifaceted ethical concepts, thereby preserving
greater informational fidelity about these concepts than any single, simplified
definition. (3) Implicit Regularization: Jointly optimizing for theoretically
conflicting objectives discourages overfitting to one specific metric, steering
models towards solutions with enhanced generalization and robustness under
real-world complexities. In contrast, efforts to enforce theoretical
consistency by simplifying or pruning metrics risk narrowing this value
diversity, losing conceptual depth, and degrading model performance. We
therefore advocate for a shift in RAI theory and practice: from getting trapped
in inconsistency to characterizing acceptable inconsistency thresholds and
elucidating the mechanisms that permit robust, approximated consistency in
practice.


## AI 摘要

这篇立场论文主张，负责任人工智能（RAI）指标间的理论不一致性（如公平性定义的差异或准确性与隐私的权衡）应被视为优势而非缺陷。作者提出，通过将指标视为多元目标，这种不一致性可带来三大益处：(1) 保持价值多样性（规范性多元主义）；(2) 更全面捕捉复杂伦理概念（认识论完整性）；(3) 避免单一指标过拟合，提升模型泛化能力（隐式正则化）。相比强行统一指标导致价值窄化，论文呼吁转变范式：界定可接受的不一致阈值，探索实践中实现稳健近似一致的机制。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-26T13:09:11Z
- **目录日期**: 2025-05-26
