# Embracing Contradiction: Theoretical Inconsistency Will Not Impede the Road of Building Responsible AI Systems

**URL**: http://arxiv.org/abs/2505.18139v1

## 原始摘要

This position paper argues that the theoretical inconsistency often observed
among Responsible AI (RAI) metrics, such as differing fairness definitions or
tradeoffs between accuracy and privacy, should be embraced as a valuable
feature rather than a flaw to be eliminated. We contend that navigating these
inconsistencies, by treating metrics as divergent objectives, yields three key
benefits: (1) Normative Pluralism: Maintaining a full suite of potentially
contradictory metrics ensures that the diverse moral stances and stakeholder
values inherent in RAI are adequately represented. (2) Epistemological
Completeness: The use of multiple, sometimes conflicting, metrics allows for a
more comprehensive capture of multifaceted ethical concepts, thereby preserving
greater informational fidelity about these concepts than any single, simplified
definition. (3) Implicit Regularization: Jointly optimizing for theoretically
conflicting objectives discourages overfitting to one specific metric, steering
models towards solutions with enhanced generalization and robustness under
real-world complexities. In contrast, efforts to enforce theoretical
consistency by simplifying or pruning metrics risk narrowing this value
diversity, losing conceptual depth, and degrading model performance. We
therefore advocate for a shift in RAI theory and practice: from getting trapped
in inconsistency to characterizing acceptable inconsistency thresholds and
elucidating the mechanisms that permit robust, approximated consistency in
practice.


## AI 摘要

这篇立场论文认为，负责任人工智能（RAI）指标间常见的理论不一致性（如公平性定义的差异或准确性与隐私的权衡）应被视为有价值的特征而非缺陷。作者提出，通过将指标视为不同目标来处理这些矛盾可带来三大优势：(1) 保持规范多元性，容纳不同道德立场；(2) 实现认识论完整性，更全面捕捉伦理概念；(3) 通过隐式正则化提升模型泛化能力。相反，强行统一指标会削弱价值多样性。因此建议RAI实践应转向界定可接受的不一致性阈值，而非追求理论一致性。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-26T18:01:13Z
- **目录日期**: 2025-05-26
