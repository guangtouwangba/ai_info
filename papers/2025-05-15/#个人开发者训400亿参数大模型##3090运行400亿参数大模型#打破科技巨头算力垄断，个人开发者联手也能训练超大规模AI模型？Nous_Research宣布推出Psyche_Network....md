# #个人开发者训400亿参数大模型##3090运行400亿参数大模型#打破科技巨头算力垄断，个人开发者联手也能训练超大规模AI模型？Nous Research宣布推出Psyche Network...

**URL**: https://weibo.com/6105753431/PrX40rH2O

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E4%B8%AA%E4%BA%BA%E5%BC%80%E5%8F%91%E8%80%85%E8%AE%AD400%E4%BA%BF%E5%8F%82%E6%95%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E4%B8%AA%E4%BA%BA%E5%BC%80%E5%8F%91%E8%80%85%E8%AE%AD400%E4%BA%BF%E5%8F%82%E6%95%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#个人开发者训400亿参数大模型#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%233090%E8%BF%90%E8%A1%8C400%E4%BA%BF%E5%8F%82%E6%95%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%23&amp;extparam=%233090%E8%BF%90%E8%A1%8C400%E4%BA%BF%E5%8F%82%E6%95%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#3090运行400亿参数大模型#</span></a><br><br>打破科技巨头算力垄断，个人开发者联手也能训练超大规模AI模型？<br><br>Nous Research宣布推出Psyche Network，可以将全球算力整合起来训练强大的人工智能。【图1】<br><br>Psyche是一个基于Deepseek的V3 MLA架构的去中心化训练网络，测试网首次启动时直接对40B参数LLM进行预训练，可以在单个H/DGX上训练，并在3090 GPU上运行。【图2】<br><br>以往类似规模的模型训练往往需要耗费大量的资源和时间，并且通常是由大型科技公司或专业研究机构凭借其雄厚的资金和算力优势来完成的。<br><br>Psyche的出现让个人和小团体也可获取资源创建独特大规模模型。【图3】<br><br>对此，有网友表示，Nous Research有潜力成为新的前沿AI实验室。【图4】<br><br>在传统AI训练中，数据需在中心服务器与分布式GPU之间高频传输，带宽不足会导致GPU利用率暴跌。<br><br>2024年Nous研发的DisTrO分布式训练优化器，通过梯度压缩（仅传输关键参数更新）和异步更新策略，将跨节点通信的数据量降低90%以上，突破了训练过程中的带宽限制，使得训练可以去中心化。【图5】<br><br>Psyche创建了一个自定义的点对点网络堆栈，用于协调全球分布式GPU运行DisTrO。<br><br>这个基于P2P（点对点）协议的专用网络层，无需依赖中心化服务器协调，全球GPU可直接通过加密通道交换梯度数据。<br><br>这一设计彻底摆脱了对传统云服务商高带宽网络的依赖，即使是家用宽带连接的GPU，也能稳定参与训练。<br><br>系统架构【图6】<br><br>Psyche网络架构有三个主要部分：<br><br>coordinator：协调器，存储有关训练运行状态和参与者列表的元数据。处理一轮训练中每个阶段之间的转换，且负责为运行中的所有客户端提供同步点。<br><br>clients：客户端，负责训练、见证和验证。每个客户端都保持自身状态与协调器同步。<br><br>data provider：负责提供训练所需的数据。可以是本地的也可以是HTTP或 CP提供者。<br><br>此前互联网公开的大规模预训练多由Meta、Google等巨头主导（如LLaMA 2的700亿参数模型），Psyche以去中心化模式实现同等级别训练。【图7】<br><br>Psyche首次测试网运行使用的是Deepseek的V3 MLA架构。<br><br>MLA通过低秩联合压缩键值和矩阵分解技术，降低计算复杂度与内存占用，使 400 亿参数大语言模型在有限算力下高效训练。<br><br>多头注意力机制与潜空间表示学习相结合，提升模型语言理解与生成能力；并且，旋转位置嵌入的运用，有效解决长序列位置依赖问题，从多维度保障了训练的高效性与模型性能的优质性。<br><br>数据集：使用了FineWeb（14T）、去除部分不常见语言的FineWeb-2（4T）和The Stack v2（1T），些数据集涵盖丰富信息，为模型训练提供了有力支持。<br><br>分布式训练策略：<br><br>- 模型并行与数据并行结合：将400亿参数拆解为128个分片，分布在不同节点进行 “模型并行” 训练，同时每个节点处理独立的数据批次（“数据并行”），通过DisTrO优化器同步梯度更新。  <br>- 动态自适应批量大小：根据节点网络延迟自动调整每个批次的训练数据量（如高延迟节点使用较小批次，减少等待时间），使全局训练效率提升25%。  <br> <br>随着AI模型参数规模呈指数级增长，传统集中式训练模式正面临算力垄断、成本高昂和扩展性瓶颈的严峻挑战。<br><br>分布式训练的崛起，正在彻底改写这一格局。<br><br>就在几天前，Prime Intellect发布了首个分布式RL训练模型INTELLEC-2，引起了广泛关注。【图8】<br><br>Nous Research也称Psyche初始训练只是起点，后续计划整合监督微调、强化学习等完整的训练后阶段工作，以及推理和其他可并行工作负载。【图9】<br><br>谁能站稳分布式训练擂台？当然，我们期待更多更优秀的成果～<br><br>感兴趣的小伙伴可以到官方查看更加详细的内容。<br><br>博客：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fnousresearch.com%2Fnous-psyche%2F" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>训练仪表板：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fpsyche.network" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>代码：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FPsycheFoundation%2Fpsyche" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>文档：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fdocs.psyche.network" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>论坛：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fforum.psyche.network" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>HuggingFace：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhuggingface.co%2FPsycheFoundation" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1gawnvl0aj30zk0aigrc.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1gawoap6ij30na0k0wlw.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1gawmc85xj30zk06575n.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1i1gawocexwj30zk0e3q7h.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1gawnvi15j30zk0ae789.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1gawnqyamj30zk0d9tct.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1gawr01l5j30k00kbjuc.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3gy1i1gawmd3rpj30zk06575n.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1i1gawo4jzcj30k00ki0z7.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

Nous Research推出Psyche Network，这是一个去中心化AI训练网络，能让个人开发者和小团队训练400亿参数大模型。Psyche基于Deepseek V3 MLA架构，通过梯度压缩和异步更新策略（DisTrO优化器）降低90%通信量，使3090 GPU也能参与训练。它采用P2P网络协调全球分布式GPU，无需依赖中心化云服务。测试网使用FineWeb等数据集，结合模型并行和数据并行策略，动态调整批量大小以提升效率。这一突破有望打破科技巨头的算力垄断，推动分布式AI训练发展。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-15T15:04:08Z
- **目录日期**: 2025-05-15
