# Detecting Multimedia Generated by Large AI Models: A Survey

**URL**: http://arxiv.org/abs/2402.00045v5

## 原始摘要

The rapid advancement of Large AI Models (LAIMs), particularly diffusion
models and large language models, has marked a new era where AI-generated
multimedia is increasingly integrated into various aspects of daily life.
Although beneficial in numerous fields, this content presents significant
risks, including potential misuse, societal disruptions, and ethical concerns.
Consequently, detecting multimedia generated by LAIMs has become crucial, with
a marked rise in related research. Despite this, there remains a notable gap in
systematic surveys that focus specifically on detecting LAIM-generated
multimedia. Addressing this, we provide the first survey to comprehensively
cover existing research on detecting multimedia (such as text, images, videos,
audio, and multimodal content) created by LAIMs. Specifically, we introduce a
novel taxonomy for detection methods, categorized by media modality, and
aligned with two perspectives: pure detection (aiming to enhance detection
performance) and beyond detection (adding attributes like generalizability,
robustness, and interpretability to detectors). Additionally, we have presented
a brief overview of generation mechanisms, public datasets, online detection
tools, and evaluation metrics to provide a valuable resource for researchers
and practitioners in this field. Most importantly, we offer a focused analysis
from a social media perspective to highlight their broader societal impact.
Furthermore, we identify current challenges in detection and propose directions
for future research that address unexplored, ongoing, and emerging issues in
detecting multimedia generated by LAIMs. Our aim for this survey is to fill an
academic gap and contribute to global AI security efforts, helping to ensure
the integrity of information in the digital realm. The project link is
https://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey.


## AI 摘要

随着大型AI模型（LAIMs）的快速发展，AI生成的多媒体内容日益普及，但也带来滥用、社会风险和伦理问题。本文首次系统综述了针对LAIM生成的多媒体（如文本、图像、视频、音频和多模态内容）的检测方法，提出了一种基于媒体模态的新分类法，涵盖纯检测（提升检测性能）和超越检测（增强泛化性、鲁棒性和可解释性）。此外，还总结了生成机制、公开数据集、在线检测工具和评估指标，并分析了社交媒体视角下的社会影响。最后，指出了当前挑战和未来研究方向，旨在填补学术空白并助力全球AI安全。项目链接已提供。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-15T08:02:46Z
- **目录日期**: 2025-05-15
