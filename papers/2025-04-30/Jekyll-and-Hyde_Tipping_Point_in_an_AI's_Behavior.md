# Jekyll-and-Hyde Tipping Point in an AI's Behavior

**URL**: http://arxiv.org/abs/2504.20980v1

## 原始摘要

Trust in AI is undermined by the fact that there is no science that predicts
-- or that can explain to the public -- when an LLM's output (e.g. ChatGPT) is
likely to tip mid-response to become wrong, misleading, irrelevant or
dangerous. With deaths and trauma already being blamed on LLMs, this
uncertainty is even pushing people to treat their 'pet' LLM more politely to
'dissuade' it (or its future Artificial General Intelligence offspring) from
suddenly turning on them. Here we address this acute need by deriving from
first principles an exact formula for when a Jekyll-and-Hyde tipping point
occurs at LLMs' most basic level. Requiring only secondary school mathematics,
it shows the cause to be the AI's attention spreading so thin it suddenly
snaps. This exact formula provides quantitative predictions for how the
tipping-point can be delayed or prevented by changing the prompt and the AI's
training. Tailored generalizations will provide policymakers and the public
with a firm platform for discussing any of AI's broader uses and risks, e.g. as
a personal counselor, medical advisor, decision-maker for when to use force in
a conflict situation. It also meets the need for clear and transparent answers
to questions like ''should I be polite to my LLM?''


## AI 摘要

这篇论文探讨了公众对AI（如ChatGPT等大语言模型）信任度下降的问题，因为目前缺乏科学理论能预测或解释其输出何时会突然变得错误、误导、无关甚至危险。作者从基本原理出发，推导出一个精确公式，揭示AI注意力过度分散导致"突变临界点"的机制。该公式仅需中学数学知识，可量化预测如何通过调整提示词或训练方式延迟或防止突变。研究为政策制定者和公众提供了讨论AI应用与风险的可靠基础，包括医疗建议、冲突决策等场景，并解答了"是否应对AI保持礼貌"等实际问题。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-30T15:01:28Z
- **目录日期**: 2025-04-30
