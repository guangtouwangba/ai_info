# Jekyll-and-Hyde Tipping Point in an AI's Behavior

**URL**: http://arxiv.org/abs/2504.20980v1

## 原始摘要

Trust in AI is undermined by the fact that there is no science that predicts
-- or that can explain to the public -- when an LLM's output (e.g. ChatGPT) is
likely to tip mid-response to become wrong, misleading, irrelevant or
dangerous. With deaths and trauma already being blamed on LLMs, this
uncertainty is even pushing people to treat their 'pet' LLM more politely to
'dissuade' it (or its future Artificial General Intelligence offspring) from
suddenly turning on them. Here we address this acute need by deriving from
first principles an exact formula for when a Jekyll-and-Hyde tipping point
occurs at LLMs' most basic level. Requiring only secondary school mathematics,
it shows the cause to be the AI's attention spreading so thin it suddenly
snaps. This exact formula provides quantitative predictions for how the
tipping-point can be delayed or prevented by changing the prompt and the AI's
training. Tailored generalizations will provide policymakers and the public
with a firm platform for discussing any of AI's broader uses and risks, e.g. as
a personal counselor, medical advisor, decision-maker for when to use force in
a conflict situation. It also meets the need for clear and transparent answers
to questions like ''should I be polite to my LLM?''


## AI 摘要

该研究揭示了大型语言模型（LLM）如ChatGPT输出突然转向错误、误导或危险内容的关键机制——当AI注意力过度分散时会触发"杰基尔-海德临界点"。通过基础原理推导出精确的数学公式（仅需中学数学即可理解），表明可通过调整提示词和训练方式来延迟或防止这种突变。这一发现为政策制定者和公众提供了量化评估AI风险的框架，适用于医疗咨询、冲突决策等关键场景，同时解答了"是否应对LLM保持礼貌"等实际问题。研究填补了当前AI可信度科学解释的空白，有助于建立透明的AI使用规范。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-30T09:01:24Z
- **目录日期**: 2025-04-30
