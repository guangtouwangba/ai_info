# T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning

**URL**: http://arxiv.org/abs/2505.16986v1

## 原始摘要

Large Language Models (LLMs) have demonstrated impressive capabilities as
intelligent agents capable of solving complex problems. However, effective
planning in scenarios involving dependencies between API or tool
calls-particularly in multi-turn conversations-remains a significant challenge.
To address this, we introduce T1, a tool-augmented, multi-domain, multi-turn
conversational dataset specifically designed to capture and manage inter-tool
dependencies across diverse domains. T1 enables rigorous evaluation of agents'
ability to coordinate tool use across nine distinct domains (4 single domain
and 5 multi-domain) with the help of an integrated caching mechanism for both
short- and long-term memory, while supporting dynamic replanning-such as
deciding whether to recompute or reuse cached results. Beyond facilitating
research on tool use and planning, T1 also serves as a benchmark for evaluating
the performance of open-source language models. We present results powered by
T1-Agent, highlighting their ability to plan and reason in complex,
tool-dependent scenarios.


## AI 摘要

大型语言模型（LLMs）作为智能代理已展现出解决复杂问题的能力，但在涉及API或工具调用依赖（尤其是多轮对话）的场景中，有效规划仍面临挑战。为此，研究团队推出T1数据集，这是一个支持工具增强、多领域、多轮对话的专用数据集，旨在捕捉和管理跨领域工具间依赖关系。T1通过集成短期/长期记忆缓存机制，支持动态重规划（如决定重新计算或复用缓存结果），可严格评估代理在9个领域（4单领域+5跨领域）协调工具使用的能力。该数据集同时成为开源语言模型性能的评估基准，T1-Agent的实验结果验证了其在复杂工具依赖场景中的规划推理能力。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-24T10:01:57Z
- **目录日期**: 2025-05-24
