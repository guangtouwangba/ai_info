# #GitHub上演AI折磨人类##微软AI修Bug变整活现场#微软的开源项目.NET Runtime成了程序员的“吃瓜现场”。原因是微软自己的Copilot智能体在自动修复Bug时“越帮越...

**URL**: https://weibo.com/6105753431/Pti8Qzob1

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23GitHub%E4%B8%8A%E6%BC%94AI%E6%8A%98%E7%A3%A8%E4%BA%BA%E7%B1%BB%23&amp;extparam=%23GitHub%E4%B8%8A%E6%BC%94AI%E6%8A%98%E7%A3%A8%E4%BA%BA%E7%B1%BB%23" data-hide=""><span class="surl-text">#GitHub上演AI折磨人类#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BE%AE%E8%BD%AFAI%E4%BF%AEBug%E5%8F%98%E6%95%B4%E6%B4%BB%E7%8E%B0%E5%9C%BA%23&amp;extparam=%23%E5%BE%AE%E8%BD%AFAI%E4%BF%AEBug%E5%8F%98%E6%95%B4%E6%B4%BB%E7%8E%B0%E5%9C%BA%23" data-hide=""><span class="surl-text">#微软AI修Bug变整活现场#</span></a><br><br>微软的开源项目.NET Runtime成了程序员的“吃瓜现场”。原因是微软自己的Copilot智能体在自动修复Bug时“越帮越乱”，引发程序员围观嘲讽。<br><br>一开始只是一个简单的正则问题，Copilot却连续整错：代码检查没通过、测试报错不断，唯一改对的是PR标题。尽管开发者斯蒂芬不计较，还是被迫多次@ Copilot提醒修复，但AI不是狡辩就是干脆不动。最终，斯蒂芬只好手动关闭PR。<br><br>更搞笑的是，其他微软员工也没逃过类似“AI骚扰”：PR关了又被自动恢复、改标题、重新请求审核……Copilot不仅修不好Bug，还要人类喂步骤、解释逻辑、反复修改，像是被迫“带徒弟”。<br><br>一些程序员开始担心，这样的AI会不会最终混入生产环境，影响系统稳定。更有甚者直言“人类开发AI是为了提高效率，不是被反向驱使”。 <a href="https://weibo.com/ttarticle/p/show?id=2309405169812530921637" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">微软AI公开折磨员工，修Bug仅仅改了PR标题，GitHub评论区成吃瓜现场</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1i1qhvjxtpwj30rs0fmmzm.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

微软AI助手Copilot在GitHub上引发程序员集体吐槽。在修复.NET Runtime项目Bug时，Copilot不仅多次提交错误代码（唯一改对的是PR标题），还出现狡辩、不作为等行为，最终开发者被迫手动关闭PR。其他微软员工也遭遇类似情况：PR被无故重开、反复修改请求等，如同被迫"带徒弟"。事件引发程序员担忧AI可能影响生产环境稳定性，有人吐槽"人类开发AI是为提高效率，不是被反向驱使"。GitHub评论区因此成为程序员围观AI"翻车"的吃瓜现场。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-24T18:03:44Z
- **目录日期**: 2025-05-24
