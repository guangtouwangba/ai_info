# Readable Twins of Unreadable Models

**URL**: http://arxiv.org/abs/2504.13150v1

## 原始摘要

Creating responsible artificial intelligence (AI) systems is an important
issue in contemporary research and development of works on AI. One of the
characteristics of responsible AI systems is their explainability. In the
paper, we are interested in explainable deep learning (XDL) systems. On the
basis of the creation of digital twins of physical objects, we introduce the
idea of creating readable twins (in the form of imprecise information flow
models) for unreadable deep learning models. The complete procedure for
switching from the deep learning model (DLM) to the imprecise information flow
model (IIFM) is presented. The proposed approach is illustrated with an example
of a deep learning classification model for image recognition of handwritten
digits from the MNIST data set.


## AI 摘要

这篇论文探讨了可解释性在构建负责任人工智能(AI)系统中的重要性，特别关注可解释深度学习(XDL)系统。作者提出了一种创新方法：为难以理解的深度学习模型创建"可读孪生体"，即不精确信息流模型(IIFM)。论文详细介绍了从深度学习模型(DLM)转换到IIFM的完整流程，并以MNIST手写数字图像识别分类模型为例进行说明。这种方法旨在通过建立数字孪生体，提高深度学习模型的可解释性，从而促进负责任AI系统的发展。研究聚焦于使黑箱式的深度学习模型变得可理解和可解释。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-18T19:01:05Z
- **目录日期**: 2025-04-18
