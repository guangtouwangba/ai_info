# Readable Twins of Unreadable Models

**URL**: http://arxiv.org/abs/2504.13150v1

## 原始摘要

Creating responsible artificial intelligence (AI) systems is an important
issue in contemporary research and development of works on AI. One of the
characteristics of responsible AI systems is their explainability. In the
paper, we are interested in explainable deep learning (XDL) systems. On the
basis of the creation of digital twins of physical objects, we introduce the
idea of creating readable twins (in the form of imprecise information flow
models) for unreadable deep learning models. The complete procedure for
switching from the deep learning model (DLM) to the imprecise information flow
model (IIFM) is presented. The proposed approach is illustrated with an example
of a deep learning classification model for image recognition of handwritten
digits from the MNIST data set.


## AI 摘要

本文探讨了构建可解释深度学习（XDL）系统的方法，以增强人工智能（AI）系统的责任性。作者提出为不可读的深度学习模型创建"可读孪生体"（即不精确信息流模型，IIFM），并详细描述了从深度学习模型（DLM）到IIFM的完整转换流程。该方法通过MNIST数据集中的手写数字图像识别分类模型进行了实例验证。这一研究为开发具有可解释性的负责任AI系统提供了新思路，特别是在数字孪生技术基础上建立模型可解释性方面具有创新意义。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-18T13:06:46Z
- **目录日期**: 2025-04-18
