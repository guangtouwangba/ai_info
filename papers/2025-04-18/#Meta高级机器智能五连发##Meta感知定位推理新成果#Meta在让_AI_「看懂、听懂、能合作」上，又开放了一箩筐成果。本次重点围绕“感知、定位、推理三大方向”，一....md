# #Meta高级机器智能五连发##Meta感知定位推理新成果#Meta在让 AI 「看懂、听懂、能合作」上，又开放了一箩筐成果。本次重点围绕“感知、定位、推理三大方向”，一...

**URL**: https://weibo.com/6105753431/PnOyppX1J

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Meta%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E6%99%BA%E8%83%BD%E4%BA%94%E8%BF%9E%E5%8F%91%23&amp;extparam=%23Meta%E9%AB%98%E7%BA%A7%E6%9C%BA%E5%99%A8%E6%99%BA%E8%83%BD%E4%BA%94%E8%BF%9E%E5%8F%91%23" data-hide=""><span class="surl-text">#Meta高级机器智能五连发#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23Meta%E6%84%9F%E7%9F%A5%E5%AE%9A%E4%BD%8D%E6%8E%A8%E7%90%86%E6%96%B0%E6%88%90%E6%9E%9C%23&amp;extparam=%23Meta%E6%84%9F%E7%9F%A5%E5%AE%9A%E4%BD%8D%E6%8E%A8%E7%90%86%E6%96%B0%E6%88%90%E6%9E%9C%23" data-hide=""><span class="surl-text">#Meta感知定位推理新成果#</span></a><br><br>Meta在让 AI 「看懂、听懂、能合作」上，又开放了一箩筐成果。<br><br>本次重点围绕“感知、定位、推理三大方向”，一口气带来了五项技术——<br><br>1. Meta Perception Encoder：新一代视觉编码器，能在图像、视频上完成零样本分类和检索任务，不仅识别能力强，还能理解细节，比如看清夜视镜头里的小动物，或海底沙中的魟鱼。【视频1】<br><br>2. Perception Language Model（PLM）：该模型能更准确理解「谁在做什么、在哪、什么时候」这类视频问题，它训练用的是Meta自建的最大人类标注视频语言数据集，重点放在动作理解和时空推理方面。【视频2】<br><br>3. Meta Locate 3D：让AI在三维世界里听懂人话、找到物体。比如说“把电视旁边的花瓶拿来”，它能理解并准确定位你说的是哪个。技术上结合了2D-3D特征融合、3D场景理解、自然语言指令三大模块，特别适合机器人和AR系统来用。【视频3】<br><br>4. Dynamic Byte Latent Transformer：替代传统分词方式的新语言模型架构，它不依赖分词词表，而是直接处理字节序列，鲁棒性大幅提升，对拼写错误、噪声输入更友好。【视频4】<br><br>5. Collaborative Reasoner：为LLM设计的协作推理框架，它能模拟两个模型之间的对话过程，进而训练出更懂合作、会沟通的AI。它甚至可以“自己和自己对话”，生成大量训练数据来实现自我优化。【视频5】<br><br>Meta表示，这些模型、数据、代码将全部开源，希望各界共同参与，一起推动机器智能的发展。<br><br>未来，这些能力可能会用在AI助手、机器人、AR眼镜等产品形态中，真正实现“能协作的智能体”。<br><br>感兴趣的小伙伴可以点击：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fai.meta.com%2Fblog%2Fmeta-fair-updates-perception-localization-reasoning" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3ly1i0kuoaedwej30zk0k0wer.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1i0kuo678kfj30zk0k0q2u.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3ly1i0kuoaauqjj30zk0k0q2u.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3ly1i0kuo9gv1gj30zk0k0mxl.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3ly1i0kuo7o020j30zk0k0t8y.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3ly1i0kuo6zk1dj30zk0k0glw.jpg" referrerpolicy="no-referrer"><br><br><br clear="both"><div style="clear: both"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/006Fd7o3ly1i0kuo9mpwsj30zk0k0t9n.jpg" style="width: 100%"><source src="https://f.video.weibocdn.com/o0/QuMeFqpplx08nz7X06Fy010412003umy0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1744970557&amp;ssig=8BEOaGJlI3&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/994VjVMHlx08nz7X1HMI010412001Ewt0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1744970557&amp;ssig=3wHAqAQIC7&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/MDD9nBenlx08nz7WWJSM0104120011TL0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1744970557&amp;ssig=msdQrCv5cl&amp;KID=unistore,video"><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5156750811398186" target="_blank" rel="noopener noreferrer">微博视频</a>观看。</p></video>

## AI 摘要

Meta近期发布了五项AI技术突破，聚焦感知、定位和推理三大方向：1）Meta Perception Encoder实现图像/视频零样本分类和细节识别；2）PLM模型精准理解视频中的时空关系；3）Meta Locate 3D结合2D-3D特征实现自然语言指令下的物体定位；4）新型语言模型Dynamic Byte直接处理字节序列提升鲁棒性；5）Collaborative Reasoner通过模拟对话训练协作型AI。所有技术将开源，可应用于AI助手、机器人及AR设备。这些进展标志着AI在环境理解与人机协作方面取得重要突破。（99字）

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-04-18T09:03:41Z
- **目录日期**: 2025-04-18
