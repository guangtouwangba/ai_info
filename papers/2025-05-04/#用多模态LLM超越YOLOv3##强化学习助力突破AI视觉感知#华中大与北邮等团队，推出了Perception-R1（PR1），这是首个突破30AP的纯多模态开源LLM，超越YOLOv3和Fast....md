# #用多模态LLM超越YOLOv3##强化学习助力突破AI视觉感知#华中大与北邮等团队，推出了Perception-R1（PR1），这是首个突破30AP的纯多模态开源LLM，超越YOLOv3和Fast...

**URL**: https://weibo.com/6105753431/Pq7giy32s

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%94%A8%E5%A4%9A%E6%A8%A1%E6%80%81LLM%E8%B6%85%E8%B6%8AYOLOv3%23&amp;extparam=%23%E7%94%A8%E5%A4%9A%E6%A8%A1%E6%80%81LLM%E8%B6%85%E8%B6%8AYOLOv3%23" data-hide=""><span class="surl-text">#用多模态LLM超越YOLOv3#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%8A%A9%E5%8A%9B%E7%AA%81%E7%A0%B4AI%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5%23&amp;extparam=%23%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%8A%A9%E5%8A%9B%E7%AA%81%E7%A0%B4AI%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5%23" data-hide=""><span class="surl-text">#强化学习助力突破AI视觉感知#</span></a><br><br>华中大与北邮等团队，推出了Perception-R1（PR1），这是首个突破30AP的纯多模态开源LLM，超越YOLOv3和Faster-RCNN等经典模型，在COCO2017 val set上表现出色。<br><br>PR1通过基于规则的强化学习（RL），优化视觉感知能力，在物体检测、OCR和计数任务中表现突出。PR1的感知策略优化框架使得现有MLLM在这些复杂任务中更加精准。<br><br>实验结果证明，PR1在visual grounding、OCR和Pixmo-Count等任务中表现超越同类专用模型，展示了其出色的可扩展性。PR1为AI视觉感知的未来发展奠定了基础，推动了AI模型理解视觉信息的极限。 <a href="https://weibo.com/ttarticle/p/show?id=2309405162244471390210" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_article_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">用多模态LLM超越YOLOv3！强化学习突破多模态感知极限｜开源</span></a><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3ly1i12cp11c2oj30iw0anq3r.jpg" referrerpolicy="no-referrer"><br><br>

## AI 摘要

华中大与北邮团队联合推出多模态大语言模型Perception-R1（PR1），首次在纯多模态开源模型中突破30AP，性能超越YOLOv3、Faster-RCNN等经典视觉模型。该模型通过基于规则的强化学习优化视觉感知能力，在COCO2017验证集上展现出卓越的物体检测、OCR和计数性能。实验显示PR1在视觉定位、文本识别等任务中优于专用模型，具有出色的可扩展性。这一突破为AI视觉感知发展奠定新基础，推动了多模态模型理解视觉信息的边界。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-04T11:02:48Z
- **目录日期**: 2025-05-04
