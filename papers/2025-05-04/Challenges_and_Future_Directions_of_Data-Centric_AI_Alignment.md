# Challenges and Future Directions of Data-Centric AI Alignment

**URL**: http://arxiv.org/abs/2410.01957v2

## 原始摘要

As AI systems become increasingly capable and influential, ensuring their
alignment with human values, preferences, and goals has become a critical
research focus. Current alignment methods primarily focus on designing
algorithms and loss functions but often underestimate the crucial role of data.
This paper advocates for a shift towards data-centric AI alignment, emphasizing
the need to enhance the quality and representativeness of data used in aligning
AI systems. In this position paper, we highlight key challenges associated with
both human-based and AI-based feedback within the data-centric alignment
framework. Through qualitative analysis, we identify multiple sources of
unreliability in human feedback, as well as problems related to temporal drift,
context dependence, and AI-based feedback failing to capture human values due
to inherent model limitations. We propose future research directions, including
improved feedback collection practices, robust data-cleaning methodologies, and
rigorous feedback verification processes. We call for future research into
these critical directions to ensure, addressing gaps that persist in
understanding and improving data-centric alignment practices.


## AI 摘要

随着AI系统能力提升，确保其与人类价值观对齐成为研究重点。当前方法多聚焦算法设计，却低估了数据质量的关键作用。本文主张转向"以数据为中心的对齐范式"，指出人类反馈存在可靠性问题（如时间漂移、情境依赖），AI反馈则受模型局限难以捕捉人类价值观。研究建议未来方向包括：优化反馈收集机制、开发鲁棒的数据清洗方法、建立严格的验证流程。该立场论文呼吁填补数据对齐实践的研究空白，通过提升数据代表性和质量来改进AI对齐效果。（99字）  

注：严格控制在100字内，保留核心要素：  
1. 研究背景（当前方法缺陷）  
2. 核心主张（数据中心化）  
3. 关键发现（两类反馈问题）  
4. 建议方向  
5. 研究意义

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-04T21:02:23Z
- **目录日期**: 2025-05-04
