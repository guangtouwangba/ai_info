# Challenges and Future Directions of Data-Centric AI Alignment

**URL**: http://arxiv.org/abs/2410.01957v2

## 原始摘要

As AI systems become increasingly capable and influential, ensuring their
alignment with human values, preferences, and goals has become a critical
research focus. Current alignment methods primarily focus on designing
algorithms and loss functions but often underestimate the crucial role of data.
This paper advocates for a shift towards data-centric AI alignment, emphasizing
the need to enhance the quality and representativeness of data used in aligning
AI systems. In this position paper, we highlight key challenges associated with
both human-based and AI-based feedback within the data-centric alignment
framework. Through qualitative analysis, we identify multiple sources of
unreliability in human feedback, as well as problems related to temporal drift,
context dependence, and AI-based feedback failing to capture human values due
to inherent model limitations. We propose future research directions, including
improved feedback collection practices, robust data-cleaning methodologies, and
rigorous feedback verification processes. We call for future research into
these critical directions to ensure, addressing gaps that persist in
understanding and improving data-centric alignment practices.


## AI 摘要

这篇立场论文主张转向以数据为中心的AI对齐方法，强调提升训练数据的质量和代表性。作者指出当前基于人类和AI反馈的对齐框架存在关键挑战：人类反馈存在不可靠性，AI反馈则受限于时间漂移、情境依赖和模型固有缺陷。论文通过定性分析揭示了这些问题，并提出未来研究方向，包括改进反馈收集方法、开发稳健的数据清洗技术以及建立严格的反馈验证流程。研究呼吁学界关注这些关键方向，以填补当前数据中心化对齐实践中的认知空白，从而更好地确保AI系统与人类价值观的一致性。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-05-04T20:02:19Z
- **目录日期**: 2025-05-04
