# #阿里开源首个全模态大模型##7B模型搞定AI视频通话#深夜重磅！阿里发布并开源首个端到端全模态大模型——通义千问Qwen2.5-Omni-7B，来了。仅靠一个一体式模型，...

**URL**: https://weibo.com/6105753431/PkuqTqTIy

## 原始摘要

<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E9%98%BF%E9%87%8C%E5%BC%80%E6%BA%90%E9%A6%96%E4%B8%AA%E5%85%A8%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E9%98%BF%E9%87%8C%E5%BC%80%E6%BA%90%E9%A6%96%E4%B8%AA%E5%85%A8%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#阿里开源首个全模态大模型#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%237B%E6%A8%A1%E5%9E%8B%E6%90%9E%E5%AE%9AAI%E8%A7%86%E9%A2%91%E9%80%9A%E8%AF%9D%23&amp;extparam=%237B%E6%A8%A1%E5%9E%8B%E6%90%9E%E5%AE%9AAI%E8%A7%86%E9%A2%91%E9%80%9A%E8%AF%9D%23" data-hide=""><span class="surl-text">#7B模型搞定AI视频通话#</span></a><br><br>深夜重磅！阿里发布并开源首个端到端全模态大模型——<br><br>通义千问Qwen2.5-Omni-7B，来了。<br><br>仅靠一个一体式模型，就能搞定文本、音频、图像、视频全模态，并实时生成文本和自然语音。<br><br>堪称7B模型的全能冠军。<br><br>你的iPhone搭载的很可能就是它！<br><br>现在打开Qwen Chat，就能直接和它打语音电话、视频通话：【图1】<br><br>话不多说，先来看一波能力展示。<br><br>打开视频通话，如果是多人，它能够分别记住每个人讲的话，并且能够精准对上每个人的人脸，连某个人戴没戴眼镜这种细节它都能记得一清二楚：【视频2】<br><br>在大街上同它视频通话，它能正确识别周围环境，按照你的需求为你推荐餐馆：【视频3】<br><br>走进厨房，它又化身“智能菜谱”，一步步指导你变成大厨：【视频4】<br><br>在多模态任务OmniBench评测中，Qwen2.5-Omni表现刷新记录拿下**新SOTA**，远超谷歌Gemini-1.5-Pro等同类模型。<br><br>在单模态的语音识别、翻译、音频理解、图像推理、视频理解、语音生成任务中，Qwen2.5-Omni也全维度表现都优于类似大小的单模态模型以及闭源模型。<br><br>在seed-tts-eval语音生成基准中，Qwen2.5-Omni展现出与人类水平相当语音合成能力。【图5】<br><br>这意味着Qwen2.5-Omni-7B能很好和世界进行实时交互，比如识别音视频情绪。<br><br>再来敲重点：<br><br>模型非常轻量，手机等终端都可轻松部署运行，且开源用的是宽松的Apache2.0协议，开发者、企业现在都可免费下载商用。<br><br>Qwen2.5-Omni-7B一开源，网友直呼这才是真正的OpenAI（doge）。【图6】<br><br>网友纷纷表示可以直接拿来装到智能眼镜上了：<br><br>这可能是智能眼镜的完美模型。【图7】<br><br>7B模型的新纪录！【图8】<br><br>目前，在Qwen Chat上即可体验该模型支持的AI视频通话功能。<br><br>更多实例，一起来看~<br><br>实测效果惊艳<br>首先，Qwen2.5-Omni-7B能胜任免费的数学家教。<br><br>它能像人类老师一样，看到题目、听懂问题，并且一步一步耐心讲解。【视频9】<br><br>更复杂的论文它也看得懂。<br><br>只需共享屏幕，然后将论文从上至下滑动，“给它看一遍”。<br><br>它就能通俗解释论文内容。<br><br>比如PPT、网页资料等，也能找它做讲解。【视频10】<br><br>而且它还有一定艺术见解，比如可以陪着你画画，然后给出指导建议。【视频11】<br><br>或者听你演奏的音乐，给出更好的改进建议。【视频12】<br><br>我们还进行了一手实测，在Qwen Chat上每天可使用语音和视频聊天10次。【图13】<br><br>实测中，模型能很好理解商品界面和优惠政策。<br><br>响应速度也很快，并且会引导人类继续问下去、很有耐心。<br><br>需要注意的是，当前视频通话还只是Beta测试版，每次通话限时3分钟。【视频14】<br><br>Hugging Face的产品负责人Jeff Boudier也第一时间上手试玩。<br><br>模型的英文能力一样出众，而且它不仅回答看到了杯子，还细致描述了杯子上的笑脸花纹。【视频15】<br><br>首创Thinker-Talker双核架构<br>目前官方已放出Qwen2.5-Omni技术Blog和论文。<br><br>Qwen2.5-Omni采用通义团队首创的全新架构——Thinker-Talker双核架构。<br><br>其中，Thinker就像“大脑”，负责处理和理解来自文本、音频、视频等多模态的输入信息，生成高层语义表征以及对应的文本内容。<br><br>Talker则更像“嘴巴”，以流式的方式接收由Thinker实时输出的语义表征与文本，并流畅地合成离散语音tokens。【图16】<br><br>具体来说，Thinker基于Transformer解码器架构，融合音频/图像编码器进行特征提取。<br><br>而Talker采用双轨自回归Transformer解码器设计，在训练和推理过程中直接接收来自Thinker的高维表征，并共享Thinker的全部历史上下文信息。因此，整个架构作为一个紧密结合的单一模型运行，支持端到端的训练和推理。<br><br>与此同时，团队还提出了一种新的位置编码算法TMRoPE（Time-aligned Multimodal RoPE）以及Position Embedding （位置嵌入）融合音视频技术。<br><br>TMRoPE编码多模态输入的三维位置信息，即多模态旋转位置嵌入（M-RoPE），并结合绝对时间位置，通过将原始旋转嵌入分解为时间、高度和宽度三个部分实现。【图17】<br><br>另外值得一提的是，从技术层面来看，Qwen2.5-Omni和一般的视频/语音理解模型以及其相应的视频/语音对话的AI功能，也有本质性区别。<br><br>在传统语音理解大模型的人机交互场景里，一般运用 ASR（Automatic Speech Recognition，自动语音识别）技术，把人类语音转换为文字文本，随后将其交给大语言模型处理，最终生成的内容借助 TTS（Text-to-Speech，语音合成）技术转化为语音反馈给用户。<br><br>而视频理解模型是基于图片、视频进行大模型理解，并以文字形式输出反馈。<br><br>这两种模型均属于相互独立的单链路模型。在一些AI应用中，甚至会串联多个模型来实现类似功能，如此一来，链路变得更长，效率大打折扣。<br><br>Qwen2.5-Omni-7B的特点在于，它原生支持视频、图片、语音、文字等多模态输入，并能原生生成语音及文字等多模态输出。【图18】<br><br>也就是说，一个模型就能通过“看”、“听”、“阅读”等多种方式来综合思考。<br><br>所以Qwen2.5-Omni得以在一系列同等规模的单模态模型权威基准测试中，拿下最强全模态性能，在语音理解、图片理解、视频理解、语音生成等领域的测评分数，均领先于专门的音频（Audio）或视觉语言（VL）模型。<br><br>抢先看到Apple Intelligence？<br>一个月前，阿里公开确认与苹果合作，宣布通义千问将为国行iPhone用户提供AI功能，此消息一经披露，便在科技圈引发热议。<br><br>而这次Qwen2.5-Omni开源，就是奔着端侧部署来的，7B尺寸使其具备直接嵌入手机的可行性，仿佛提前看到了Apple Intelligence，让大家看到多模态大模型上手机都能有哪些效果。<br><br>不只是苹果，据量子位了解，这种端侧部署能力已吸引超90%国产手机品牌接入通义千问，包括OPPO、vivo、荣耀、传音等，还有众多汽车品牌、AI硬件产品选择与之携手。<br><br>为啥都选通义千问？<br><br>梳理通义千问的最新发展动态，答案便不难理解。<br><br>首先，通义千问Qwen目前已稳居全球最大AI大模型族群。<br><br>仅在最近一个月的时间里，就接连推出了一系列具有竞争力的模型：推理模型Max旗舰版QwQ-Max-Preview、视频生成模型Wan 2.1、推理模型QwQ-32B、视觉语言模型Qwen2.5-VL-32B-Instruct……<br><br>实际上，2023年至今，阿里通义团队已累计开源200多款模型，涵盖从0.5B到110B全尺寸范围，模型类型覆盖文本生成、视觉理解与生成、语音理解与生成、文生图及视频模型等全模态领域，应用场景也极为丰富。<br><br>在海内外开源社区中，通义千问Qwen衍生变体数量更是一路飙升，现已超过10万，超越Llama系列。<br><br>根据Huggingface2月10日发布的最新全球开源大模型榜单，排名前十的开源大模型无一例外，全部是基于通义千问Qwen开源模型二创的变体模型。<br><br>其次，阿里巴巴通过开源等一系列积极举措，成功构建起一个丰富且活跃的大模型生态。<br><br>阿里不仅将开源进行到底，更向大模型公司提供了全方位的服务支持，其中包括算力资源以及开发工具等，阿里云已成为中国大模型领域的公共AI算力底座。<br><br>阿里魔搭社区ModelScope截至2025年2月中旬，模型总量已超4万个，服务超1000万开发者。<br><br>那么通义千问Qwen团队下一步要干啥？<br><br>期待听到您的反馈，并看到您使用Qwen2.5-Omni开发的创新应用。<br><br>在不久的将来，将着力增强模型对语音指令的遵循能力，并提升音视频协同理解能力。还将持续拓展多模态能力边界，发展全面的通用模型。<br><br>感兴趣的友友不如一起来上手试试吧~<br>Qwen Chat：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fchat.qwenlm.ai" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>Hugging Face：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhuggingface.co%2FQwen%2FQwen2.5-Omni-7B" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>ModelScope：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FQwen%2FQwen2.5-Omni-7B" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>DashScope：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fmodel-studio%2Fuser-guide%2Fqwen-omni" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>GitHub：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fgithub.com%2FQwenLM%2FQwen2.5-Omni" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>Demo体验：<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmodelscope.cn%2Fstudios%2FQwen%2FQwen2.5-Omni-Demo" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1hzvkbijoy2g30pq0c0tw7.gif" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3ly1hzvko9wu9rj30zk0k0tae.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax1.sinaimg.cn/large/006Fd7o3ly1hzvko9j7kmj30zk0k077r.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3ly1hzvkoa692nj30zk0k0jso.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1hzvkd8alluj30zk0r3jxk.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax4.sinaimg.cn/large/006Fd7o3gy1hzvkdj991sj30wk07240f.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1hzvkdpcdodj30wg06ydi7.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax2.sinaimg.cn/large/006Fd7o3gy1hzvkdzgckkj30wm04ogng.jpg" referrerpolicy="no-referrer"><br><br><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3ly1hzvko9lev8j30zk0k03yw.jpg" referrerpolicy="no-referrer"><br><br><br clear="both"><div style="clear: both"></div><video controls="controls" poster="https://tvax3.sinaimg.cn/orj480/006Fd7o3ly1hzvko9zk8vj30zk0k0tae.jpg" style="width: 100%"><source src="https://f.video.weibocdn.com/o0/FOFYIU0Mlx08n0fMu9sQ01041200jWrg0E010.mp4?label=mp4_720p&amp;template=1280x720.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1743102145&amp;ssig=xdF866jmu6&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/0OfBwfjllx08n0fLmy6Y010412009FAP0E010.mp4?label=mp4_hd&amp;template=852x480.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1743102145&amp;ssig=k0nUL%2BP7AC&amp;KID=unistore,video"><source src="https://f.video.weibocdn.com/o0/Xu6gWXonlx08n0fLqJmM0104120068UP0E010.mp4?label=mp4_ld&amp;template=640x360.25.0&amp;ori=0&amp;ps=1CwnkDw1GXwCQx&amp;Expires=1743102145&amp;ssig=aXzCRCWgvQ&amp;KID=unistore,video"><p>视频无法显示，请前往<a href="https://video.weibo.com/show?fid=1034%3A5148832300728350" target="_blank" rel="noopener noreferrer">微博视频</a>观看。</p></video>

## AI 摘要

阿里开源了首个端到端全模态大模型Qwen2.5-Omni-7B，支持文本、音频、图像、视频多模态处理，能实时生成文本和语音。该模型采用Thinker-Talker双核架构，在多项评测中超越同类模型，尤其适合终端设备部署。目前已应用于iPhone等设备，支持视频通话、实时环境识别等功能。模型轻量且开源，开发者可免费商用。阿里通义千问生态持续扩展，已与多家手机和汽车品牌合作，推动多模态AI应用落地。

## 元数据

- **来源**: ArXiv
- **类型**: 论文
- **保存时间**: 2025-03-27T18:03:06Z
- **目录日期**: 2025-03-27
