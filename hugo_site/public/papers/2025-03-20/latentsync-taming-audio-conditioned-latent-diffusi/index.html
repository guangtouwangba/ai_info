<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>LatentSync: Taming Audio-Conditioned Latent Diffusion Models for Lip Sync with SyncNet Supervision 网页链接本研究提出了一种名为LatentSync的端到端唇同... - AI研究资料库</title>
    <link rel="stylesheet" href="/css/style.css">
</head>
<body>
    
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark');
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <div class="header-content">
        <h1><a href="/">AI研究资料库</a></h1>
        <nav>
            
            <a href="/papers/">论文</a>
            
            <a href="/tags/">标签</a>
            
            <a href="/categories/">分类</a>
            
            <a href="/search/">搜索</a>
            
        </nav>
        
<div class="language-switcher">
    
    <a href="https://example.org/" class="active">
        中文
    </a>
    
    <a href="https://example.org/en/" class="">
        English
    </a>
    
</div>
 
    </div>
</header> 
    
    <main>
        

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://example.org/">首页</a>&nbsp;»&nbsp;<a href="https://example.org/papers/">Papers</a></div>
    <h1 class="post-title">
      LatentSync: Taming Audio-Conditioned Latent Diffusion Models for Lip Sync with SyncNet Supervision 网页链接本研究提出了一种名为LatentSync的端到端唇同...
    </h1>
    <div class="post-meta"><span title='2025-03-20 04:03:00 +0000 +0000'>三月 20, 2025</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;AI Research Repository&nbsp;|&nbsp;<a href="https://github.com/yourusername/yourrepository/tree/main/content/papers/2025-03-20/latentsync-taming-audio-conditioned-latent-diffusi.md" rel="noopener noreferrer" target="_blank">建议修改</a>

</div>
  </header> 
  <div class="original-link">
    <a href="https://weibo.com/1870858943/Pjot9eGs2" target="_blank" rel="noopener">查看原文</a>
  </div>

  <div class="post-content"><h1 id="latentsync-taming-audio-conditioned-latent-diffusion-models-for-lip-sync-with-syncnet-supervision-网页链接本研究提出了一种名为latentsync的端到端唇同">LatentSync: Taming Audio-Conditioned Latent Diffusion Models for Lip Sync with SyncNet Supervision 网页链接本研究提出了一种名为LatentSync的端到端唇同&hellip;<a hidden class="anchor" aria-hidden="true" href="#latentsync-taming-audio-conditioned-latent-diffusion-models-for-lip-sync-with-syncnet-supervision-网页链接本研究提出了一种名为latentsync的端到端唇同">#</a></h1>
<p><strong>原始链接</strong>: <a href="https://weibo.com/1870858943/Pjot9eGs2">查看原文</a></p>
<h2 id="原始摘要">原始摘要<a hidden class="anchor" aria-hidden="true" href="#原始摘要">#</a></h2>
<p>LatentSync: Taming Audio-Conditioned Latent Diffusion Models for Lip Sync with SyncNet Supervision <a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fwww.aminer.cn%2Fpub%2F675ba34bae8580e7ff21df01%2Flatentsync-taming-audio-conditioned-latent-diffusion-models-for-lip-sync-with-syncnet" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>本研究提出了一种名为LatentSync的端到端唇同步框架，基于音频条件的潜在扩散模型，无需中间运动表示，与先前的基于像素空间扩散或两阶段生成的唇同步方法不同。该框架能够利用Stable Diffusion的强大能力，直接建模复杂的音频视觉相关性。研究中发现，基于扩散的唇同步方法在不同帧的扩散过程中存在时间一致性不足的问题。为此，研究提出了时间表示对齐（TREPA）方法以增强时间一致性，同时保持唇同步的准确性。TREPA利用大规模自监督视频模型提取的时间表示来对齐生成的帧与真实帧。此外，研究还观察到了SyncNet收敛问题，并进行了全面的实证研究，识别了影响SyncNet收敛的关键因素，包括模型架构、训练超参数和数据预处理方法。通过改变SyncNet的整体训练框架，显著提高了SyncNet的准确性。这些经验也可应用于其他使用SyncNet的唇同步和音频驱动的人像动画方法。基于这些创新，该方法在HDTF和VoxCeleb2数据集上的多个指标上超越了现有的唇同步方法。<a href="https://m.weibo.cn/p/index?extparam=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;containerid=100808f068f0dad74789bee210163c40a4b50d" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://n.sinaimg.cn/photo/5213b46e/20180926/timeline_card_small_super_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">人工智能</span></a><a href="https://m.weibo.cn/p/index?extparam=%E5%A4%A7%E6%A8%A1%E5%9E%8B&amp;containerid=1008082dc9b4e036056e2a00e5499db67ddd30" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://n.sinaimg.cn/photo/5213b46e/20180926/timeline_card_small_super_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">大模型</span></a><a href="https://m.weibo.cn/p/index?extparam=%E7%A1%95%E5%A3%AB%E8%AE%BA%E6%96%87&amp;containerid=1008084cacf38f5903dc7b04550404d0bd3608" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://n.sinaimg.cn/photo/5213b46e/20180926/timeline_card_small_super_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">硕士论文</span></a><img style="" src="https://tvax2.sinaimg.cn/large/6f830abfly1hzn8lwp5a6j21n90z1b29.jpg" referrerpolicy="no-referrer"><br><br></p>
<h2 id="ai-摘要">AI 摘要<a hidden class="anchor" aria-hidden="true" href="#ai-摘要">#</a></h2>
<p>本研究提出了LatentSync，一种基于音频条件的潜在扩散模型的端到端唇同步框架，无需中间运动表示，直接建模音频与视觉的复杂关系。为解决扩散过程中时间一致性问题，提出了时间表示对齐（TREPA）方法，利用自监督视频模型增强生成帧与真实帧的时间一致性。研究还优化了SyncNet的训练框架，提升了其准确性。实验表明，该方法在HDTF和VoxCeleb2数据集上超越了现有唇同步方法，为音频驱动的人像动画提供了新的解决方案。</p>
<h2 id="元数据">元数据<a hidden class="anchor" aria-hidden="true" href="#元数据">#</a></h2>
<ul>
<li><strong>来源</strong>: ArXiv</li>
<li><strong>类型</strong>: 论文</li>
<li><strong>保存时间</strong>: 2025-03-20T04:03:43Z</li>
<li><strong>目录日期</strong>: 2025-03-20</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://example.org/tags/latentsync/">LatentSync</a></li>
      <li><a href="https://example.org/tags/taming/">Taming</a></li>
      <li><a href="https://example.org/tags/latent/">Latent</a></li>
      <li><a href="https://example.org/tags/diffusion/">Diffusion</a></li>
      <li><a href="https://example.org/tags/lip/">Lip</a></li>
    </ul>
    
    

    
    <div class="tagged-related">
      <h3>相关主题</h3>
      <ul>
        <li><a href="/papers/2025-03-20/hybrid-quantum-classical-reinforcement-learning-in/">Hybrid Quantum-Classical Reinforcement Learning in Latent Observation Spaces</a></li>
      </ul>
    </div>
<nav class="paginav">
  <a class="prev" href="https://example.org/papers/2025-03-20/infinity-scaling-bitwise-autoregressive-modeling-f/">
    <span class="title">« 上一页</span>
    <br>
    <span>Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis网页链接本文介绍了一种名为Infinity的位运算视觉自回归模型，该模型...</span>
  </a>
  <a class="next" href="https://example.org/papers/2025-03-20/llmscaling-up-llmrouting-llm8500llm/">
    <span class="title">下一页 »</span>
    <br>
    <span>#路由LLM最全面探索##笔记本也能玩的大模型Scaling Up研究# 事关路由LLM（Routing LLM），一项截至目前最全面的研究，来了——共计收集和整理了涉及8500&#43;个LLM，...</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
    <footer>
        <p>&copy; 2025 AI研究资料库</p>
    </footer>
</body>
</html> 