<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Evaluating and Aligning CodeLLMs on Human Preference网页链接这篇论文研究了代码生成大型语言模型（codeLLMs）的性能评估和与人类偏好对齐的问题。现有的大部... - AI研究资料库</title>
    <link rel="stylesheet" href="/css/style.css">
</head>
<body>
    
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark');
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <div class="header-content">
        <h1><a href="/">AI研究资料库</a></h1>
        <nav>
            
            <a href="/papers/">论文</a>
            
            <a href="/tags/">标签</a>
            
            <a href="/categories/">分类</a>
            
            <a href="/search/">搜索</a>
            
        </nav>
        
<div class="language-switcher">
    
    <a href="https://example.org/" class="active">
        中文
    </a>
    
    <a href="https://example.org/en/" class="">
        English
    </a>
    
</div>
 
    </div>
</header> 
    
    <main>
        

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://example.org/">首页</a>&nbsp;»&nbsp;<a href="https://example.org/papers/">Papers</a></div>
    <h1 class="post-title">
      Evaluating and Aligning CodeLLMs on Human Preference网页链接这篇论文研究了代码生成大型语言模型（codeLLMs）的性能评估和与人类偏好对齐的问题。现有的大部...
    </h1>
    <div class="post-meta"><span title='2025-03-20 04:04:00 +0000 +0000'>三月 20, 2025</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;AI Research Repository&nbsp;|&nbsp;<a href="https://github.com/yourusername/yourrepository/tree/main/content/papers/2025-03-20/evaluating-and-aligning-codellms-on-human-preferen.md" rel="noopener noreferrer" target="_blank">建议修改</a>

</div>
  </header> 
  <div class="original-link">
    <a href="https://weibo.com/1870858943/P58h85y3u" target="_blank" rel="noopener">查看原文</a>
  </div>

  <div class="post-content"><h1 id="evaluating-and-aligning-codellms-on-human-preference网页链接这篇论文研究了代码生成大型语言模型codellms的性能评估和与人类偏好对齐的问题现有的大部">Evaluating and Aligning CodeLLMs on Human Preference网页链接这篇论文研究了代码生成大型语言模型（codeLLMs）的性能评估和与人类偏好对齐的问题。现有的大部&hellip;<a hidden class="anchor" aria-hidden="true" href="#evaluating-and-aligning-codellms-on-human-preference网页链接这篇论文研究了代码生成大型语言模型codellms的性能评估和与人类偏好对齐的问题现有的大部">#</a></h1>
<p><strong>原始链接</strong>: <a href="https://weibo.com/1870858943/P58h85y3u">查看原文</a></p>
<h2 id="原始摘要">原始摘要<a hidden class="anchor" aria-hidden="true" href="#原始摘要">#</a></h2>
<p>Evaluating and Aligning CodeLLMs on Human Preference<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fwww.aminer.cn%2Fpub%2F67565a4bae8580e7ff8e0fbd%2F%3Ff%3Dwb" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>这篇论文研究了代码生成大型语言模型（codeLLMs）的性能评估和与人类偏好对齐的问题。现有的大部分代码相关基准测试主要关注生成正确代码片段的能力，但忽略了与人类偏好的匹配。为此，论文提出了一种严格的人类策划的基准CodeArena，模拟现实世界编程任务的复杂性和多样性，并从用户查询中精心选取了397个高质量样本，涵盖了40个类别和44种编程语言。此外，论文还构建了一个多样化的合成指令语料库SynCode-Instruct（近20B个标记），通过扩展网站上的指令来验证大规模合成指令微调的有效性。实验表明，基于执行的基准测试与CodeArena之间存在性能差异，且在40多个大型语言模型上的系统实验显示，开源的顶级代码LLM（如Qwen2.5-Coder）与专有LLM（如OpenAI o1）之间存在显著的性能差距，突显了与人类偏好对齐的重要性。<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#语言模型#</span></a><a href="https://m.weibo.cn/p/index?extparam=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;containerid=100808f068f0dad74789bee210163c40a4b50d" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://n.sinaimg.cn/photo/5213b46e/20180926/timeline_card_small_super_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">人工智能</span></a><a href="https://m.weibo.cn/p/index?extparam=%E7%A7%91%E7%A0%94&amp;containerid=100808a62e87d21630c0abf068bf92641e88be" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://n.sinaimg.cn/photo/5213b46e/20180926/timeline_card_small_super_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">科研</span></a><a href="https://m.weibo.cn/p/index?extparam=%E7%A0%94%E7%A9%B6%E7%94%9F&amp;containerid=100808951b26a4a4b4ec29f6ca7f280fccb863" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://n.sinaimg.cn/photo/5213b46e/20180926/timeline_card_small_super_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">研究生</span></a><img style="" src="https://tvax4.sinaimg.cn/large/6f830abfly1hwmt504ez9j22bt17pnpd.jpg" referrerpolicy="no-referrer"><br><br></p>
<h2 id="ai-摘要">AI 摘要<a hidden class="anchor" aria-hidden="true" href="#ai-摘要">#</a></h2>
<p>这篇论文探讨了代码生成大型语言模型（codeLLMs）在性能评估和与人类偏好对齐方面的问题。现有基准测试主要关注代码生成正确性，而忽略了人类偏好。为此，研究提出了CodeArena基准，模拟现实编程任务，包含397个高质量样本，涵盖40个类别和44种编程语言。此外，研究构建了SynCode-Instruct语料库（近20B标记），验证大规模合成指令微调的有效性。实验显示，开源顶级代码LLM（如Qwen2.5-Coder）与专有LLM（如OpenAI o1）存在显著性能差距，强调了与人类偏好对齐的重要性。</p>
<h2 id="元数据">元数据<a hidden class="anchor" aria-hidden="true" href="#元数据">#</a></h2>
<ul>
<li><strong>来源</strong>: ArXiv</li>
<li><strong>类型</strong>: 论文</li>
<li><strong>保存时间</strong>: 2025-03-20T04:04:06Z</li>
<li><strong>目录日期</strong>: 2025-03-20</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://example.org/tags/human/">Human</a></li>
      <li><a href="https://example.org/tags/preference%E7%BD%91%E9%A1%B5%E9%93%BE%E6%8E%A5%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E7%A0%94%E7%A9%B6%E4%BA%86%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8Bcodellms%E7%9A%84%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E5%92%8C%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%81%8F%E5%A5%BD%E5%AF%B9%E9%BD%90%E7%9A%84%E9%97%AE%E9%A2%98%E7%8E%B0%E6%9C%89%E7%9A%84%E5%A4%A7%E9%83%A8/">Preference网页链接这篇论文研究了代码生成大型语言模型（codeLLMs）的性能评估和与人类偏好对齐的问题。现有的大部</a></li>
      <li><a href="https://example.org/tags/evaluating/">Evaluating</a></li>
      <li><a href="https://example.org/tags/aligning/">Aligning</a></li>
      <li><a href="https://example.org/tags/codellms/">CodeLLMs</a></li>
    </ul>
    
    

    
    <div class="tagged-related">
      <h3>相关主题</h3>
      <ul>
        <li><a href="/papers/2025-03-20/value-profiles-for-encoding-human-variation/">Value Profiles for Encoding Human Variation</a></li>
      </ul>
    </div>
<nav class="paginav">
  <a class="prev" href="https://example.org/papers/2025-03-20/aminer/">
    <span class="title">« 上一页</span>
    <br>
    <span>AMiner——新一代智能型科技情报挖掘与服务系统，能够为你提供查找论文、理解论文、分析论文、写作论文四位一体一站式服务，拥有中英文文献检索、文献辅助阅读、...</span>
  </a>
  <a class="next" href="https://example.org/papers/2025-03-20/florence-vl-enhancing-vision-language-models-with-/">
    <span class="title">下一页 »</span>
    <br>
    <span>Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion网页链接本文提出了一种名为Florence-VL的新型多模态...</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
    <footer>
        <p>&copy; 2025 AI研究资料库</p>
    </footer>
</body>
</html> 