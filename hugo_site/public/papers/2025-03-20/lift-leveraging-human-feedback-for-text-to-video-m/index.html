<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment网页链接本文提出了一种新的微调方法LiFT，通过利用人工反馈来优化文本到视频生成模型的匹... - AI研究资料库</title>
    <link rel="stylesheet" href="/css/style.css">
</head>
<body>
    
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark');
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <div class="header-content">
        <h1><a href="/">AI研究资料库</a></h1>
        <nav>
            
            <a href="/papers/">论文</a>
            
            <a href="/tags/">标签</a>
            
            <a href="/categories/">分类</a>
            
            <a href="/search/">搜索</a>
            
        </nav>
        
<div class="language-switcher">
    
    <a href="https://example.org/" class="active">
        中文
    </a>
    
    <a href="https://example.org/en/" class="">
        English
    </a>
    
</div>
 
    </div>
</header> 
    
    <main>
        

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://example.org/">首页</a>&nbsp;»&nbsp;<a href="https://example.org/papers/">Papers</a></div>
    <h1 class="post-title">
      LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment网页链接本文提出了一种新的微调方法LiFT，通过利用人工反馈来优化文本到视频生成模型的匹...
    </h1>
    <div class="post-meta"><span title='2025-03-20 04:05:00 +0000 +0000'>三月 20, 2025</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;AI Research Repository&nbsp;|&nbsp;<a href="https://github.com/yourusername/yourrepository/tree/main/content/papers/2025-03-20/lift-leveraging-human-feedback-for-text-to-video-m.md" rel="noopener noreferrer" target="_blank">建议修改</a>

</div>
  </header> 
  <div class="original-link">
    <a href="https://weibo.com/1870858943/P4kWe0L4G" target="_blank" rel="noopener">查看原文</a>
  </div>

  <div class="post-content"><h1 id="lift-leveraging-human-feedback-for-text-to-video-model-alignment网页链接本文提出了一种新的微调方法lift通过利用人工反馈来优化文本到视频生成模型的匹">LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment网页链接本文提出了一种新的微调方法LiFT，通过利用人工反馈来优化文本到视频生成模型的匹&hellip;<a hidden class="anchor" aria-hidden="true" href="#lift-leveraging-human-feedback-for-text-to-video-model-alignment网页链接本文提出了一种新的微调方法lift通过利用人工反馈来优化文本到视频生成模型的匹">#</a></h1>
<p><strong>原始链接</strong>: <a href="https://weibo.com/1870858943/P4kWe0L4G">查看原文</a></p>
<h2 id="原始摘要">原始摘要<a hidden class="anchor" aria-hidden="true" href="#原始摘要">#</a></h2>
<p>LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fwww.aminer.cn%2Fpub%2F675659efae8580e7ff8d68a8%2F%3Ff%3Dwb" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>本文提出了一种新的微调方法LiFT，通过利用人工反馈来优化文本到视频生成模型的匹配度。研究团队首先构建了一个包含大约1万个由人工评分及其理由组成的人类评分注释数据集LiFT-HRA。基于此数据集，训练了一个奖励模型LiFT-Critic，该模型可以有效地学习奖励函数，作为人类判断的代理，衡量给定视频与人类期望之间的匹配度。最后，利用学到的奖励函数通过最大化奖励加权的似然性来调整T2V模型。以CogVideoX-2B为案例，研究结果显示经过微调的模型在所有16项指标上均优于CogVideoX-5B，证明了人类反馈在提高生成视频的匹配度和质量方面的潜力。<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#生成模型#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#奖励模型#</span></a><a href="https://m.weibo.cn/p/index?extparam=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;containerid=100808f068f0dad74789bee210163c40a4b50d" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://n.sinaimg.cn/photo/5213b46e/20180926/timeline_card_small_super_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">人工智能</span></a><a href="https://m.weibo.cn/p/index?extparam=%E7%A1%95%E5%A3%AB%E8%AE%BA%E6%96%87&amp;containerid=1008084cacf38f5903dc7b04550404d0bd3608" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://n.sinaimg.cn/photo/5213b46e/20180926/timeline_card_small_super_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">硕士论文</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23" data-hide=""><span class="surl-text">#开源#</span></a><img style="" src="https://tvax4.sinaimg.cn/large/6f830abfly1hwgrb57m70j22cl18bnpd.jpg" referrerpolicy="no-referrer"><br><br></p>
<h2 id="ai-摘要">AI 摘要<a hidden class="anchor" aria-hidden="true" href="#ai-摘要">#</a></h2>
<p>本文介绍了一种名为LiFT的新微调方法，旨在通过利用人工反馈来优化文本到视频生成模型的匹配度。研究团队首先构建了一个包含1万个人工评分及其理由的数据集LiFT-HRA，并基于此训练了一个奖励模型LiFT-Critic，该模型能够学习奖励函数，作为人类判断的代理，衡量视频与人类期望的匹配度。最后，利用学到的奖励函数通过最大化奖励加权的似然性来调整T2V模型。实验结果显示，经过微调的模型在所有16项指标上均优于CogVideoX-5B，证明了人类反馈在提高生成视频匹配度和质量方面的潜力。</p>
<h2 id="元数据">元数据<a hidden class="anchor" aria-hidden="true" href="#元数据">#</a></h2>
<ul>
<li><strong>来源</strong>: ArXiv</li>
<li><strong>类型</strong>: 论文</li>
<li><strong>保存时间</strong>: 2025-03-20T04:05:11Z</li>
<li><strong>目录日期</strong>: 2025-03-20</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://example.org/tags/feedback/">Feedback</a></li>
      <li><a href="https://example.org/tags/text-to-video/">Text-to-Video</a></li>
      <li><a href="https://example.org/tags/model/">Model</a></li>
      <li><a href="https://example.org/tags/alignment%E7%BD%91%E9%A1%B5%E9%93%BE%E6%8E%A5%E6%9C%AC%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95lift%E9%80%9A%E8%BF%87%E5%88%A9%E7%94%A8%E4%BA%BA%E5%B7%A5%E5%8F%8D%E9%A6%88%E6%9D%A5%E4%BC%98%E5%8C%96%E6%96%87%E6%9C%AC%E5%88%B0%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8C%B9/">Alignment网页链接本文提出了一种新的微调方法LiFT，通过利用人工反馈来优化文本到视频生成模型的匹</a></li>
      <li><a href="https://example.org/tags/lift/">LiFT</a></li>
    </ul>
    
    
    <div class="related-content">
      <h3>Related Content</h3>
      <ul>
        <li><a href="/papers/2025-03-19/cosmos-world-foundation-model-platform-for-physica/">Cosmos World Foundation Model Platform for Physical AI</a></li>
      </ul>
    </div>

    
    <div class="tagged-related">
      <h3>相关主题</h3>
      <ul>
        <li><a href="/papers/2025-03-20/more-information-is-not-always-better-connections-/">More Information is Not Always Better: Connections between Zero-Sum Local Nash Equilibria in Feedback and Open-Loop Information Patterns</a></li>
        <li><a href="/papers/2025-03-19/cosmos-world-foundation-model-platform-for-physica/">Cosmos World Foundation Model Platform for Physical AI</a></li>
      </ul>
    </div>
<nav class="paginav">
  <a class="prev" href="https://example.org/papers/2025-03-20/value-profiles-for-encoding-human-variation/">
    <span class="title">« 上一页</span>
    <br>
    <span>Value Profiles for Encoding Human Variation</span>
  </a>
  <a class="next" href="https://example.org/papers/2025-03-20/aminer/">
    <span class="title">下一页 »</span>
    <br>
    <span>AMiner——新一代智能型科技情报挖掘与服务系统，能够为你提供查找论文、理解论文、分析论文、写作论文四位一体一站式服务，拥有中英文文献检索、文献辅助阅读、...</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
    <footer>
        <p>&copy; 2025 AI研究资料库</p>
    </footer>
</body>
</html> 