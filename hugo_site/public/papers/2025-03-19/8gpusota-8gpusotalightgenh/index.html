<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>#8张GPU训出近SOTA模型# 超低成本图像生成预训练方案来了——仅需8张GPU训练，就能实现近SOTA的高质量图像生成效果。划重点：开源。模型名为LightGen，由港科大H... - AI研究资料库</title>
    <link rel="stylesheet" href="/css/style.css">
</head>
<body>
    
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark');
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <div class="header-content">
        <h1><a href="/">AI研究资料库</a></h1>
        <nav>
            
            <a href="/papers/">论文</a>
            
            <a href="/tags/">标签</a>
            
            <a href="/categories/">分类</a>
            
            <a href="/search/">搜索</a>
            
        </nav>
        
<div class="language-switcher">
    
    <a href="https://example.org/" class="active">
        中文
    </a>
    
    <a href="https://example.org/en/" class="">
        English
    </a>
    
</div>
 
    </div>
</header> 
    
    <main>
        

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://example.org/">首页</a>&nbsp;»&nbsp;<a href="https://example.org/papers/">Papers</a></div>
    <h1 class="post-title">
      #8张GPU训出近SOTA模型# 超低成本图像生成预训练方案来了——仅需8张GPU训练，就能实现近SOTA的高质量图像生成效果。划重点：开源。模型名为LightGen，由港科大H...
    </h1>
    <div class="post-meta"><span title='2025-03-19 23:04:00 +0000 +0000'>三月 19, 2025</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;AI Research Repository&nbsp;|&nbsp;<a href="https://github.com/yourusername/yourrepository/tree/main/content/papers/2025-03-19/8gpusota-8gpusotalightgenh.md" rel="noopener noreferrer" target="_blank">建议修改</a>

</div>
  </header> 
  <div class="original-link">
    <a href="https://weibo.com/6105753431/PjfF42Dzu" target="_blank" rel="noopener">查看原文</a>
  </div>

  <div class="post-content"><h1 id="8张gpu训出近sota模型-超低成本图像生成预训练方案来了仅需8张gpu训练就能实现近sota的高质量图像生成效果划重点开源模型名为lightgen由港科大h">#8张GPU训出近SOTA模型# 超低成本图像生成预训练方案来了——仅需8张GPU训练，就能实现近SOTA的高质量图像生成效果。划重点：开源。模型名为LightGen，由港科大H&hellip;<a hidden class="anchor" aria-hidden="true" href="#8张gpu训出近sota模型-超低成本图像生成预训练方案来了仅需8张gpu训练就能实现近sota的高质量图像生成效果划重点开源模型名为lightgen由港科大h">#</a></h1>
<p><strong>原始链接</strong>: <a href="https://weibo.com/6105753431/PjfF42Dzu">查看原文</a></p>
<h2 id="原始摘要">原始摘要<a hidden class="anchor" aria-hidden="true" href="#原始摘要">#</a></h2>
<p><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%238%E5%BC%A0GPU%E8%AE%AD%E5%87%BA%E8%BF%91SOTA%E6%A8%A1%E5%9E%8B%23&amp;extparam=%238%E5%BC%A0GPU%E8%AE%AD%E5%87%BA%E8%BF%91SOTA%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#8张GPU训出近SOTA模型#</span></a> <br>超低成本图像生成预训练方案来了——<br><br>仅需8张GPU训练，就能实现近SOTA的高质量图像生成效果。<br><br>划重点：开源。<br><br>模型名为LightGen，由港科大Harry Yang团队联合Everlyn AI等机构打造，借助知识蒸馏（KD）和直接偏好优化（DPO）策略，有效压缩了大规模图像生成模型的训练流程。<br><br>LightGen不仅显著降低了数据规模与计算资源需求，而且在高质量图像生成任务上展现了与SOTA模型相媲美的性能。<br><br>LightGen相较于现有的生成模型，尽管参数量更小、预训练数据规模更精简，却在geneval图像生成任务的基准评测中甚至超出了部分最先进SOTA模型。<br><br>此外，LightGen在效率与性能之间实现了良好的平衡，成功地将传统上需要数千GPU days的预训练过程缩短至仅88个GPU days，即可完成高质量图像生成模型的训练。<br><br>以下是更多细节。<br><a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fmp.toutiao.com%2Fprofile_v4%2Fgraphic%2Fpreview%3Fpgc_id%3D7483368874113745417" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><img style="" src="https://tvax3.sinaimg.cn/large/006Fd7o3gy1hzm5rp9kd9j30u00u0e81.jpg" referrerpolicy="no-referrer"><br><br></p>
<h2 id="ai-摘要">AI 摘要<a hidden class="anchor" aria-hidden="true" href="#ai-摘要">#</a></h2>
<p>港科大Harry Yang团队与Everlyn AI等机构合作开发了名为LightGen的开源图像生成模型。该模型通过知识蒸馏和直接偏好优化策略，显著降低了训练所需的数据规模和计算资源，仅需8张GPU即可实现接近SOTA的高质量图像生成效果。LightGen在参数量和预训练数据规模上更为精简，但在图像生成任务中表现优异，甚至超越部分现有SOTA模型。此外，LightGen将传统上需要数千GPU天的预训练过程缩短至仅88个GPU天，实现了效率与性能的良好平衡。</p>
<h2 id="元数据">元数据<a hidden class="anchor" aria-hidden="true" href="#元数据">#</a></h2>
<ul>
<li><strong>来源</strong>: ArXiv</li>
<li><strong>类型</strong>: 论文</li>
<li><strong>保存时间</strong>: 2025-03-19T23:04:39Z</li>
<li><strong>目录日期</strong>: 2025-03-19</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://example.org/tags/8%E5%BC%A0gpu%E8%AE%AD%E5%87%BA%E8%BF%91sota%E6%A8%A1%E5%9E%8B%23/">8张GPU训出近SOTA模型#</a></li>
      <li><a href="https://example.org/tags/yang%E5%9B%A2%E9%98%9F%E4%B8%8Eeverlyn/">Yang团队与Everlyn</a></li>
      <li><a href="https://example.org/tags/ai%E7%AD%89%E6%9C%BA%E6%9E%84%E5%90%88%E4%BD%9C%E5%BC%80%E5%8F%91%E4%BA%86%E5%90%8D%E4%B8%BAlightgen%E7%9A%84%E5%BC%80%E6%BA%90%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E8%AF%A5%E6%A8%A1%E5%9E%8B%E9%80%9A%E8%BF%87%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E5%92%8C%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5%E6%98%BE%E8%91%97%E9%99%8D%E4%BD%8E%E4%BA%86%E8%AE%AD%E7%BB%83%E6%89%80%E9%9C%80%E7%9A%84%E6%95%B0%E6%8D%AE%E8%A7%84%E6%A8%A1%E5%92%8C%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E4%BB%85%E9%9C%808%E5%BC%A0gpu%E5%8D%B3%E5%8F%AF%E5%AE%9E%E7%8E%B0%E6%8E%A5%E8%BF%91sota%E7%9A%84%E9%AB%98%E8%B4%A8%E9%87%8F%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%95%88%E6%9E%9Clightgen%E5%9C%A8%E5%8F%82%E6%95%B0%E9%87%8F%E5%92%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E8%A7%84%E6%A8%A1%E4%B8%8A%E6%9B%B4%E4%B8%BA%E7%B2%BE%E7%AE%80%E4%BD%86%E5%9C%A8%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1%E4%B8%AD%E8%A1%A8%E7%8E%B0%E4%BC%98%E5%BC%82%E7%94%9A%E8%87%B3%E8%B6%85%E8%B6%8A%E9%83%A8%E5%88%86%E7%8E%B0%E6%9C%89sota%E6%A8%A1%E5%9E%8B%E6%AD%A4%E5%A4%96lightgen%E5%B0%86%E4%BC%A0%E7%BB%9F%E4%B8%8A%E9%9C%80%E8%A6%81%E6%95%B0%E5%8D%83gpu%E5%A4%A9%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E7%BC%A9%E7%9F%AD%E8%87%B3%E4%BB%8588%E4%B8%AAgpu%E5%A4%A9%E5%AE%9E%E7%8E%B0%E4%BA%86%E6%95%88%E7%8E%87%E4%B8%8E%E6%80%A7%E8%83%BD%E7%9A%84%E8%89%AF%E5%A5%BD%E5%B9%B3%E8%A1%A1/">AI等机构合作开发了名为LightGen的开源图像生成模型。该模型通过知识蒸馏和直接偏好优化策略，显著降低了训练所需的数据规模和计算资源，仅需8张GPU即可实现接近SOTA的高质量图像生成效果。LightGen在参数量和预训练数据规模上更为精简，但在图像生成任务中表现优异，甚至超越部分现有SOTA模型。此外，LightGen将传统上需要数千GPU天的预训练过程缩短至仅88个GPU天，实现了效率与性能的良好平衡。</a></li>
    </ul>
    
    

    
    <div class="tagged-related">
      <h3>相关主题</h3>
      <ul>
        <li><a href="/papers/2025-03-20/8gpusota-8gpusotalightgenh/">#8张GPU训出近SOTA模型# 超低成本图像生成预训练方案来了——仅需8张GPU训练，就能实现近SOTA的高质量图像生成效果。划重点：开源。模型名为LightGen，由港科大H...</a></li>
      </ul>
    </div>
<nav class="paginav">
  <a class="prev" href="https://example.org/papers/2025-03-20/8gpusota-8gpusotalightgenh/">
    <span class="title">« 上一页</span>
    <br>
    <span>#8张GPU训出近SOTA模型# 超低成本图像生成预训练方案来了——仅需8张GPU训练，就能实现近SOTA的高质量图像生成效果。划重点：开源。模型名为LightGen，由港科大H...</span>
  </a>
  <a class="next" href="https://example.org/papers/2025-03-19/33htmlpython/">
    <span class="title">下一页 »</span>
    <br>
    <span>#豆包编程能力升级##用豆包3分钟做个小游戏#豆包编程能力升级了，现在3分钟就能做出专属小游戏。升级后，豆包支持HTML代码实时预览、Python运行，甚至是生成完整...</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
    <footer>
        <p>&copy; 2025 AI研究资料库</p>
    </footer>
</body>
</html> 