<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>路由LLM最全面探索##笔记本也能玩的大模型Scaling - AI研究资料库</title>
    <link rel="stylesheet" href="/css/style.css">
</head>
<body>
    
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark');
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <div class="header-content">
        <h1><a href="/">AI研究资料库</a></h1>
        <nav>
            
            <a href="/papers/">论文</a>
            
            <a href="/tags/">标签</a>
            
            <a href="/categories/">分类</a>
            
            <a href="/search/">搜索</a>
            
        </nav>
        
<div class="language-switcher">
    
    <a href="https://example.org/" class="active">
        中文
    </a>
    
    <a href="https://example.org/en/" class="">
        English
    </a>
    
</div>
 
    </div>
</header> 
    
    <main>
        
<section class="taxonomy-list">
    <h1>路由LLM最全面探索##笔记本也能玩的大模型Scaling</h1>
    <div class="papers-list">
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/llmscaling-up-llmrouting-llm8500llm/">#路由LLM最全面探索##笔记本也能玩的大模型Scaling Up研究# 事关路由LLM（Routing LLM），一项截至目前最全面的研究，来了——共计收集和整理了涉及8500&#43;个LLM，...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                中山大学和普渡大学的研究团队对路由LLM（Routing LLM）进行了迄今为止最全面的研究，涉及8500多个LLM在12个基准测试中的2亿条性能记录。路由LLM通过将多个LLM视为“专家”，并由Router（路由器）根据输入选择最合适的LLM进行处理，从而实现高性能、低计算消耗和低幻觉的目标。研究发现，随着LLM候选数量的增加，路由LLM的性能显著提升，称为“Model-level Scaling Up”。团队还开发了RouterEval评测工具，使其他研究人员能够在有限的计算资源（如笔记本或单卡GPU）上参与路由LLM的研究。
            </div>
            <a href="/papers/2025-03-20/llmscaling-up-llmrouting-llm8500llm/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-19/llmscaling-up-llmrouting-llm8500llm/">#路由LLM最全面探索##笔记本也能玩的大模型Scaling Up研究# 事关路由LLM（Routing LLM），一项截至目前最全面的研究，来了——共计收集和整理了涉及8500&#43;个LLM，...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-19</span>
            </div>
            <div class="summary">
                中山大学和普渡大学的研究团队进行了一项关于路由LLM（Routing LLM）的全面研究，涉及8500多个大型语言模型（LLM）在12个基准测试上的2亿条性能记录。路由LLM通过将输入分配给最合适的LLM处理，旨在实现高性能、低计算消耗和减少幻觉。研究发现，随着LLM候选数量的增加，路由LLM的性能显著提升，这一现象被称为“Model-level Scaling Up”。此外，团队开发了RouterEval评测工具，使其他研究人员能在有限计算资源（如笔记本或单卡GPU）上参与路由LLM的研究。
            </div>
            <a href="/papers/2025-03-19/llmscaling-up-llmrouting-llm8500llm/" class="read-more">阅读更多</a>
        </article>
        
    </div>
</section>

    </main>
    
    <footer>
        <p>&copy; 2025 AI研究资料库</p>
    </footer>
</body>
</html> 