<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Model on AI研究资料库</title>
    <link>https://example.org/tags/model/</link>
    <description>Recent content in Model on AI研究资料库</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>zh</language>
    <lastBuildDate>Thu, 20 Mar 2025 04:05:00 +0000</lastBuildDate>
    <atom:link href="https://example.org/tags/model/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment网页链接本文提出了一种新的微调方法LiFT，通过利用人工反馈来优化文本到视频生成模型的匹...</title>
      <link>https://example.org/papers/2025-03-20/lift-leveraging-human-feedback-for-text-to-video-m/</link>
      <pubDate>Thu, 20 Mar 2025 04:05:00 +0000</pubDate>
      <guid>https://example.org/papers/2025-03-20/lift-leveraging-human-feedback-for-text-to-video-m/</guid>
      <description>本文介绍了一种名为LiFT的新微调方法，旨在通过利用人工反馈来优化文本到视频生成模型的匹配度。研究团队首先构建了一个包含1万个人工评分及其理由的数据集LiFT-HRA，并基于此训练了一个奖励模型LiFT-Critic，该模型能够学习奖励函数，作为人类判断的代理，衡量视频与人类期望的匹配度。最后，利用学到的奖励函数通过最大化奖励加权的似然性来调整T2V模型。实验结果显示，经过微调的模型在所有16项指标上均优于CogVideoX-5B，证明了人类反馈在提高生成视频匹配度和质量方面的潜力。</description>
      <content:encoded><![CDATA[<h1 id="lift-leveraging-human-feedback-for-text-to-video-model-alignment网页链接本文提出了一种新的微调方法lift通过利用人工反馈来优化文本到视频生成模型的匹">LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment网页链接本文提出了一种新的微调方法LiFT，通过利用人工反馈来优化文本到视频生成模型的匹&hellip;</h1>
<p><strong>原始链接</strong>: <a href="https://weibo.com/1870858943/P4kWe0L4G">查看原文</a></p>
<h2 id="原始摘要">原始摘要</h2>
<p>LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment<a href="https://weibo.cn/sinaurl?u=https%3A%2F%2Fwww.aminer.cn%2Fpub%2F675659efae8580e7ff8d68a8%2F%3Ff%3Dwb" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://h5.sinaimg.cn/upload/2015/09/25/3/timeline_card_small_web_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">网页链接</span></a><br>本文提出了一种新的微调方法LiFT，通过利用人工反馈来优化文本到视频生成模型的匹配度。研究团队首先构建了一个包含大约1万个由人工评分及其理由组成的人类评分注释数据集LiFT-HRA。基于此数据集，训练了一个奖励模型LiFT-Critic，该模型可以有效地学习奖励函数，作为人类判断的代理，衡量给定视频与人类期望之间的匹配度。最后，利用学到的奖励函数通过最大化奖励加权的似然性来调整T2V模型。以CogVideoX-2B为案例，研究结果显示经过微调的模型在所有16项指标上均优于CogVideoX-5B，证明了人类反馈在提高生成视频的匹配度和质量方面的潜力。<a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#生成模型#</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B%23&amp;extparam=%23%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B%23" data-hide=""><span class="surl-text">#奖励模型#</span></a><a href="https://m.weibo.cn/p/index?extparam=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;containerid=100808f068f0dad74789bee210163c40a4b50d" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://n.sinaimg.cn/photo/5213b46e/20180926/timeline_card_small_super_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">人工智能</span></a><a href="https://m.weibo.cn/p/index?extparam=%E7%A1%95%E5%A3%AB%E8%AE%BA%E6%96%87&amp;containerid=1008084cacf38f5903dc7b04550404d0bd3608" data-hide=""><span class="url-icon"><img style="width: 1rem;height: 1rem" src="https://n.sinaimg.cn/photo/5213b46e/20180926/timeline_card_small_super_default.png" referrerpolicy="no-referrer"></span><span class="surl-text">硕士论文</span></a><a href="https://m.weibo.cn/search?containerid=231522type%3D1%26t%3D10%26q%3D%23%E5%BC%80%E6%BA%90%23" data-hide=""><span class="surl-text">#开源#</span></a><img style="" src="https://tvax4.sinaimg.cn/large/6f830abfly1hwgrb57m70j22cl18bnpd.jpg" referrerpolicy="no-referrer"><br><br></p>
<h2 id="ai-摘要">AI 摘要</h2>
<p>本文介绍了一种名为LiFT的新微调方法，旨在通过利用人工反馈来优化文本到视频生成模型的匹配度。研究团队首先构建了一个包含1万个人工评分及其理由的数据集LiFT-HRA，并基于此训练了一个奖励模型LiFT-Critic，该模型能够学习奖励函数，作为人类判断的代理，衡量视频与人类期望的匹配度。最后，利用学到的奖励函数通过最大化奖励加权的似然性来调整T2V模型。实验结果显示，经过微调的模型在所有16项指标上均优于CogVideoX-5B，证明了人类反馈在提高生成视频匹配度和质量方面的潜力。</p>
<h2 id="元数据">元数据</h2>
<ul>
<li><strong>来源</strong>: ArXiv</li>
<li><strong>类型</strong>: 论文</li>
<li><strong>保存时间</strong>: 2025-03-20T04:05:11Z</li>
<li><strong>目录日期</strong>: 2025-03-20</li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>Cosmos World Foundation Model Platform for Physical AI</title>
      <link>https://example.org/papers/2025-03-19/cosmos-world-foundation-model-platform-for-physica/</link>
      <pubDate>Wed, 19 Mar 2025 23:02:00 +0000</pubDate>
      <guid>https://example.org/papers/2025-03-19/cosmos-world-foundation-model-platform-for-physica/</guid>
      <description>本文介绍了Cosmos世界基础模型平台，旨在帮助开发者为其物理AI系统构建定制化的世界模型。该平台包括视频处理管道、预训练的世界基础模型、模型微调示例和视频标记器。世界基础模型作为通用模型，可微调为下游应用的定制模型。为促进物理AI解决社会关键问题，Cosmos平台开源并提供开放权重模型，许可宽松，可通过https://github.com/nvidia-cosmos/cosmos-predict1获取。</description>
      <content:encoded><![CDATA[<h1 id="cosmos-world-foundation-model-platform-for-physical-ai">Cosmos World Foundation Model Platform for Physical AI</h1>
<p><strong>原始链接</strong>: <a href="http://arxiv.org/abs/2501.03575v2">查看原文</a></p>
<h2 id="原始摘要">原始摘要</h2>
<p>Physical AI needs to be trained digitally first. It needs a digital twin of
itself, the policy model, and a digital twin of the world, the world model. In
this paper, we present the Cosmos World Foundation Model Platform to help
developers build customized world models for their Physical AI setups. We
position a world foundation model as a general-purpose world model that can be
fine-tuned into customized world models for downstream applications. Our
platform covers a video curation pipeline, pre-trained world foundation models,
examples of post-training of pre-trained world foundation models, and video
tokenizers. To help Physical AI builders solve the most critical problems of
our society, we make Cosmos open-source and our models open-weight with
permissive licenses available via
<a href="https://github.com/nvidia-cosmos/cosmos-predict1">https://github.com/nvidia-cosmos/cosmos-predict1</a>.</p>
<h2 id="ai-摘要">AI 摘要</h2>
<p>本文介绍了Cosmos世界基础模型平台，旨在帮助开发者为其物理AI系统构建定制化的世界模型。该平台包括视频处理管道、预训练的世界基础模型、模型微调示例和视频标记器。世界基础模型作为通用模型，可微调为下游应用的定制模型。为促进物理AI解决社会关键问题，Cosmos平台开源并提供开放权重模型，许可宽松，可通过https://github.com/nvidia-cosmos/cosmos-predict1获取。</p>
<h2 id="元数据">元数据</h2>
<ul>
<li><strong>来源</strong>: ArXiv</li>
<li><strong>类型</strong>: 论文</li>
<li><strong>保存时间</strong>: 2025-03-19T23:02:31Z</li>
<li><strong>目录日期</strong>: 2025-03-19</li>
</ul>
]]></content:encoded>
    </item>
  </channel>
</rss>
