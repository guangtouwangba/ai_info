<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>2025-03-20 - AI研究资料库</title>
    <link rel="stylesheet" href="/css/style.css">
</head>
<body>
    
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark');
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <div class="header-content">
        <h1><a href="/">AI研究资料库</a></h1>
        <nav>
            
            <a href="/papers/">论文</a>
            
            <a href="/tags/">标签</a>
            
            <a href="/categories/">分类</a>
            
            <a href="/search/">搜索</a>
            
        </nav>
        
<div class="language-switcher">
    
    <a href="https://example.org/" class="active">
        中文
    </a>
    
    <a href="https://example.org/en/" class="">
        English
    </a>
    
</div>
 
    </div>
</header> 
    
    <main>
        
<section class="taxonomy-list">
    <h1>2025-03-20</h1>
    <div class="papers-list">
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/20242025/">#小米汽车透露今年愿景#在财报电话会议上，小米总裁卢伟冰透露了小米汽车今年的新前景。2024年，小米汽车的关键词是“增长”，而2025年，则是“智能化”。卢伟冰...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                在2024年财报电话会议上，小米总裁卢伟冰透露了小米汽车的发展愿景。2024年的关键词是“增长”，而2025年则是“智能化”。小米计划在智能驾驶领域实现“一年追三代”，并加大AI研发投入，目标在2025年进入自动驾驶第一梯队。目前，小米的智驾系统已实现高速NOA、端到端泊车等功能，2024年目标是优化全场景智驾，实现“车位到车位”自动驾驶。此外，小米计划在2024年底推出SUV车型YU7，并加速全球化布局，计划2027年启动海外销售，挑战特斯拉Model Y的销量地位。
            </div>
            <a href="/papers/2025-03-20/20242025/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/365935/">#小米史上最强年报#去年是小米集团成立以来，业绩最辉煌的一年。据小米年报显示，小米集团全年营收高达3659亿元，同比增长35%，第四季度更是首次突破千亿大关，...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                小米集团2022年财报显示，全年营收达3659亿元，同比增长35%，净利润272亿元，增长41.3%。智能手机业务收入1918亿元，同比增长21.8%，高端化战略初见成效。IoT与生活消费产品收入1041亿元，增长30%，互联网服务收入341亿元，增长13.3%。研发投入240.5亿元，增长26%，重点投入AI和智能驾驶。全年毛利率20.9%，汽车业务毛利率突破20%，为未来盈利奠定基础。财报显示小米多元化布局进入收获期，业绩增长强劲。
            </div>
            <a href="/papers/2025-03-20/365935/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/g1/">#机器人会侧空翻了##全球首次人形机器人原地侧空翻#宇树科技的G1人形机器人，刚刚完成了全球首次原地侧空翻动作。官方发布的【视频】显示，机器人不仅顺利完成侧...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                宇树科技的G1人形机器人成功完成了全球首次原地侧空翻动作，展示了其流畅的翻滚和协调的机身动作。这一成就体现了团队在动力学算法和机械设计方面的实力。去年，宇树科技曾用H1机器人完成全球首个电机驱动人形机器人后空翻。尽管这一技术突破令人印象深刻，但有网友表示，他们更希望看到机器人执行如做家务等实用性任务。
            </div>
            <a href="/papers/2025-03-20/g1/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/gtc-gtcnewtongroot-n1-/">#老黄带迪士尼机器人炸场GTC# 老黄带着迪士尼机器人炸场GTC，现场发布机器人物理引擎Newton、基础模型GROOT N1，他还预言：机器人将会是未来最大的行业。 量子位...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                在GTC大会上，老黄展示了迪士尼机器人，并发布了机器人物理引擎Newton和基础模型GROOT N1。他预测机器人将成为未来最大的行业。这一展示突显了机器人在娱乐和技术领域的潜力，预示着机器人技术的快速发展及其在各行业的广泛应用。
            </div>
            <a href="/papers/2025-03-20/gtc-gtcnewtongroot-n1-/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/pebblepebblepebble/">#苹果限制第三方智能手表##智能手表鼻祖Pebble回归#Pebble，这款智能手表的鼻祖，凭借超长续航和极简设计，被无数科技极客奉为神器。尽管Pebble品牌早已停止运营...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                Pebble智能手表鼻祖回归，推出Core 2 Duo和Core Time 2两款新品。Core 2 Duo延续经典设计，配备1.26英寸黑白电子墨水屏和30天续航，售价149美元。Core Time 2则更先进，拥有1.5英寸64色电子墨水屏、金属机身和心率监测功能，售价225美元。两款手表均开放源代码，支持开发者自由修改。然而，PebbleOS手表在iPhone上使用受限，无法发送短信、快速回复消息等，导致其在Android上的体验优于iOS。苹果对此限制的解释是出于安全、隐私和用户体验考虑，但美国司法部已展开反垄断调查。
            </div>
            <a href="/papers/2025-03-20/pebblepebblepebble/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/aiaichatbot-arenasearch-arenaai/">#搜索竞技场上线##AI联网搜索竞技场#AI联网搜索这一块，也有竞技场了。Chatbot Arena做了个搜索竞技场（Search Arena），这是一个盲测AI的搜索能力的平台，用户...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                Chatbot Arena推出了“搜索竞技场”（Search Arena），这是一个盲测AI搜索能力的平台。用户可以通过投票比较不同模型的搜索效果。例如，用户提问“下次月全食是什么时候？”，平台会展示两个模型的回答，并揭示答案来源。Search Arena还支持图片对话、文生图（Text-to-Image）以及与GitHub代码仓库对话等功能，方便开发者查代码。平台展示了多个对比案例，如总结论文、撰写文章等，用户可自行判断哪个模型表现更好。
            </div>
            <a href="/papers/2025-03-20/aiaichatbot-arenasearch-arenaai/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/su7136/">#小米成中国市值第一车企#小米SU7的热销不仅助推公司营收增长，更是带动了股价暴涨。短短一年，小米市值翻了近四倍，突破1.36万亿元，超越比亚迪，成了中国市值...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                小米凭借其SU7车型的热销，市值在一年内翻了近四倍，达到1.36万亿元，超越比亚迪成为中国市值最高的汽车制造商。这一成就得益于小米的“手机+AI+汽车”一体化生态战略及其在供应链、技术积累和用户流量上的优势。小米SU7自上市以来销量迅速增长，7个月内单月销量突破2万，并创下新势力最快十万台下线纪录。小米已将年交付目标提升至35万辆，并计划推出第二款SUV车型YU7，以进一步扩大市场份额。市值的飙升反映了资本市场对小米前景的看好。
            </div>
            <a href="/papers/2025-03-20/su7136/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/ai-galgameaigal/">【#AI实时汉化游戏# 】其实不止Galgame……各种其他类型的游戏都可以用AI来翻译游玩，这期视频用Gal举例是因为文字对这类游戏至关重要，体验起来会更明显。啊我...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                该微博讨论了AI技术在游戏实时汉化中的应用，特别是以Galgame为例，因为这类游戏的文字内容对玩家体验至关重要。视频展示了AI如何通过大模型和LM-Studio等工具实现游戏的实时翻译，提升玩家的游戏体验。此外，视频还提供了相关文件的下载链接，供用户进一步了解和尝试。整体内容强调了AI在游戏翻译中的潜力及其对玩家体验的积极影响。
            </div>
            <a href="/papers/2025-03-20/ai-galgameaigal/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/openai-deepseek270deepseek-r1270openaiopenaio1-pro/">#OpenAI史上最贵模型来了# 比DeepSeek贵270倍比DeepSeek-R1贵270倍，OpenAI史上最贵模型来了！就在刚刚，OpenAI上线了推理模型o1-pro的API。本来大家还挺高兴，...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                OpenAI最近推出了其史上最贵的推理模型o1-pro的API，其价格引发了广泛争议。该模型的100万输入/输出token价格分别为150美元和600美元，相比DeepSeek模型的输出价格贵了270倍。这一高价引发了网友的强烈反应，许多人认为除非模型的智能达到爱因斯坦级别，否则不值得如此高昂的价格。关于价格的争议迅速在𝕏和Reddit等平台上展开讨论。
            </div>
            <a href="/papers/2025-03-20/openai-deepseek270deepseek-r1270openaiopenaio1-pro/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/geminip-gemini-20-flashpsp-/">#谷歌Gemini一句话P图# 没想到谷歌推出Gemini 2.0 Flash之后，最先遭殃的居然是PS。虽然不稳定，但这个靠对话就能免费P图的功能还是挺好玩的…… 量子位的微博视...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                谷歌推出的Gemini 2.0 Flash版本，通过对话即可实现免费P图功能，这一创新功能虽然尚不稳定，但其便捷性和趣味性已引起广泛关注。该功能可能对传统图像处理软件如Photoshop构成挑战，展示了AI技术在图像编辑领域的潜力。用户可以通过简单的对话指令完成复杂的图像处理任务，预示着未来图像编辑工具的发展方向。
            </div>
            <a href="/papers/2025-03-20/geminip-gemini-20-flashpsp-/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/a-role-of-environmental-complexity-on-representati/">A Role of Environmental Complexity on Representation Learning in Deep Reinforcement Learning Agents</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                研究开发了一个模拟环境，用于训练深度强化学习代理在捷径使用导航任务中的表现，灵感来自人类导航者的双解决方案范式测试。研究发现，代理在封闭捷径试验中一旦开始学习，便能迅速达到最佳表现。高频率接触捷径的代理在捷径开放时导航速度和捷径使用更快。分析显示，频繁呈现的导航线索在初期能更好地编码于单个节点中，但更强的线索表示是通过导航规划中的使用形成的。空间表示在训练早期发展并稳定，而计划轨迹而非当前位置在代理网络中编码，且编码在群体而非单个节点水平上表示。
            </div>
            <a href="/papers/2025-03-20/a-role-of-environmental-complexity-on-representati/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/developer-perspectives-on-licensing-and-copyright-/">Developer Perspectives on Licensing and Copyright Issues Arising from Generative AI for Software Development</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文探讨了生成式AI（GenAI）工具在编码任务中的应用及其引发的法律问题，特别是版权法相关的风险。通过对574名开发者的调查和后续访谈，研究捕捉了开发者对GenAI快速演变中的看法，并分析了他们的观点。结果显示，开发者从GenAI中获益，认为使用AI生成的代码与现有代码类似，但对代码所有权和补偿问题意见不一，且担忧数据泄露。这些发现为组织和政策制定者提供了关于技术使用和利益相关者关注点的宝贵见解，有助于未来监管决策。
            </div>
            <a href="/papers/2025-03-20/developer-perspectives-on-licensing-and-copyright-/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/hybrid-quantum-classical-reinforcement-learning-in/">Hybrid Quantum-Classical Reinforcement Learning in Latent Observation Spaces</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                量子机器学习的最新进展激发了利用量子强化学习方法解决经典控制问题的兴趣。然而，经典强化学习环境通常涉及高维问题空间，这对量子代理实现的有限且昂贵的资源构成了挑战。为解决这一维度挑战，本文提出了一种结合经典自编码器和量子代理的混合训练方法，通过联合学习压缩的观测表示来优化控制问题和量子处理单元架构的需求。通过一系列数值实验，展示了该方法在不同控制问题和光子（连续变量）及基于量子比特的代理中的性能，证明了联合训练对量子神经网络学习过程的改进效果。
            </div>
            <a href="/papers/2025-03-20/hybrid-quantum-classical-reinforcement-learning-in/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/modeling-crystal-defects-using-defect-informed-neu/">Modeling crystal defects using defect-informed neural networks</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                机器学习在晶体材料研究中实现了快速预测和发现，但现有研究多集中于理想晶体，忽略了实际材料中的缺陷。这些缺陷和掺杂破坏了几何对称性，增加了相互作用的复杂性，对传统机器学习模型构成挑战。为此，研究者提出了缺陷信息等变图神经网络（DefiNet），专门用于捕捉点缺陷结构中的缺陷相关相互作用和几何配置。DefiNet在14,866个缺陷结构上训练，能一步实现高精度结构预测，避免了迭代过程中的误差积累。通过密度泛函理论验证，DefiNet预测的结构仅需3次离子步骤即可达到基态，展示了其在缺陷材料研究中的突破性潜力。
            </div>
            <a href="/papers/2025-03-20/modeling-crystal-defects-using-defect-informed-neu/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/resource-efficient-quantum-correlation-measurement/">Resource-Efficient Quantum Correlation Measurement: A Multicopy Neural Network Approach for Practical Applications</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                传统量子态层析（QST）方法需要重建密度矩阵，资源需求随系统规模指数增长。本文提出一种结合多拷贝测量和人工神经网络（ANN）的策略，将测量需求减少67%。实验在IBMQ处理器上使用transmon量子比特，成功测量了受退极化通道和振幅阻尼通道影响的两量子比特纠缠态。通过最大似然方法抑制噪声，并利用SHAP分析优化投影集训练ANN估计纠缠和非局域性。该方法简化了多拷贝测量，提高了噪声鲁棒性，无需复杂非线性方程分析，显著推动了AI辅助量子测量的实际应用。
            </div>
            <a href="/papers/2025-03-20/resource-efficient-quantum-correlation-measurement/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/subversion-strategy-eval-can-language-models-state/">Subversion Strategy Eval: Can language models statelessly strategize to subvert control protocols?</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文研究了AI系统在无状态操作下（即上下文间无共享内存）生成并执行策略以规避控制协议的能力。通过开发“Subversion Strategy Eval”评估套件，包含八个环境和六组功能，测试了Claude 3.5和OpenAI模型。结果显示，当前模型在无状态下规避控制协议的能力有限，但增加功能（如上下文间共享计划）可显著提升性能。该评估旨在作为模型规避控制协议能力的早期指标，并缓解AI控制评估中对完美策略能力的极端假设。评估工具已开源发布。
            </div>
            <a href="/papers/2025-03-20/subversion-strategy-eval-can-language-models-state/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/from-1000000-users-to-every-user-scaling-up-person/">From 1,000,000 Users to Every User: Scaling Up Personalized Preference for User-level Alignment</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文提出了一种可扩展的个性化对齐大语言模型（LLMs）的框架，突破了传统“一刀切”方法的局限。通过建立系统化的偏好空间和多样化的人物表征，结合包含130万个性化偏好示例的AlignX数据集，开发了两种对齐方法：基于人物表征的上下文对齐和基于中间偏好分布的偏好桥接对齐。实验表明，该方法在四个基准测试中平均提升了17.06%的准确率，展现出对新偏好的强适应性、对有限用户数据的鲁棒性以及精确的偏好控制能力，推动了真正适应用户的AI系统的发展。
            </div>
            <a href="/papers/2025-03-20/from-1000000-users-to-every-user-scaling-up-person/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/more-information-is-not-always-better-connections-/">More Information is Not Always Better: Connections between Zero-Sum Local Nash Equilibria in Feedback and Open-Loop Information Patterns</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                非合作动态博弈理论为多智能体在无通信情况下的序贯决策提供了建模方法。研究重点在于寻找不同信息结构下双智能体零和动态博弈的纳什均衡。在线性二次博弈中，反馈和开环信息结构下的唯一纳什均衡轨迹相同。本文扩展至非线性动态和非凸非凹目标函数，证明局部反馈纳什均衡（FBNE）满足局部开环纳什均衡（OLNE）的一阶和二阶最优性条件，且在满足反馈充分条件时构成局部OLNE。此外，在严格互补条件下，局部FBNE也满足局部OLNE的一阶最优性条件。
            </div>
            <a href="/papers/2025-03-20/more-information-is-not-always-better-connections-/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/sweet-rl-training-multi-turn-llm-agents-on-collabo/">SWEET-RL: Training Multi-Turn LLM Agents on Collaborative Reasoning Tasks</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                大型语言模型（LLM）代理在现实任务中需进行多轮交互，但现有多轮强化学习（RL）算法难以有效分配多轮信用并利用LLM的泛化能力。为此，研究团队提出了新基准ColBench，模拟LLM代理与人类协作解决后端编程和前端设计任务。基于此，他们开发了SWEET-RL算法，通过训练时信息优化目标训练评论家模型，提供步骤级奖励以改进策略模型。实验表明，SWEET-RL在ColBench上成功率提升6%，使Llama-3.1-8B在协作内容创作中表现媲美或超越GPT4-o。
            </div>
            <a href="/papers/2025-03-20/sweet-rl-training-multi-turn-llm-agents-on-collabo/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/value-profiles-for-encoding-human-variation/">Value Profiles for Encoding Human Variation</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本研究提出了一种通过价值档案（自然语言描述）和可调控解码器模型来建模人类评分任务中的个体差异的方法。价值档案通过上下文演示压缩生成，能够有效保留超过70%的有用信息。研究发现，演示包含最多信息，其次是价值档案和人口统计信息。价值档案在可审查性、可解释性和可调控性方面具有优势，且通过聚类价值档案能更好地解释评分者差异。解码器模型能够根据语义差异调整评分，具有良好的校准性，并能模拟注释者群体以解释实例级分歧。价值档案为描述个体差异提供了新的预测方法。
            </div>
            <a href="/papers/2025-03-20/value-profiles-for-encoding-human-variation/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/lift-leveraging-human-feedback-for-text-to-video-m/">LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment网页链接本文提出了一种新的微调方法LiFT，通过利用人工反馈来优化文本到视频生成模型的匹...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文介绍了一种名为LiFT的新微调方法，旨在通过利用人工反馈来优化文本到视频生成模型的匹配度。研究团队首先构建了一个包含1万个人工评分及其理由的数据集LiFT-HRA，并基于此训练了一个奖励模型LiFT-Critic，该模型能够学习奖励函数，作为人类判断的代理，衡量视频与人类期望的匹配度。最后，利用学到的奖励函数通过最大化奖励加权的似然性来调整T2V模型。实验结果显示，经过微调的模型在所有16项指标上均优于CogVideoX-5B，证明了人类反馈在提高生成视频匹配度和质量方面的潜力。
            </div>
            <a href="/papers/2025-03-20/lift-leveraging-human-feedback-for-text-to-video-m/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/aminer/">AMiner——新一代智能型科技情报挖掘与服务系统，能够为你提供查找论文、理解论文、分析论文、写作论文四位一体一站式服务，拥有中英文文献检索、文献辅助阅读、...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                AMiner是一个智能科技情报挖掘与服务系统，提供论文查找、理解、分析和写作的一站式服务。它支持中英文文献检索、辅助阅读和翻译功能，涵盖42个学科的3.5亿论文、0.6亿学者、1.5亿专利和2600万科研项目。AMiner通过互动式问答机制和自动生成文献摘要，提高研究效率。此外，它还提供科研情报订阅服务，根据用户偏好推送最新学术动态。AMiner还具备学者画像、学术会议和必读论文专题等功能，用户可通过浏览器免费使用。
            </div>
            <a href="/papers/2025-03-20/aminer/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/evaluating-and-aligning-codellms-on-human-preferen/">Evaluating and Aligning CodeLLMs on Human Preference网页链接这篇论文研究了代码生成大型语言模型（codeLLMs）的性能评估和与人类偏好对齐的问题。现有的大部...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                这篇论文探讨了代码生成大型语言模型（codeLLMs）在性能评估和与人类偏好对齐方面的问题。现有基准测试主要关注代码生成正确性，而忽略了人类偏好。为此，研究提出了CodeArena基准，模拟现实编程任务，包含397个高质量样本，涵盖40个类别和44种编程语言。此外，研究构建了SynCode-Instruct语料库（近20B标记），验证大规模合成指令微调的有效性。实验显示，开源顶级代码LLM（如Qwen2.5-Coder）与专有LLM（如OpenAI o1）存在显著性能差距，强调了与人类偏好对齐的重要性。
            </div>
            <a href="/papers/2025-03-20/evaluating-and-aligning-codellms-on-human-preferen/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/florence-vl-enhancing-vision-language-models-with-/">Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion网页链接本文提出了一种名为Florence-VL的新型多模态...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文介绍了Florence-VL，一种新型的多模态大型语言模型（MLLM），通过集成生成性视觉基础模型Florence-2来增强视觉表征。Florence-VL采用了一种名为“深度-广度融合（DBFusion）”的方法，有效融合了Florence-2的视觉特征到预训练的语言模型Phi 3.5和LLama 3中。该模型在多种多模态和视觉为中心的基准测试中表现出色，特别是在视觉语言对齐方面优于流行的视觉编码器。研究团队开源了模型和训练方法，以促进未来研究。
            </div>
            <a href="/papers/2025-03-20/florence-vl-enhancing-vision-language-models-with-/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/from-generation-to-judgment-opportunities-and-chal/">From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge网页链接本文全面探讨了大型语言模型（LLM）作为评判者的应用与评估，对LLM在评...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文探讨了大型语言模型（LLM）作为评判者的应用与评估，详细定义了LLM评判者的概念，并从评判内容、方式和领域三个维度构建了分类体系。文章还汇总了评估LLM评判者的基准，突出了关键挑战和潜在研究方向，旨在为这一新兴领域提供见解并激发未来研究。
            </div>
            <a href="/papers/2025-03-20/from-generation-to-judgment-opportunities-and-chal/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/infinity-scaling-bitwise-autoregressive-modeling-f/">Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis网页链接本文介绍了一种名为Infinity的位运算视觉自回归模型，该模型...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文介绍了一种名为Infinity的位运算视觉自回归模型，能够根据语言指令生成高分辨率、逼真的图像。Infinity通过无限词汇量的标记分类器和位运算自我校正机制，显著提高了生成能力和细节表现。该方法将标记词汇量扩展至无限，并同步扩大了变换器规模，展现出更强大的扩展能力。Infinity在自回归文本到图像模型中创下新纪录，性能超过了顶尖的扩散模型如SD3-Medium和SDXL，并在0.8秒内完成1024x1024图像的生成，速度是SD3-Medium的2.6倍。研究团队将发布模型和代码以推动进一步探索。
            </div>
            <a href="/papers/2025-03-20/infinity-scaling-bitwise-autoregressive-modeling-f/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/latentsync-taming-audio-conditioned-latent-diffusi/">LatentSync: Taming Audio-Conditioned Latent Diffusion Models for Lip Sync with SyncNet Supervision 网页链接本研究提出了一种名为LatentSync的端到端唇同...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本研究提出了LatentSync，一种基于音频条件的潜在扩散模型的端到端唇同步框架，无需中间运动表示，直接建模音频与视觉的复杂关系。为解决扩散过程中时间一致性问题，提出了时间表示对齐（TREPA）方法，利用自监督视频模型增强生成帧与真实帧的时间一致性。研究还优化了SyncNet的训练框架，提升了其准确性。实验表明，该方法在HDTF和VoxCeleb2数据集上超越了现有唇同步方法，为音频驱动的人像动画提供了新的解决方案。
            </div>
            <a href="/papers/2025-03-20/latentsync-taming-audio-conditioned-latent-diffusi/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/llmscaling-up-llmrouting-llm8500llm/">#路由LLM最全面探索##笔记本也能玩的大模型Scaling Up研究# 事关路由LLM（Routing LLM），一项截至目前最全面的研究，来了——共计收集和整理了涉及8500&#43;个LLM，...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                中山大学和普渡大学的研究团队对路由LLM（Routing LLM）进行了迄今为止最全面的研究，涉及8500多个LLM在12个基准测试中的2亿条性能记录。路由LLM通过将多个LLM视为“专家”，并由Router（路由器）根据输入选择最合适的LLM进行处理，从而实现高性能、低计算消耗和低幻觉的目标。研究发现，随着LLM候选数量的增加，路由LLM的性能显著提升，称为“Model-level Scaling Up”。团队还开发了RouterEval评测工具，使其他研究人员能够在有限的计算资源（如笔记本或单卡GPU）上参与路由LLM的研究。
            </div>
            <a href="/papers/2025-03-20/llmscaling-up-llmrouting-llm8500llm/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/33htmlpython/">#豆包编程能力升级##用豆包3分钟做个小游戏#豆包编程能力升级了，现在3分钟就能做出专属小游戏。升级后，豆包支持HTML代码实时预览、Python运行，甚至是生成完整...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                豆包编程能力升级，现支持3分钟内制作专属小游戏。新功能包括HTML代码实时预览、Python运行及完整项目生成。用户可通过点击操作消除单词、抽取生日祝福语及生成MBTI人格测试结果。豆包还新增运行按钮，可直接在平台内运行Python代码。
            </div>
            <a href="/papers/2025-03-20/33htmlpython/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/information-fusion-in-smart-agriculture-machine-le/">Information Fusion in Smart Agriculture: Machine Learning Applications and Future Research Directions</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文综述了机器学习（ML）在农业可持续发展与效率提升中的广泛应用，填补了现有研究在跨领域融合视角上的不足。研究围绕五大目标展开：分析ML在农业各阶段的应用、探讨ML与农业数据及数据融合的结合、进行文献计量与统计分析、考察AI驱动农业企业的实际案例，以及整理公开数据集以支持ML模型训练。通过多源数据融合（如遥感、物联网和气候分析），ML提升了精准农业的预测精度与决策能力。本文为研究者、行业专家及政策制定者提供了利用信息融合与ML推动精准农业发展的路线图。
            </div>
            <a href="/papers/2025-03-20/information-fusion-in-smart-agriculture-machine-le/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/navigating-llm-ethics-advancements-challenges-and-/">Navigating LLM Ethics: Advancements, Challenges, and Future Directions</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本研究探讨了大型语言模型（LLMs）在人工智能领域的伦理问题，包括与其他AI系统共有的隐私和公平性挑战，以及LLMs特有的问题，如幻觉、可验证的责任和审查复杂性。研究强调需解决这些复杂性以确保责任性、减少偏见并增强透明度，特别是在信息传播方面。提出了缓解策略和未来方向，倡导跨学科合作，推荐针对特定领域的伦理框架和适应多样环境的动态审计系统，旨在指导LLMs的负责任开发和整合，设想伦理考虑主导AI社会进步的未来。
            </div>
            <a href="/papers/2025-03-20/navigating-llm-ethics-advancements-challenges-and-/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/cosmos-world-foundation-model-platform-for-physica/">Cosmos World Foundation Model Platform for Physical AI</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文介绍了Cosmos世界基础模型平台，旨在帮助开发者为其物理AI系统构建定制化的世界模型。该平台包括视频处理管道、预训练的世界基础模型、模型微调示例和视频标记器。世界基础模型作为通用模型，可微调为下游应用的定制模型。为促进物理AI解决社会关键问题，Cosmos平台开源并提供开放权重模型，许可宽松，可通过https://github.com/nvidia-cosmos/cosmos-predict1获取。
            </div>
            <a href="/papers/2025-03-20/cosmos-world-foundation-model-platform-for-physica/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/envbench-a-benchmark-for-automated-environment-set/">EnvBench: A Benchmark for Automated Environment Setup</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                近期大型语言模型（LLMs）的进展使得研究者能够专注于软件工程领域的实际仓库级任务。本文提出EnvBench，一个全面的环境设置基准，涵盖329个Python和665个基于JVM（Java、Kotlin）的仓库，重点关注具有真实配置挑战的项目。我们实现了两种自动评估指标：Python的静态分析检查和JVM语言的编译检查。通过评估三种环境设置方法，包括一个简单的零样本基线和两个代理工作流，使用GPT-4o和GPT-4o-mini进行测试，最佳方法成功配置了6.69%的Python仓库和29.47%的JVM仓库，表明EnvBench对当前方法仍具挑战性。
            </div>
            <a href="/papers/2025-03-20/envbench-a-benchmark-for-automated-environment-set/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/play2prompt-zero-shot-tool-instruction-optimizatio/">PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                为了解决大型语言模型（LLMs）在零样本工具使用中的挑战，研究者提出了PLAY2PROMPT框架。该框架通过自动“试错”探索工具的输入输出行为，无需标注数据即可优化工具文档并生成使用示例。这些示例不仅指导LLM推理，还作为验证进一步提升工具使用效果。实验表明，PLAY2PROMPT显著提升了开放和封闭模型在零样本任务中的表现，为领域特定工具集成提供了可扩展且有效的解决方案。
            </div>
            <a href="/papers/2025-03-20/play2prompt-zero-shot-tool-instruction-optimizatio/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/visescape-a-benchmark-for-evaluating-exploration-d/">VisEscape: A Benchmark for Evaluating Exploration-driven Decision-making in Virtual Escape Rooms</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                VisEscape是一个包含20个虚拟密室逃脱的基准测试，旨在评估AI模型在探索驱动规划中的表现。该测试要求模型不仅解决孤立谜题，还需构建和优化动态变化环境的时空知识。研究发现，即使最先进的多模态模型也难以成功逃脱，表现差异显著。为此，研究者提出了VisEscaper模型，通过整合记忆、反馈和ReAct模块，显著提升了性能，平均效率提高了5倍，效果提升了3.7倍。
            </div>
            <a href="/papers/2025-03-20/visescape-a-benchmark-for-evaluating-exploration-d/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/cosmos-transfer1-conditional-world-generation-with/">Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                Cosmos-Transfer是一种条件世界生成模型，能够基于多种空间控制输入（如分割、深度和边缘）生成世界模拟。其设计中的空间条件方案具有自适应性和可定制性，允许在不同空间位置对条件输入进行不同权重的调整，从而实现高度可控的世界生成。该模型在Sim2Real等世界到世界转换应用中具有广泛用途，包括物理AI、机器人Sim2Real和自动驾驶数据增强。通过NVIDIA GB200 NVL72机架，模型实现了实时世界生成。为加速该领域研究，模型和代码已在GitHub开源。
            </div>
            <a href="/papers/2025-03-20/cosmos-transfer1-conditional-world-generation-with/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/dont-lie-to-your-friends-learning-what-you-know-fr/">Don&#39;t lie to your friends: Learning what you know from collaborative self-play</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文提出了一种名为“协作自玩”的新方法，用于教导AI代理了解自身能力和限制。通过构建多代理协作环境，团队因共同得出正确答案而获得奖励，从而促使代理发展出对自身知识的元认知。该方法特别适用于拥有不同工具（如特定语料库检索）的小型代理群体，它们必须协作以最大化成功并最小化努力。实验表明，多代理群体的集体奖励能够诱导出在单个代理独立部署时也能改善工具使用和选择性预测的策略。
            </div>
            <a href="/papers/2025-03-20/dont-lie-to-your-friends-learning-what-you-know-fr/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/gricean-norms-as-a-basis-for-effective-collaborati/">Gricean Norms as a Basis for Effective Collaboration</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文提出了一种结合Gricean准则和认知框架的规范性框架，旨在提升基于大型语言模型（LLM）的AI代理在人类-AI协作中的表现。该框架通过整合Gricean准则（数量、质量、关联、方式）和推理，帮助AI代理处理模糊、不完整、无效或不相关的指令。实验表明，采用Gricean准则的Lamoid（基于GPT-4的代理）在任务准确性和生成清晰、准确、上下文相关的响应方面优于未采用准则的版本。这一改进源于规范性框架增强了代理的语用推理能力，促进了有效的人类-AI协作和上下文感知的沟通。
            </div>
            <a href="/papers/2025-03-20/gricean-norms-as-a-basis-for-effective-collaborati/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/measuring-ai-ability-to-complete-long-tasks/">Measuring AI Ability to Complete Long Tasks</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                本文提出了一种新指标“50%-任务完成时间范围”，用于量化AI系统在人类能力方面的表现。该指标指人类完成AI模型能以50%成功率完成的任务所需时间。研究发现，当前前沿AI模型（如Claude 3.7 Sonnet）的50%时间范围约为50分钟，且自2019年以来每7个月翻倍，2024年可能加速。AI能力的提升主要源于更高的可靠性、错误适应能力、逻辑推理和工具使用能力。若趋势持续，5年内AI可能自动化许多目前人类需一个月完成的软件任务，但也带来潜在危险能力增加的担忧。
            </div>
            <a href="/papers/2025-03-20/measuring-ai-ability-to-complete-long-tasks/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/hunyuanvideo-a-systematic-framework-for-large-vide/">HunyuanVideo: A Systematic Framework for Large Video Generative 网页链接本文介绍了一种名为HunyuanVideo的开源视频生成基础模型，其性能可以媲美或超越业界...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                HunyuanVideo是一个开源的大规模视频生成基础模型，性能媲美或超越业界领先的闭源模型。该模型包含数据筛选、高级架构设计、渐进式扩展与训练等关键要素，成功训练了超过130亿参数的视频生成模型，成为开源模型中规模最大的一个。HunyuanVideo在视觉质量、运动动态、文本-视频对齐等方面表现出色，超越了包括Runway Gen-3和Luma 1.6在内的先进模型。研究者公开了基础模型及应用代码，旨在缩小闭源与开源社区的差距，推动视频生成生态系统的发展。相关代码已在GitHub公开。
            </div>
            <a href="/papers/2025-03-20/hunyuanvideo-a-systematic-framework-for-large-vide/" class="read-more">阅读更多</a>
        </article>
        
        <article class="paper-item">
            <h3><a href="/papers/2025-03-20/8gpusota-8gpusotalightgenh/">#8张GPU训出近SOTA模型# 超低成本图像生成预训练方案来了——仅需8张GPU训练，就能实现近SOTA的高质量图像生成效果。划重点：开源。模型名为LightGen，由港科大H...</a></h3>
            <div class="paper-meta">
                <span class="date">2025-03-20</span>
            </div>
            <div class="summary">
                港科大Harry Yang团队与Everlyn AI等机构合作开发的LightGen模型，通过知识蒸馏和直接偏好优化策略，显著降低了图像生成模型的训练成本。仅需8张GPU和88个GPU days，LightGen就能实现与当前最先进（SOTA）模型相媲美的高质量图像生成效果。尽管模型参数量和预训练数据规模较小，LightGen在基准评测中甚至超越部分SOTA模型，展示了高效与高性能的平衡。该模型已开源，为低成本图像生成预训练提供了新方案。
            </div>
            <a href="/papers/2025-03-20/8gpusota-8gpusotalightgenh/" class="read-more">阅读更多</a>
        </article>
        
    </div>
</section>

    </main>
    
    <footer>
        <p>&copy; 2025 AI研究资料库</p>
    </footer>
</body>
</html> 